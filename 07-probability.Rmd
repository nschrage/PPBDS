# Probability {#probability}


Probability forms the foundation for statistics. You might already be
familiar with many aspects of probability, however, formalization of the
concepts is new for most. This chapter aims to introduce probability on
familiar terms using processes most people have seen before.

## Defining probability {#basicsOfProbability}

### Intro Questions

**Q1**: A "die", the singular of dice, is a cube with six faces numbered *1*,
*2*, *3*, *4*, *5*, and *6*. What is the chance of getting *1* when
rolling a die

> **S1**: If the die is
> fair, then the chance of a *1* is as good as the chance of any other
> number. Since there are six outcomes, the chance must be 1-in-6 or,
> equivalently, $1/6$.

**Q2**: What is the chance of getting a *1* or *2* in the next
roll
 
> **S2**: *1* and *2*
> constitute two of the six equally likely possible outcomes, so the
> chance of getting one of these two outcomes must be $2/6 = 1/3$.

**Q3**: What is the chance of getting either *1*, *2*, *3*, *4*, *5*, or *6* on
the next roll
 

> **S3**: 100%. The outcome must be one of these numbers.

**Q4**: What is the chance of not rolling a *2*
 
> **S4**: Since the chance of rolling a *2* is $1/6$ or
> $16.\bar{6}\%$, the chance of not rolling a *2* must be
> $100\% - 16.\bar{6}\%=83.\bar{3}\%$ or $5/6$.
> 
> Alternatively, we could have noticed that not rolling a *2* is the same
> as getting a *1*, *3*, *4*, *5*, or *6*, which makes up five of the six
> equally likely outcomes and has probability $5/6$.

**Q5**: Consider rolling two dice. If $1/6^{th}$ of the time the first die is a
*1* and $1/6^{th}$ of those times the second die is a *1*, what is the
chance of getting two *1*s
 
> **S**: If $16.\bar{6}$% of the time the first die is a *1*
> and $1/6^{th}$ of *those* times the second die is also a *1*, then the
> chance that both dice are *1* is $(1/6)\times (1/6)$ or $1/36$.

### Probability

We use probability to build tools to describe and understand apparent randomness. We often frame probability in terms of a **random process** giving rise to an outcome.

  ------------- --------------- ---------------------------------
  Roll a die    $\rightarrow$   *1*, *2*, *3*, *4*, *5*, or *6*
  Flip a coin   $\rightarrow$   *H* or *T*
  ------------- --------------- ---------------------------------

Rolling a die or flipping a coin is a seemingly random process and each
gives rise to an outcome.



**Definition of Probability**

> The **probability** of an outcome is the proportion of times the outcome would occur if
> we observed the random process an infinite number of times.


Probability is defined as a proportion, and it always takes values
between 0 and 1 (inclusively). It may also be displayed as a percentage
between 0% and 100%.

Probability can be illustrated by rolling a die many times. Let
$\hat{p}_n$ be the proportion of outcomes that are *1* after the first
$n$ rolls. As the number of rolls increases, $\hat{p}_n$ will converge
to the probability of rolling a *1*, $p = 1/6$.
Figure [1.1](#dieProp){reference-type="ref" reference="dieProp"} shows
this convergence for 100,000 die rolls. The tendency of $\hat{p}_n$ to
stabilize around $p$ is described by the **Law of Large Numbers**.

![The fraction of die rolls that are 1 at each stage in a simulation.
The proportion tends to get closer to the probability
$1/6 \approx 0.167$ as the number of rolls
increases.[]{label="dieProp"}](images/dieProp.png){#dieProp
width="80%"}

<!-- Replace the above with some R code. Should eventually by an interactive display which allows the reader to try different things. For example, don't some processes converse faster than others? Or is that too advanced for the first page? -->

**Definition of Law of Large Numbers**

> As more observations are collected, the proportion $\hat{p}_n$ of
> occurrences with a particular outcome converges to the probability $p$
> of that outcome.

<!-- The references in this chapters are different from the references elsewhere. What are current best practices? -->

Occasionally the proportion will veer off from the probability and
appear to defy the Law of Large Numbers, as $\hat{p}_n$ does many times
in Figure [1.1](#dieProp){reference-type="ref" reference="dieProp"}.
However, these deviations become smaller as the number of rolls
increases.

Above we write $p$ as the probability of rolling a *1*. We can also
write this probability as $$\begin{aligned}
P(\text{rolling a 1})\end{aligned}$$ As we become more
comfortable with this notation, we will abbreviate it further. For
instance, if it is clear that the process is "rolling a die", we could
abbreviate $P($rolling a *1*$)$ as $P($*1*$)$. It can be helpful to model a process as random even if it is not truly random.

<!-- The above math notation seems to use way too many dollar signs. Are they really necessary? -->


### Disjoint or mutually exclusive outcomes

Two outcomes are called **disjoint** or **mutually exclusive** if they cannot both happen. For instance, if
we roll a die, the outcomes *1* and *2* are disjoint since they cannot
both occur. On the other hand, the outcomes *1* and "rolling an odd
number" are not disjoint since both occur if the outcome of the roll is
a *1*. The terms *disjoint* and *mutually exclusive* are equivalent and
interchangeable.

Calculating the probability of disjoint outcomes is easy. When rolling a
die, the outcomes *1* and *2* are disjoint, and we compute the
probability that one of these outcomes will occur by adding their
separate probabilities: 

$$\begin{aligned}
P(\text{1 or 2}) = P(\text{1})+P(\text{2}) = 1/6 + 1/6 = 1/3
\end{aligned}$$

The **Addition Rule** guarantees the accuracy of this approach when the outcomes are disjoint.


### Probabilities when events are not disjoint

Let's consider calculations for two events that are not disjoint in the
context of a deck of cards. 

  ------------------- ------------------- ------------------- ------------------- ------------------- ------------------- ------------------- ------------------- -------------------- ------------------- ------------------- ------------------- -------------------
  *2$\clubsuit$*      *3$\clubsuit$*      *4$\clubsuit$*      *5$\clubsuit$*      *6$\clubsuit$*      *7$\clubsuit$*      *8$\clubsuit$*      *9$\clubsuit$*      *10$\clubsuit$*      *J$\clubsuit$*      *Q$\clubsuit$*      *K$\clubsuit$*      *A$\clubsuit$*
  *2$\diamondsuit$*   *3$\diamondsuit$*   *4$\diamondsuit$*   *5$\diamondsuit$*   *6$\diamondsuit$*   *7$\diamondsuit$*   *8$\diamondsuit$*   *9$\diamondsuit$*   *10$\diamondsuit$*   *J$\diamondsuit$*   *Q$\diamondsuit$*   *K$\diamondsuit$*   *A$\diamondsuit$*
  *2$\heartsuit$*     *3$\heartsuit$*     *4$\heartsuit$*     *5$\heartsuit$*     *6$\heartsuit$*     *7$\heartsuit$*     *8$\heartsuit$*     *9$\heartsuit$*     *10$\heartsuit$*     *J$\heartsuit$*     *Q$\heartsuit$*     *K$\heartsuit$*     *A$\heartsuit$*
  *2$\spadesuit$*     *3$\spadesuit$*     *4$\spadesuit$*     *5$\spadesuit$*     *6$\spadesuit$*     *7$\spadesuit$*     *8$\spadesuit$*     *9$\spadesuit$*     *10$\spadesuit$*     *J$\spadesuit$*     *Q$\spadesuit$*     *K$\spadesuit$*     *A$\spadesuit$*
  ------------------- ------------------- ------------------- ------------------- ------------------- ------------------- ------------------- ------------------- -------------------- ------------------- ------------------- ------------------- -------------------

  : Representations of the 52 unique cards in a
  deck.[]{label="deckOfCards"}


**Venn diagrams** are useful when outcomes can be categorized as "in" or "out" for two or
three variables, attributes, or random processes. The Venn diagram in
Figure [1.3](#venn){reference-type="ref" reference="venn"} uses a circle
to represent diamonds and another to represent face cards. If a card is
both a diamond and a face card, it falls into the intersection of the
circles. If it is a diamond but not a face card, it will be in part of
the left circle that is not in the right circle (and so on). The total
number of cards that are diamonds is given by the total number of cards
in the diamonds circle: $10+3=13$. The probabilities are also shown
(e.g. $10/52 = 0.1923$).

![A Venn diagram for diamonds and face
cards.[]{label="venn"}](images/venn.png){#venn height="1.4in"}


Let $A$ represent the event that a randomly selected card is a diamond
and $B$ represent the event that it is a face card. How do we compute
$P(A$ or $B)$
 
 Events $A$ and $B$ are not disjoint -- the cards
$J\diamondsuit$, $Q\diamondsuit$, and $K\diamondsuit$ fall into both
categories -- so we cannot use the Addition Rule for disjoint events.
Instead we use the Venn diagram. We start by adding the probabilities of
the two events: $$\begin{aligned}
P(A) + P(B) = P({\color{redcards}\diamondsuit}) + P(\text{face card}) = 12/52 + 13/52
\label{overCountFaceDiamond}\end{aligned}$$ However, the three cards
that are in both events were counted twice, once in each probability. We
must correct this double counting: $$\begin{aligned}
P(A\text{ or } B) &=&P(\text{face card or }{\color{redcards}\diamondsuit})  \notag \\
 &=& P(\text{face card}) + P({\color{redcards}\diamondsuit}) - P(\text{face card and }{\color{redcards}\diamondsuit}) \label{diamondFace} \\
 &=& 12/52 + 13/52 - 3/52 \notag \\
 &=& 22/52 = 11/26 \notag\end{aligned}$$
The Equation above is an example of the **General Addition Rule**.

**General Addition Rule**

> If $A$ and $B$ are any two events, disjoint or not, then the probability
> that at least one of them will occur is $$\begin{aligned}
> P(A\text{ or }B) = P(A) + P(B) - P(A\text{ and }B)
> \label{generalAdditionRule}\end{aligned}$$ where $P(A$ and $B)$ is the
> probability that both events occur. When we write "or" in statistics, 
> we mean "and/or" unless we explicitly
> state otherwise. Thus, $A$ or $B$ occurs means $A$, $B$, or both $A$ and
> $B$ occur.


### Probability distributions

A **Probability distribution** is a table of all disjoint outcomes and their associated
probabilities. The table below shows the probability distribution for the sum of
two dice.

  ------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ----------------
  Â                                                                                                                                                                                        
  Dice sum             2                3                4                5                6                7                8                9                10               11               12
  Probability    $\frac{1}{36}$   $\frac{2}{36}$   $\frac{3}{36}$   $\frac{4}{36}$   $\frac{5}{36}$   $\frac{6}{36}$   $\frac{5}{36}$   $\frac{4}{36}$   $\frac{3}{36}$   $\frac{2}{36}$   $\frac{1}{36}$
  ------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ---------------- ----------------

  : Probability distribution for the sum of two
  dice.[]{label="diceProb"}

**Rules for probability distributions**

> A probability distribution is a list of the possible outcomes with
corresponding probabilities that satisfies three rules:

> 1.  The outcomes listed must be disjoint.
> 2.  Each probability must be between 0 and 1.
> 3.  The probabilities must total 1.


Probability distributions can also be
summarized in a bar plot. For instance, the distribution of US household
incomes is shown in
Figure [1.4](#usHouseholdIncomeDistBar){reference-type="ref"
reference="usHouseholdIncomeDistBar"} as a bar plot.[^14] The
probability distribution for the sum of two dice is shown in
the table at the begining of the probability distributions section and plotted in
Figure [1.5](#diceSumDist){reference-type="ref"
reference="diceSumDist"}.

<!-- These figures should be calculated live. Maybe we can make a theme for the book which makes all the figures look similar and nice. -->

![The probability distribution of US household
income.[]{label="usHouseholdIncomeDistBar"}](images/usHouseholdIncomeDistBar.png){#usHouseholdIncomeDistBar
width="68%"}

![The probability distribution of the sum of two
dice.[]{label="diceSumDist"}](images/diceSumDist.png){#diceSumDist
width="73%"}

In these bar plots, the bar heights represent the probabilities of
outcomes. If the outcomes are numerical and discrete, it is usually
(visually) convenient to make a bar plot that resembles a histogram, as
in the case of the sum of two dice. 

### Complement of an event

<!-- Cut this section? Do we ever need the complement? -->

Rolling a die produces a value in the set $\{$*1*, *2*, *3*, *4*, *5*,
*6*$\}$. This set of all possible outcomes is called the **sample space** ($S$) for
rolling a die. We often use the sample space to examine the scenario
where an event does not occur.

Let $D=\{$*2*, *3*$\}$ represent the event that the outcome of a die
roll is *2* or *3*. Then the **complement** of $D$ represents all outcomes in our
sample space that are not in $D$, which is denoted by $D^c = \{$*1*,
*4*, *5*, *6*$\}$. That is, $D^c$ is the set of all possible outcomes
not already included in $D$.
Figure [1.6](#complementOfD){reference-type="ref"
reference="complementOfD"} shows the relationship between $D$, $D^c$,
and the sample space $S$.

![Event $D=\{$*2*, *3*$\}$ and its complement, $D^c = \{$*1*, *4*, *5*,
*6*$\}$. $S$ represents the sample space, which is the set of all
possible
events.[]{label="complementOfD"}](images/complementOfD.png){#complementOfD
width="40%"}

A complement of an event $A$ is constructed to have two very important
properties: (i) every possible outcome not in $A$ is in $A^c$, and (ii)
$A$ and $A^c$ are disjoint. Property (i) implies $$\begin{aligned}
P(A\text{ or }A^c) = 1
\label{complementSumTo1}\end{aligned}$$ That is, if the outcome is not
in $A$, it must be represented in $A^c$. 


### Independence {#probabilityIndependence}

Just as variables and observations can be independent, random processes
can be independent, too. Two processes are **independent** if knowing the outcome of one
provides no useful information about the outcome of the other. For
instance, flipping a coin and rolling a die are two independent
processes -- knowing the coin was heads does not help determine the
outcome of a die roll. On the other hand, stock prices usually move up
or down together, so they are not independent.

Rolling two dice is a basic example of independence. We want to determine the probability that
both will be *1*. Suppose one of the dice is red and the other white. If
the outcome of the red die is a *1*, it provides no information about
the outcome of the white die. We first encountered this same question in
the beginning of the chapter, where we calculated the probability
using the following reasoning: $1/6^{th}$ of the time the red die is a
*1*, and $1/6^{th}$ of *those* times the white die will also be *1*.
This is illustrated in
Figure [1.7](#indepForRollingTwo1s){reference-type="ref"
reference="indepForRollingTwo1s"}. Because the rolls are independent,
the probabilities of the corresponding outcomes can be multiplied to get
the final answer: $(1/6)\times(1/6)=1/36$. This can be generalized to
many independent processes.

![$1/6^{th}$ of the time, the first roll is a *1*. Then $1/6^{th}$ of
*those* times, the second roll will also be a
*1*.[]{label="indepForRollingTwo1s"}](images/indepForRollingTwo1s.png){#indepForRollingTwo1s
width="65%"}

**Example**
What if there was also a blue die independent of the other two?
 
 What is
the probability of rolling the three dice and getting all
*1*s?
 
If $1/36^{th}$ of the time the white and red
dice are both *1*, then $1/6^{th}$ of *those* times the blue die will
also be *1*, so multiply: $$\begin{aligned}
P(white=\text{1 and } red=\text{1 and } blue=\text{1})
    &= P(white=\text{1})\times P(red=\text{1})\times P(blue=\text{1}) \\
    &= (1/6)\times (1/6)\times (1/6)
    = 1/216\end{aligned}$$

The example above illustrate what is called the Multiplication Rule
for independent processes. Sometimes we wonder if one outcome provides 
useful information about
another outcome. The question we are asking is, are the occurrences of
the two events independent
 
 We say that two events $A$ and $B$ are
independent if they satisfy
$$P(A \text{ and }B) = P(A) \times  P(B)$$

**Example**

If we shuffle up a deck of cards and draw one, is the event that the
card is a heart independent of the event that the card is an ace
 
 The
probability the card is a heart is $1/4$ and the probability that it is
an ace is $1/13$. The probability the card is the ace of hearts is
$1/52$. We check whether
$P(A \text{ and }B) = P(A) \times  P(B)$ is satisfied: $$\begin{aligned}
P({\color{redcards}\heartsuit})\times P(\text{ace}) = \frac{1}{4}\times \frac{1}{13} = \frac{1}{52} 
                    = P({\color{redcards}\heartsuit}\text{ and ace})\end{aligned}$$
Because the equation holds, the event that the card is a heart and the
event that the card is an ace are independent events.

### Conditional probability {#conditionalProbabilitySection}

Are students more likely to use marijuana when their parents used drugs?
 

The data set contains a sample of 445 cases with two variables, students and parents,
and is summarized in the table below.[^23] The variable is either *uses*
or *not*, where a student is labeled as if she has recently used
marijuana. The student variable takes the value *used* if at least one of the
parents used drugs, including alcohol.

               used      not       Total
  ---------- ---------- --------- -------
  uses         125        94      219
  not           85       141      226
  Total        210       235      445


  : Contingency table summarizing the data
  set.[]{label="contTableOfParStDrugUse"}

![A Venn diagram using boxes for the data
set.[]{label="drugUseVenn"}](images/drugUseVenn.png){#drugUseVenn
width="65%"}

**Example**

If at least one parent used drugs, what is the chance their child
uses drugs.
 
 We will estimate this probability using the data. Of the 210 cases
in this data set where = *used*, 125 represent cases where = *uses*:
$$\begin{aligned}
P(\text{student = uses given parents = used}) = \frac{125}{210} = 0.60\end{aligned}$$

**Example**

A student is randomly selected from the study and she does not use
drugs. What is the probability that at least one of her parents
used
 
If the student does not use
drugs, then she is one of the 226 students in the second row. Of these
226 students, 85 had at least one parent who used drugs:
$$\begin{aligned}
P(\text{parents = used given student = not}) = \frac{85}{226} = 0.376\end{aligned}$$

### Marginal and joint probabilities {#marginalAndJointProbabilities}

The Table below includes row and column totals for each
variable separately in the data set. These totals represent **marginal probabilities** for the
sample, which are the probabilities based on a single variable without
conditioning on any other variables. For instance, a probability based
solely on the variable is a marginal probability: $$\begin{aligned}
P(\text{student = uses}) = \frac{219}{445} = 0.492\end{aligned}$$
A probability of outcomes for two or more variables or processes is
called a **joint probability**: $$\begin{aligned}
P(\text{student = uses and parents = not}) = \frac{94}{445} = 0.21\end{aligned}$$
It is common to substitute a comma for "and" in a joint probability,
although either is acceptable.

               used      not       Total
  ---------- ---------- --------- -------
  uses         0.28      0.21      0.49
  not          0.19      0.32      0.51
  Total        0.47      0.53      1.00

  : Probability table summarizing parental and student drug
  use.[]{label="drugUseProbTable"}

**Marginal and joint Probabilities**

> If a probability is based on a single variable, it is a *marginal
> probability*. The probability of outcomes for two or more variables or
> processes is called a *joint probability*.

We use **table proportions** to summarize joint probabilities for the sample. These
proportions are computed by dividing each count in the first table by 445 to obtain the proportions in
the second table. The joint probability distribution of the
and variables is shown in
the table below.

  Joint outcome         Probability
  -------------------- -------------
  = *used*, = *uses*       0.28
  = *used*, = *not*        0.19
  = *not*, = *uses*        0.21
  = *not*, = *not*         0.32
  Total                    1.00

  : A joint probability distribution for the data
  set.[]{label="drugUseDistribution"}


We can compute marginal probabilities using joint probabilities in
simple cases. For example, the probability a random student from the
study uses drugs is found by summing the outcomes from
the table above where = *uses*: $$\begin{aligned}
&&P(\text{student = uses}) \\
&& \quad =  P(\text{parents = used, student = uses}) + \\
&& \quad \quad \quad \quad P(\text{parents = not, student = uses}) \\
&& \quad = 0.28 + 0.21 = 0.49\end{aligned}$$

### Defining conditional probability

There is some connection between drug use of parents and of the student:
drug use of one is associated with drug use of the other.[^25] In this
section, we discuss how to use information about associations between
two variables to improve probability estimation.

The probability that a random student from the study uses drugs is 0.49.
Could we update this probability if we knew that this student's parents
used drugs
 
 Absolutely. To do so, we limit our view to only those 210
cases where parents used drugs and look at the fraction where the
student uses drugs: $$\begin{aligned}
P(\text{student = uses given parents = used}) = \frac{125}{210} = 0.60\end{aligned}$$
We call this a **conditional probability** because we computed the probability under a condition: =
*used*. There are two parts to a conditional probability, **the outcome of interest** and the **condition** . It
is useful to think of the condition as information we know to be true,
and this information usually can be described as a known outcome
or event.

We separate the text inside our probability notation into the outcome of
interest and the condition: $$\begin{aligned}
&& P(\text{student = uses given parents = used}) \notag \\
&& = P(\text{student = uses } | \text{ parents = used}) = \frac{125}{210} = 0.60
\label{probStudentUsedIfParentsUsedInFormalNotation}\end{aligned}$$ The
vertical bar "$|$" is read as *given*.

In
the Equation above, we computed
the probability a student uses based on the condition that at least one
parent used as a fraction: $$\begin{aligned}
&& P(\text{student = uses } | \text{ parents = used}) \notag \\
&&\quad = \frac{\text{#times student = uses and parents = used}}{\text{#times parents = used}} \label{ratioOfBothToRatioOfConditionalForParentsAndStudent} \\
&&\quad = \frac{125}{210} = 0.60 \notag\end{aligned}$$ We considered
only those cases that met the condition, = *used*, and then we computed
the ratio of those cases that satisfied our outcome of interest, the
student uses.

Counts are not always available for data, and instead only marginal and
joint probabilities may be provided. For example, disease rates are
commonly listed in percentages rather than in a count format. We would
like to be able to compute conditional probabilities even when no counts
are available, and we use
the equation above as an
example demonstrating this technique.

We considered only those cases that satisfied the condition, = *used*.
Of these cases, the conditional probability was the fraction who
represented the outcome of interest, = *uses*. Suppose we were provided
only the information in
the second table of this section i.e. only probability data. Then if we
took a sample of 1000 people, we would anticipate about 47% or
$0.47\times 1000 = 470$ would meet our information criterion. Similarly,
we would expect about 28% or $0.28\times 1000 = 280$ to meet both the
information criterion and represent our outcome of interest. Thus, the
conditional probability could be computed: $$\begin{aligned}
P(\text{student = uses } | \text{ parents = used})
    &= \frac{\text{#(student = uses and parents = used)}}{\text{#(parents = used)}} \notag \\
    &= \frac{280}{470} = \frac{0.28}{0.47} = 0.60
\label{stUserPUsedHypSampSize}\end{aligned}$$ In
In the equation above, we examine exactly the fraction of
two probabilities, 0.28 and 0.47, which we can write as
$$\begin{aligned}
P(student = uses\ \text{and}\ parents = used)
    \quad\text{and}\quad
    P(parents = used).\end{aligned}$$ The fraction of these
probabilities represents our general formula for conditional
probability.

**Conditional Probability**

> The conditional probability of the outcome of interest $A$ given
condition $B$ is computed as the following: $$\begin{aligned}
P(A | B) = \frac{P(A\text{ and }B)}{P(B)}
\label{condProbEq}\end{aligned}$$


### Smallpox in Boston, 1721

The data set provides a sample of 6,224 individuals from the year 1721
who were exposed to smallpox in Boston.[^29] Doctors at the time
believed that inoculation, which involves exposing a person to the
disease in a controlled form, could reduce the likelihood of death.

Each case represents one person with two variables: innoculated and result . The variable
takes two levels: *yes* or *no*, indicating whether the person was
inoculated or not. The variable has outcomes *lived* or *died*. These
data are summarized in
the tables below.

  --------- ------- ----- ------ -------
                      yes     no   Total
            lived     238   5136    5374
            died        6    844     850
            Total     244   5980    6224
  --------- ------- ----- ------ -------

  : Contingency table for the data
  set.[]{label="smallpoxContingencyTable"}

  --------- ------- -------- -------- --------
                         yes       no    Total
            lived     0.0382   0.8252   0.8634
            died      0.0010   0.1356   0.1366
            Total     0.0392   0.9608   1.0000
  --------- ------- -------- -------- --------

  : Table proportions for the data, computed by dividing each count by
  the table total, 6224.[]{label="smallpoxProbabilityTable"}


  : Table proportions for the data, computed by dividing each count by
  the table total, 6224.[]{label="smallpoxProbabilityTable"}



### General multiplication rule

Section [1.1.6](#probabilityIndependence){reference-type="ref"
reference="probabilityIndependence"} introduced the Multiplication Rule
for independent processes. Here we provide the **General Multiplication rule** for events that might not
be independent.

**General Multiplication Rule**

> If $A$ and $B$ represent two outcomes or events, then $$\begin{aligned}
P(A\text{ and }B) = P(A | B)\times P(B)\end{aligned}$$

> It is useful to think of $A$ as the outcome of interest and $B$ as the
condition.

This General Multiplication Rule is simply a rearrangement of the
definition for conditional probability.

**Example**

Consider the smallpox data set. Suppose we are given only two pieces of
information: 96.08% of residents were not inoculated, and 85.88% of the
residents who were not inoculated ended up surviving. How could we
compute the probability that a resident was not inoculated and lived
 
 We
will compute our answer using the General Multiplication Rule and then
verify it using
the smallpox probability table. We want to determine
$$\begin{aligned}
P(\text{result = lived and inoculated = no})\end{aligned}$$
and we are given that $$\begin{aligned}
P(\text{result = lived }|\text{ inoculated = no})=0.8588 \\
P(\text{inoculated = no})=0.9608\end{aligned}$$ Among the
96.08% of people who were not inoculated, 85.88% survived:
$$\begin{aligned}
P(\text{result = lived and inoculated = no}) = 0.8588\times 0.9608 = 0.8251\end{aligned}$$
This is equivalent to the General Multiplication Rule. We can confirm
this probability in
the smallpox probability table at the intersection of *no* and
*lived* (with a small rounding error).


**Sum of conditional probabilities**

> Let $A_1$, \..., $A_k$ represent all the disjoint outcomes for a
variable or process. Then if $B$ is an event, possibly for another
variable or process, we have: $$\begin{aligned}
P(A_1|B)+\cdots+P(A_k|B) = 1\end{aligned}$$

> The rule for complements also holds when an event and its complement are
conditioned on the same information: $$\begin{aligned}
P(A | B) = 1 - P(A^c | B)\end{aligned}$$

### Independence considerations in conditional probability

If two processes are independent, then knowing the outcome of one should
provide no information about the other. We can show this is
mathematically true using conditional probabilities.



### Tree diagrams

**Tree diagrams** are a tool to organize outcomes and probabilities around the structure
of the data. They are most useful when two or more processes occur in a
sequence and each process is conditioned on its predecessors.

The data fit this description. We see the population as split by : *yes*
and *no*. Following this split, survival rates were observed for each
group. This structure is reflected in the *tree diagram** shown in
Figure [1.9](#smallpoxTreeDiagram){reference-type="ref"
reference="smallpoxTreeDiagram"}. The first branch for is said to be the **primary**
branch while the other branches are **secondary** .

![A tree diagram of the data
set.[]{label="smallpoxTreeDiagram"}](fimages/smallpoxTreeDiagram.png){#smallpoxTreeDiagram
width="93%"}

Tree diagrams are annotated with marginal and conditional probabilities,
as shown in Figure [1.9](#smallpoxTreeDiagram){reference-type="ref"
reference="smallpoxTreeDiagram"}. This tree diagram splits the smallpox
data by innoculation into the *yes* and *no* groups with respective marginal
probabilities 0.0392 and 0.9608. The secondary branches are conditioned
on the first, so we assign conditional probabilities to these branches.
For example, the top branch in
Figure [1.9](#smallpoxTreeDiagram){reference-type="ref"
reference="smallpoxTreeDiagram"} is the probability that result = *lived*
conditioned on the information that innoculated = *yes*. We may (and usually do)
construct joint probabilities at the end of each branch in our tree by
multiplying the numbers we come across as we move from left to right.
These joint probabilities are computed using the General Multiplication
Rule: $$\begin{aligned}
&& P(\text{inoculated = yes and result = lived}) \\
    &&\quad = P(\text{inoculated = yes})\times P(\text{result = lived}|\text{inoculated = yes}) \\
    &&\quad = 0.0392\times 0.9754=0.0382\end{aligned}$$

**Example**

Consider the midterm and final for a statistics class. Suppose 13% of
students earned an *A* on the midterm. Of those students who earned an
*A* on the midterm, 47% received an *A* on the final, and 11% of the
students who earned lower than an *A* on the midterm received an *A* on
the final. You randomly pick up a final exam and notice the student
received an *A*. What is the probability that this student earned an *A*
on the midterm
 


The end-goal is to find
$P(\text{midterm = A} | \text{final = A})$. To
calculate this conditional probability, we need the following
probabilities: $$\begin{aligned}
P(\text{midterm = A and final = A}) \qquad\text{and}\qquad
P(\text{final = A})\end{aligned}$$ 


However, this
information is not provided, and it is not obvious how to calculate
these probabilities. Since we aren't sure how to proceed, it is useful
to organize the information into a tree diagram, as shown in
Figure [1.10](#testTree){reference-type="ref" reference="testTree"}.
When constructing a tree diagram, variables provided with marginal
probabilities are often used to create the tree's primary branches; in
this case, the marginal probabilities are provided for midterm grades.
The final grades, which correspond to the conditional probabilities
provided, will be shown on the secondary branches.

![A tree diagram describing the and
variables.[]{label="testTree"}](images/testTree.png){#testTree
width="87%"}

With the tree diagram constructed, we may compute the required
probabilities: $$\begin{aligned}
&&P(\text{midterm = A and final = A}) = 0.0611 \\
&&P(\text{final = A})  \\
&& \quad= P(\text{midterm = other and final = A}) + P(\text{midterm = A and final = A}) \\
&& \quad= 0.0611 + 0.0957 = 0.1568\end{aligned}$$ The marginal
probability, $P($ = *A*$)$, was calculated by adding up all the joint
probabilities on the right side of the tree that correspond to = *A*. We
may now finally take the ratio of the two probabilities:
$$\begin{aligned}
P(\text{midterm = A} | \text{final = A}) &=& \frac{P(\text{midterm = A and final = A})}{P(\text{final = A})} \\
&=& \frac{0.0611}{0.1568} = 0.3897\end{aligned}$$ The probability the
student also earned an A on the midterm is about 0.39.


Random variables {#randomVariablesSection}
----------------

**Example**

Two books are assigned for a statistics class: a textbook and its
corresponding study guide. The university bookstore determined 20% of
enrolled students do not buy either book, 55% buy the textbook only, and
25% buy both books, and these percentages are relatively constant from
one term to another. If there are 100 students enrolled, how many books
should the bookstore expect to sell to this
class

**Example**

Would you be surprised if the bookstore sold slightly more or less than
105 books
 
[^39]

The textbook costs \$137 and the study guide \$33. How much revenue
should the bookstore expect from this class of 100
students
 
 About 55
students will just buy a textbook, providing revenue of
$$\begin{aligned}
\$137 \times  55 = \$7,535\end{aligned}$$ The roughly 25 students who
buy both the textbook and the study guide would pay a total of
$$\begin{aligned}
(\$137 + \$33) \times  25 = \$170 \times  25 = \$4,250\end{aligned}$$
Thus, the bookstore should expect to generate about
$\$7,535 + \$4,250 = \$11,785$ from these 100 students for this one
class. However, there might be some *sampling variability* so the actual
amount may differ by a little bit.

![Probability distribution for the bookstore's revenue from a single
student. The distribution balances on a triangle representing the
average revenue per
student.[]{label="bookCostDist"}](images/bookCostDist.png){#bookCostDist
width="69%"}

**Example**

What is the average revenue per student for this
course
 
 The
expected total revenue is \$11,785, and there are 100 students.
Therefore the expected revenue per student is
$\$11,785/100 =  \$117.85$.

### Expectation

We call a variable or process with a numerical outcome a , and we
usually represent this random variable with a capital letter such as
$X$, $Y$, or $Z$. The amount of money a single student will spend on her
statistics books is a random variable, and we represent it by $X$.

**Random Variable**
> A random process or variable with a numerical outcome.

The possible outcomes of $X$ are labeled with a corresponding lower case
letter $x$ and subscripts. For example, we write $x_1=\$0$, $x_2=\$137$,
and $x_3=\$170$, which occur with probabilities $0.20$, $0.55$, and
$0.25$. The distribution of $X$ is summarized in
Figure [1.11](#bookCostDist){reference-type="ref"
reference="bookCostDist"} and
the table below

  $i$            1       2       3      Total
  ------------ ------ ------- ------- -------
  $x_i$         \$0    \$137   \$170       --
  $P(X=x_i)$    0.20   0.55    0.25      1.00

  : The probability distribution for the random variable $X$,
  representing the bookstore's revenue from a single
  student.[]{label="statSpendDist"}

We computed the average outcome of $X$ as \$117.85 in
dealing with the revenue per student. We call this average the **expected value** of $X$, denoted by
$E(X)$. The expected value of a random variable is computed by adding
each outcome weighted by its probability: $$\begin{aligned}
E(X) &= 0 \times  P(X=0) + 137 \times  P(X=137) + 170 \times  P(X=170) \\
    &= 0 \times  0.20 + 137 \times  0.55 + 170 \times  0.25 = 117.85\end{aligned}$$
    
**Expected value of a Discrete Random Variable**

> If $X$ takes outcomes $x_1$, \..., $x_k$ with probabilities $P(X=x_1)$,
\..., $P(X=x_k)$, the expected value of $X$ is the sum of each outcome
multiplied by its corresponding probability: $$\begin{aligned}
E(X)    &= x_1\times P(X=x_1) + \cdots + x_k\times P(X=x_k) \notag \\
    &= \sum_{i=1}^{k}x_iP(X=x_i)\end{aligned}$$ The Greek letter $\mu$
may be used in place of the notation $E(X)$.

The expected value for a random variable represents the average outcome.
For example, $E(X)=117.85$ represents the average amount the bookstore
expects to make from a single student, which we could also write as
$\mu=117.85$.

It is also possible to compute the expected value of a continuous random
variable. However, it requires a little calculus and we save it for a
later class.[^40]

In physics, the expectation holds the same meaning as the center of
gravity. The distribution can be represented by a series of weights at
each outcome, and the mean represents the balancing point. This is
represented in Figures [1.11](#bookCostDist){reference-type="ref"
reference="bookCostDist"} and [1.12](#bookWts){reference-type="ref"
reference="bookWts"}. The idea of a center of gravity also expands to
continuous probability distributions.
Figure [1.13](#contBalance){reference-type="ref"
reference="contBalance"} shows a continuous probability distribution
balanced atop a wedge placed at the mean.

![A weight system representing the probability distribution for $X$. The
string holds the distribution at the mean to keep the system
balanced.[]{label="bookWts"}](images/bookWts.png){#bookWts
width="72%"}

![A continuous distribution can also be balanced at its
mean.[]{label="contBalance"}](images/contBalance.png){#contBalance
width="65%"}

### Variability in random variables

Suppose you ran the university bookstore. Besides how much revenue you
expect to generate, you might also want to know the volatility
(variability) in your revenue.

The and can be used to describe the variability of a random variable. We first computed deviations from
the mean ($x_i - \mu$), squared those deviations, and took an average to
get the variance. In the case of a random variable, we again compute
squared deviations. However, we take their sum weighted by their
corresponding probabilities, just like we did for the expectation. This
weighted sum of squared deviations equals the variance, and we calculate
the standard deviation by taking the square root of the variance.

**General variance formula**

> If $X$ takes outcomes $x_1$, \..., $x_k$ with probabilities $P(X=x_1)$,
\..., $P(X=x_k)$ and expected value $\mu=E(X)$, then the variance of
$X$, denoted by $Var(X)$ or the symbol $\sigma^2$, is $$\begin{aligned}
\sigma^2 &= (x_1-\mu)^2\times P(X=x_1) + \cdots \notag \\
    & \qquad\quad\cdots+ (x_k-\mu)^2\times P(X=x_k) \notag \\
    &= \sum_{j=1}^{k} (x_j - \mu)^2 P(X=x_j)\end{aligned}$$ The standard
deviation of $X$, labeled $\sigma$, is the square root of the variance.

**Example**

Compute the expected value, variance, and standard deviation of $X$, the
revenue of a single statistics student for the bookstore. It is useful
to construct a table that holds computations for each outcome
separately, then add up the results.

  $i$                           1       2       3    Total
  ------------------------ ------ ------- ------- --------
  $x_i$                       \$0   \$137   \$170 
  $P(X=x_i)$                 0.20    0.55    0.25 
  $x_i \times  P(X=x_i)$        0   75.35   42.50   117.85

Thus, the expected value is $\mu=117.85$, which we computed earlier. The
variance can be constructed by extending this table:

  $i$                                     1        2         3    Total
  ------------------------------ ---------- -------- --------- --------
  $x_i$                                 \$0    \$137     \$170 
  $P(X=x_i)$                           0.20     0.55      0.25 
  $x_i \times  P(X=x_i)$                  0    75.35     42.50   117.85
  $x_i - \mu$                       -117.85    19.15     52.15 
  $(x_i-\mu)^2$                    13888.62   366.72   2719.62 
  $(x_i-\mu)^2\times P(X=x_i)$       2777.7    201.7     679.9   3659.3

The variance of $X$ is $\sigma^2 = 3659.3$, which means the standard
deviation is $\sigma = \sqrt{3659.3} = \$60.49$.


### Linear combinations of random variables

So far, we have thought of each variable as being a complete story in
and of itself. Sometimes it is more appropriate to use a combination of
variables. For instance, the amount of time a person spends commuting to
work each week can be broken down into several daily commutes.
Similarly, the total gain or loss in a stock portfolio is the sum of the
gains and losses in its components.

**Example**

John travels to work five days a week. We will use $X_1$ to represent
his travel time on Monday, $X_2$ to represent his travel time on
Tuesday, and so on. Write an equation using $X_1$, \..., $X_5$ that
represents his travel time for the week, denoted by $W$. His total
weekly travel time is the sum of the five daily values:
$$W = X_1 + X_2 + X_3 + X_4 + X_5$$ Breaking the weekly travel time $W$
into pieces provides a framework for understanding each source of
randomness and is useful for modeling $W$.

**Example**

It takes John an average of 18 minutes each day to commute to work. What
would you expect his average commute time to be for the week
 
 We were
told that the average (i.e. expected value) of the commute time is 18
minutes per day: $E(X_i) = 18$. To get the expected time for the sum of
the five days, we can add up the expected time for each individual day:
$$\begin{aligned}
E(W) &= E(X_1 + X_2 + X_3 + X_4 + X_5) \\
    &= E(X_1) + E(X_2) + E(X_3) + E(X_4) + E(X_5) \\
    &= 18 + 18 + 18 + 18 + 18 = 90\text{ minutes}\end{aligned}$$ The
expectation of the total time is equal to the sum of the expected
individual times. More generally, the expectation of a sum of random
variables is always the sum of the expectation for each random variable.


Two important concepts concerning combinations of random variables have
so far been introduced. First, a final value can sometimes be described
as the sum of its parts in an equation. Second, intuition suggests that
putting the individual average values into this equation gives the
average value we would expect in total. This second point needs
clarification -- it is guaranteed to be true in what are called *linear
combinations of random variables*.

A **Linear Combination** of two random variables $X$ and $Y$ is a fancy phrase to describe a
combination $$aX + bY$$ where $a$ and $b$ are some fixed and known
numbers. For John's commute time, there were five random variables --
one for each work day -- and each random variable could be written as
having a fixed coefficient of 1:
$$1X_1 + 1 X_2 + 1 X_3 + 1 X_4 + 1 X_5$$ For Elena's net gain or loss,
the $X$ random variable had a coefficient of +1 and the $Y$ random
variable had a coefficient of -1.

When considering the average of a linear combination of random
variables, it is safe to plug in the mean of each random variable and
then compute the final result. For a few examples of nonlinear
combinations of random variables -- cases where we cannot simply plug in
the means -- see the footnote.[^45]

**Linear combinations of random variables and the average result**

> If $X$ and $Y$ are random variables, then a linear combination of the
random variables is given by $$\begin{aligned}
\label{linComboOfRandomVariablesXAndY}
aX + bY\end{aligned}$$ where $a$ and $b$ are some fixed numbers. To
compute the average value of a linear combination of random variables,
plug in the average of each individual random variable and compute the
result: $$\begin{aligned}
a\times E(X) + b\times E(Y)\end{aligned}$$ Recall that the expected
value is the same as the mean, e.g. $E(X) = \mu_X$.

**Example**

Leonard has invested \$6000 in Google Inc. (stock ticker: GOOG) and
\$2000 in Exxon Mobil Corp. (XOM). If $X$ represents the change in
Google's stock next month and $Y$ represents the change in Exxon Mobil
stock next month, write an equation that describes how much money will
be made or lost in Leonard's stocks for the month. For simplicity, we
will suppose $X$ and $Y$ are not in percents but are in decimal form
(e.g. if Google's stock increases 1%, then $X=0.01$; or if it loses 1%,
then $X=-0.01$). Then we can write an equation for Leonard's gain as
$$\begin{aligned}
\$6000\times X + \$2000\times Y\end{aligned}$$ If we plug in the change
in the stock value for $X$ and $Y$, this equation gives the change in
value of Leonard's stock portfolio for the month. A positive value
represents a gain, and a negative value represents a loss.


### Variability in linear combinations of random variables

Quantifying the average outcome from a linear combination of random
variables is helpful, but it is also important to have some sense of the
uncertainty associated with the total outcome of that combination of
random variables. We calculated the expected net gain or loss of Leonard's stock
portfolio was considered in Guided
Practice. However, there was
no quantitative discussion of the volatility of this portfolio. For
instance, while the average monthly gain might be about \$134 according
to the data, that gain is not guaranteed.
Figure [1.14](#changeInLeonardsStockPortfolioFor36Months){reference-type="ref"
reference="changeInLeonardsStockPortfolioFor36Months"} shows the monthly
changes in a portfolio like Leonard's during the 36 months from 2009 to
2011. The gains and losses vary widely, and quantifying these
fluctuations is important when investing in stocks.

![The change in a portfolio like Leonard's for the 36 months from 2009
to 2011, where \$6000 is in Google's stock and \$2000 is in Exxon
Mobil's.[]{label="changeInLeonardsStockPortfolioFor36Months"}](images/changeInLeonardsStockPortfolioFor36Months.png){#changeInLeonardsStockPortfolioFor36Months
width="65%"}

Just as we have done in many previous cases, we use the variance and
standard deviation to describe the uncertainty associated with Leonard's
monthly returns. To do so, the variances of each stock's monthly return
will be useful, and these are shown in
the table below. The stocks' returns are nearly
independent.

           Mean ($\bar{x}$)   Standard deviation ($s$)   Variance ($s^2$)
  ------ ------------------ -------------------------- ------------------
  GOOG               0.0210                     0.0846             0.0072
  XOM                0.0038                     0.0519             0.0027

  : The mean, standard deviation, and variance of the GOOG and XOM
  stocks. These statistics were estimated from historical stock data, so
  notation used for sample statistics has been
  used.[]{label="sumStatOfGOOGXOM"}

Here we use an equation from probability theory to describe the
uncertainty of Leonard's monthly returns; we leave the proof of this
method to a dedicated probability course. The variance of a linear
combination of random variables can be computed by plugging in the
variances of the individual random variables and squaring the
coefficients of the random variables: $$\begin{aligned}
Var(aX + bY) = a^2\times Var(X) + b^2\times Var(Y)\end{aligned}$$ It is
important to note that this equality assumes the random variables are
independent; if independence doesn't hold, then more advanced methods
are necessary. This equation can be used to compute the variance of
Leonard's monthly return: $$\begin{aligned}
Var(6000\times X + 2000\times Y)
    &= 6000^2\times Var(X) + 2000^2\times Var(Y) \\
    &= 36,000,000\times 0.0072 + 4,000,000\times 0.0027 \\
    &= 270,000\end{aligned}$$ The standard deviation is computed as the
square root of the variance: $\sqrt{270,000} = \$520$. While an average
monthly return of \$134 on an \$8000 investment is nothing to scoff at,
the monthly returns are so volatile that Leonard should not expect this
income to be very stable.

**Variability of linear combinations of random variables**

>The variance of a linear combination of random variables may be computed
by squaring the constants, substituting in the variances for the random
variables, and computing the result: $$\begin{aligned}
Var(aX + bY) = a^2\times Var(X) + b^2\times Var(Y)\end{aligned}$$ This
equation is valid as long as the random variables are independent of
each other. The standard deviation of the linear combination may be
found by taking the square root of the variance.

**Example**

Suppose John's daily commute has a standard deviation of 4 minutes. What
is the uncertainty in his total commute time for the week
 

The expression for John's commute
time was $$\begin{aligned}
X_1 + X_2 + X_3 + X_4 + X_5\end{aligned}$$ Each coefficient is 1, and
the variance of each day's time is $4^2=16$. Thus, the variance of the
total weekly commute time is $$\begin{aligned}
&\text{variance }= 1^2 \times  16 + 1^2 \times  16 + 1^2 \times  16 + 1^2 \times  16 + 1^2 \times  16 = 5\times 16 = 80 \\
&\text{standard deviation } = \sqrt{\text{variance}} = \sqrt{80} = 8.94\end{aligned}$$
The standard deviation for John's weekly work commute time is about 9
minutes.


The negative coefficient for $Y$ in the linear combination was
eliminated when we squared the coefficients. This generally holds true:
negatives in a linear combination will have no impact on the variability
computed for a linear combination, but they do impact the expected value
computations.

## Statistical Background {#appendixA}

```{r setup_appA, include=FALSE}
chap <- "A"
lc <- 0
rq <- 0
# **`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`**
# **`r paste0("(RQ", chap, ".", (rq <- rq + 1), ")")`**

knitr::opts_chunk$set(
  tidy = FALSE, 
  out.width = '\\textwidth', 
  fig.height = 4,
  warning = FALSE
)

options(scipen = 99, digits = 3)

# Set random number generator see value for replicable pseudorandomness.
set.seed(76)
```

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# Packages needed internally, but not in text.
library(scales)
library(tidyverse)
```


## Basic statistical terms {#appendix-stat-terms}

Note that all the following statistical terms apply only to *numerical* variables, except the *distribution* which can exist for both numerical and categorical variables. 

### Mean

The *mean* is the most commonly reported measure of center.  It is commonly called the *average* though this term can be a little ambiguous.  The mean is the sum of all of the data elements divided by how many elements there are. If we have $n$ data points, the mean is given by: 

$$Mean = \frac{x_1 + x_2 + \cdots + x_n}{n}$$

### Median

The median is calculated by first sorting a variable's data from smallest to largest.  After sorting the data, the middle element in the list is the *median*.  If the middle falls between two values, then the median is the mean of those two middle values.

### Standard deviation

We will next discuss the *standard deviation* ($sd$) of a variable.  The formula can be a little intimidating at first but it is important to remember that it is essentially a measure of how far we expect a given data value will be from its mean:

$$sd = \sqrt{\frac{(x_1 - Mean)^2 + (x_2 - Mean)^2 + \cdots + (x_n - Mean)^2}{n - 1}}$$

### Five-number summary

The *five-number summary* consists of five summary statistics: the minimum, the first quantile AKA 25th percentile, the second quantile AKA median or 50th percentile, the third quantile AKA 75th, and the maximum. The five-number summary of a variable is used when constructing boxplots, as seen in Section \@ref(boxplots).

The quantiles are calculated as

- first quantile ($Q_1$): the median of the first half of the sorted data
- third quantile ($Q_3$): the median of the second half of the sorted data

The *interquartile range (IQR)*\index{interquartile range (IQR)} is defined as $Q_3 - Q_1$ and is a measure of how spread out the middle 50% of values are. The IQR corresponds to the length of the box in a boxplot.

The median and the IQR are not influenced by the presence of outliers in the ways that the mean and standard deviation are. They are, thus, recommended for skewed datasets. We say in this case that the median and IQR are more *robust to outliers*.

### Distribution

The *distribution* of a variable shows how frequently different values of a variable occur. Looking at the visualization of a distribution can show where the values are centered, show how the values vary, and give some information about where a typical value might fall.  It can also alert you to the presence of outliers. 

Recall from Chapter \@ref(viz) that we can visualize the distribution of a numerical variable using binning in a histogram and that we can visualize the distribution of a categorical variable using a barplot.


### Outliers

*Outliers* correspond to values in the dataset that fall far outside the range of "ordinary" values.  In the context of a boxplot, by default they correspond to values below $Q_1 - (1.5 \cdot IQR)$ or above $Q_3 + (1.5 \cdot IQR)$.




## Normal distribution {#appendix-normal-curve}

Let's next discuss one particular kind of distribution: \index{distribution!normal} *normal distributions*. Such bell-shaped distributions are defined by two values: (1) the *mean* $\mu$ ("mu") which locates the center of the distribution and (2) the *standard deviation* $\sigma$ ("sigma") which determines the variation of the distribution. In Figure \@ref(fig:normal-curves), we plot three normal distributions where:

1. The solid normal curve has mean $\mu = 5$ \& standard deviation $\sigma = 2$.
1. The dotted normal curve has mean $\mu = 5$ \& standard deviation $\sigma = 5$.
1. The dashed normal curve has mean $\mu = 15$ \& standard deviation $\sigma = 2$.

```{r normal-curves, echo=FALSE, fig.cap="Three normal distributions.", purl=FALSE, out.width="90%"}
all_points <- tibble(
  domain = seq(from = -10, to = 25, by = 0.01),
  `mu = 5, sigma = 2` = dnorm(x = domain, mean = 5, sd = 2),
  `mu = 5, sigma = 5` = dnorm(x = domain, mean = 5, sd = 5),
  `mu = 15, sigma = 2` = dnorm(x = domain, mean = 15, sd = 2)
)  %>% 
  gather(key = "Distribution", value = "value", - domain) %>% 
  mutate(
    Distribution = factor(
      Distribution, 
      levels = c("mu = 5, sigma = 2", 
                 "mu = 5, sigma = 5", 
                 "mu = 15, sigma = 2")
    )
  )

for_labels <- all_points %>% 
  filter(between(domain, 3.795, 3.805) & Distribution == "mu = 5, sigma = 2" |
           between(domain, 0.005, 0.0105) & Distribution == "mu = 5, sigma = 5" |
           between(domain, 16.005, 16.015) & Distribution == "mu = 15, sigma = 2")

all_points %>% 
  ggplot(aes(x = domain, y = value, linetype = Distribution)) +
  geom_line() +
  ggrepel::geom_label_repel(data = for_labels, aes(label = Distribution),
                            nudge_x = c(-1, -2.1, 1)) +
  theme_light() +
  scale_linetype_manual(values=c("solid", "dotted", "longdash")) + 
  theme(
    axis.title.y = element_blank(),
    axis.title.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    legend.position = "none"
  )
```

Notice how the solid and dotted line normal curves have the same center due to their common mean $\mu$ = 5. However, the dotted line normal curve is wider due to its larger standard deviation of $\sigma$ = 5. On the other hand, the solid and dashed line normal curves have the same variation due to their common standard deviation $\sigma$ = 2. However, they are centered at different locations. 

When the mean $\mu$ = 0 and the standard deviation $\sigma$ = 1, the normal distribution has a special name. It's called the *standard normal distribution* or the *$z$-curve*\index{distribution!standard normal}.

Furthermore, if a variable follows a normal curve, there are *three rules of thumb* we can use:

1. 68% of values will lie within $\pm$ 1 standard deviation of the mean.
1. 95% of values will lie within $\pm$ 1.96 $\approx$ 2 standard deviations of the mean.
1. 99.7% of values will lie within $\pm$ 3 standard deviations of the mean.

Let's illustrate this on a standard normal curve in Figure \@ref(fig:normal-rule-of-thumb). The dashed lines are at -3, -1.96, -1, 0, 1, 1.96, and 3. These 7 lines cut up the x-axis into 8 segments. The areas under the normal curve for each of the 8 segments are marked and add up to 100%. For example:

1. The middle two segments represent the interval -1 to 1. The shaded area above this interval represents 34% + 34% = 68% of the area under the curve. In other words, 68% of values. 
1. The middle four segments represent the interval -1.96 to 1.96. The shaded area above this interval represents 13.5% + 34% + 34% + 13.5%= 95% of the area under the curve. In other words, 95% of values. 
1. The middle six segments represent the interval -3 to 3. The shaded area above this interval represents 2.35% + 13.5% + 34% + 34% + 13.5% + 2.35% = 99.7% of the area under the curve. In other words, 99.7% of values. 

```{r normal-rule-of-thumb, echo=FALSE, fig.cap="Rules of thumb about areas under normal curves.", purl=FALSE, out.width = "80%"}
shade_3_sd <- function(x) {
  y <- dnorm(x, mean = 0, sd = 1)
  y[x <= -3 | x >= 3] <- NA
  return(y)
}
shade_2_sd <- function(x) {
  y <- dnorm(x, mean = 0, sd = 1)
  y[x <= -1.96 | x >= 1.96] <- NA
  return(y)
}
shade_1_sd <- function(x) {
  y <- dnorm(x, mean = 0, sd = 1)
  y[x <= -1 | x >= 1] <- NA
  return(y)
}

labels <- tibble(
  x = c(-3.5, -2.5, -1.5, -0.5, 0.5, 1.5, 2.5, 3.5),
  label = c("0.15%", "2.35%", "13.5%", "34%", "34%", "13.5%", "2.35%", "0.15%")
) %>% 
  mutate(y = rep(0.3, times = n()))

ggplot(data = tibble(x = c(-4, 4)), aes(x)) +
  geom_text(data = labels, aes(y=y, label = label)) + 
  # Trace normal curve
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1), n = 1000) + 
  # Shade and delineate +/- 3 SD
  stat_function(fun = shade_3_sd, geom = "area", fill = "black", alpha = 0.25, n = 1000) +
  # annotate(geom = "segment", x = c(3, -3), xend = c(3, -3), y = 0, yend = dnorm(3, mean = 0, sd = 1)) +
  # Shade and delineate +/- 2 SD
  stat_function(fun = shade_2_sd, geom = "area", fill = "black", alpha = 0.25, n = 1000) +
  # annotate(geom = "segment", x = c(1.96, -1.96), xend = c(1.96, -1.96), y = 0, yend = dnorm(1.96, mean = 0, sd = 1)) +
  # Shade and delineate +/- 1 SD
  stat_function(fun = shade_1_sd, geom = "area", fill = "black", alpha = 0.25, n = 1000) +
  # annotate(geom = "segment", x = c(1, -1), xend = c(1, -1), y = 0, yend = dnorm(1, mean = 0, sd = 1)) + 
  geom_vline(xintercept = c(-3, -1.96, -1, 0, 1, 1.96, 3), linetype = "dashed", alpha = 0.5) +
  # Axes
  scale_x_continuous(breaks = seq(from = -3, to = 3, by = 1)) +
  labs(x = "z", y = "") +
  theme(axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank())
```

\vspace{0.1in}

```{block, type='learncheck', purl=FALSE}
\vspace{-0.15in}
**_Learning check_**
\vspace{-0.1in}
```

<!--
Consider LC using this later on: <https://gallery.shinyapps.io/dist_calc/>
-->

Say you have a normal distribution with mean $\mu = 6$ and standard deviation $\sigma = 3$. 

**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** What proportion of the area under the normal curve is less than 3? Greater than 12? Between 0 and 12?

**`r paste0("(LC", chap, ".", (lc <- lc + 1), ")")`** What is the 2.5th percentile of the area under the normal curve? The 95th percentile? The 100th percentile?


```{block, type='learncheck', purl=FALSE}
\vspace{-0.25in}
\vspace{-0.25in}
```

\vspace{0.1in}

## log10 transformations {#appendix-log10-transformations}

At its simplest, log10 transformations return base 10 *logarithms*. For example, since $1000 = 10^3$, running `log10(1000)` returns `3` in R. To undo a log10 transformation, we raise 10 to this value. For example, to undo the previous log10 transformation and return the original value of 1000, we raise 10 to the power of 3 by running `10^(3) = 1000` in R. \index{log transformations}

Log transformations allow us to focus on changes in *orders of magnitude*. In other words, they allow us to focus on *multiplicative changes* instead of *additive ones*. Let's illustrate this idea in Table \@ref(tab:logten) with examples of prices of consumer goods in 2019 US dollars. 

<!--
We can also frame such changes as being relative percentage increases/decreases instead of absolute increases/decreases. 
-->

```{r logten, echo=FALSE}
tibble(Price = c(1,10,100,1000,10000,100000,1000000)) %>% 
  mutate(
    `log10(Price)` = log10(Price),
    Price = dollar(Price),
    `Order of magnitude` = c("Singles", "Tens", "Hundreds", "Thousands", "Tens of thousands", "Hundreds of thousands", "Millions"),
    `Examples` = c("Cups of coffee", "Books", "Mobile phones", "High definition TVs", "Cars", "Luxury cars and houses", "Luxury houses")
  ) %>% 
  knitr::kable(
    digits = 3, 
    caption = "log10 transformed prices, orders of magnitude, and examples", 
    booktabs = TRUE,
    linesep = ""
  ) 
```

Let's make some remarks about log10 transformations based on Table \@ref(tab:logten):

1. When purchasing a cup of coffee, we tend to think of prices ranging in single dollars, such as \$2 or \$3. However, when purchasing a mobile phone, we don't tend to think of their prices in units of single dollars such as \$313 or \$727. Instead, we tend to think of their prices in units of hundreds of dollars like \$300 or \$700. Thus, cups of coffee and mobile phones are of different *orders of magnitude* in price.
1. Let's say we want to know the log10 transformed value of \$76. This would be hard to compute exactly without a calculator. However, since \$76 is between \$10 and \$100 and since log10(10) = 1 and log10(100) = 2, we know log10(76) will be between 1 and 2. In fact, log10(76) is 1.880814.
1. log10 transformations are *monotonic*, meaning they preserve orders. So if Price A is lower than Price B, then log10(Price A) will also be lower than log10(Price B).
1. Most importantly, increments of one in log10-scale correspond to *relative multiplicative changes* in the original scale and not *absolute additive changes*. For example, increasing a log10(Price) from 3 to 4 corresponds to a multiplicative increase by a factor of 10: \$100 to \$1000.



[^1]: Here are four examples. (i) Whether someone gets sick in the next
    month or not is an apparently random process with outcomes *sick*
    and *not*. (ii) We can *generate* a random process by randomly
    picking a person and measuring that person's height. The outcome of
    this process will be a positive number. (iii) Whether the stock
    market goes up or down next week is a seemingly random process with
    possible outcomes *up*, *down*, and *no\_change*. Alternatively, we
    could have used the percent change in the stock market as a
    numerical outcome. (iv) Whether your roommate cleans her dishes
    tonight probably seems like a random process with possible outcomes
    *cleans\_dishes* and *leaves\_dishes*.

[^2]: () The random process is a die roll, and at most one of these
    outcomes can come up. This means they are disjoint outcomes.
    (b) $P($*1* or *4* or
    *5*$) = P($*1*$)+P($*4*$)+P($*5*$) = \frac{1}{6} + \frac{1}{6} + \frac{1}{6} = \frac{3}{6} = \frac{1}{2}$

[^3]: (a) Yes. Each email is categorized in only one level of . (b)
    Small: $\frac{2827}{3921} = 0.721$. Big: $\frac{545}{3921} = 0.139$.
    (c) $P($*small* or
    *big*$) = P($*small*$) + P($*big*$) = 0.721 + 0.139 = 0.860$.

[^4]: (a) $P(A) = P($*1* or
    *2*$) = P($*1*$) + P($*2*$) = \frac{1}{6} + \frac{1}{6} = \frac{2}{6} = \frac{1}{3}$.
    (b) Similarly, $P(B) = 1/3$.

[^5]: (a) Outcomes *2* and *3*. (b) Yes, events $B$ and $D$ are disjoint
    because they share no outcomes. (c) The events $A$ and $D$ share an
    outcome in common, *2*, and so are not disjoint.

[^6]: Since $B$ and $D$ are disjoint events, use the Addition Rule:
    $P(B$ or
    $D) = P(B) + P(D) = \frac{1}{3} + \frac{1}{3} = \frac{2}{3}$.

[^7]: The 52 cards are split into four : $\clubsuit$ (club),
    $\diamondsuit$ (diamond), $\heartsuit$ (heart), $\spadesuit$
    (spade). Each suit has its 13 cards labeled: *2*, *3*, \..., *10*,
    *J* (jack), *Q* (queen), *K* (king), and *A* (ace). Thus, each card
    is a unique combination of a suit and a label, e.g. *4$\heartsuit$*
    and *J$\clubsuit$*. The 12 cards represented by the jacks, queens,
    and kings are called . The cards that are $\diamondsuit$ or
    $\heartsuit$ are typically colored red while the other two suits are
    typically colored black.

[^8]: (a) There are 52 cards and 13 diamonds. If the cards are
    thoroughly shuffled, each card has an equal chance of being drawn,
    so the probability that a randomly selected card is a diamond is
    $P({\color{redcards}\diamondsuit}) = \frac{13}{52} = 0.250$.
    (b) Likewise, there are 12 face cards, so $P($face
    card$) = \frac{12}{52} = \frac{3}{13} = 0.231$.

[^9]: The Venn diagram shows face cards split up into "face card but not
    $\diamondsuit$" and "face card and $\diamondsuit$". Since these
    correspond to disjoint events, $P($face card$)$ is found by adding
    the two corresponding probabilities:
    $\frac{3}{52} + \frac{9}{52} = \frac{12}{52} = \frac{3}{13}$.

[^10]: (a) If $A$ and $B$ are disjoint, $A$ and $B$ can never occur
    simultaneously. (b) If $A$ and $B$ are disjoint, then the last term
    of
    Equation ({reference-type="ref"
    reference="generalAdditionRule"}) is 0 (see part (a)) and we are
    left with the Addition Rule for disjoint events.

[^11]: Both the counts and corresponding probabilities (e.g.
    $2659/3921 = 0.678$) are shown. Notice that the number of emails
    represented in the left circle corresponds to $2659 + 168 = 2827$,
    and the number represented in the right circle is $168 + 199 = 367$.

     

    ![image](images/emailSpamNumberVenn.png){height="13mm"}

[^12]: (a) The solution is represented by the intersection of the two
    circles: 0.043. (b) This is the sum of the three disjoint
    probabilities shown in the circles: $0.678 + 0.043 + 0.051 = 0.772$.

[^13]: The probabilities of (a) do not sum to 1. The second probability
    in (b) is negative. This leaves (c), which sure enough satisfies the
    requirements of a distribution. One of the three was said to be the
    actual distribution of US household incomes, so it must be (c).

[^14]: It is also possible to construct a distribution plot when income
    is not artificially binned into four groups.

[^15]: (a) The outcomes are disjoint and each has probability $1/6$, so
    the total probability is $4/6=2/3$. (b) We can also see that
    $P(D)=\frac{1}{6} + \frac{1}{6} = 1/3$. Since $D$ and $D^c$ are
    disjoint, $P(D) + P(D^c) = 1$.

[^16]: Brief solutions: (a) $A^c=\{$*3*, *4*, *5*, *6*$\}$ and
    $B^c=\{$*1*, *2*, *3*, *5*$\}$. (b) Noting that each outcome is
    disjoint, add the individual outcome probabilities to get
    $P(A^c)=2/3$ and $P(B^c)=2/3$. (c) $A$ and $A^c$ are disjoint, and
    the same is true of $B$ and $B^c$. Therefore, $P(A) + P(A^c) = 1$
    and $P(B) + P(B^c) = 1$.

[^17]: (a) The complement of $A$: when the total is equal to *12*.
    (b) $P(A^c) = 1/36$. (c) Use the probability of the complement from
    part (b), $P(A^c) = 1/36$, and
    Equation ({reference-type="ref"
    reference="complement"}): $P($less than
    *12*$) = 1 - P($*12*$) = 1 - 1/36 = 35/36$.

[^18]: (a) First find $P($*6*$)=5/36$, then use the complement: $P($not
    *6*$) = 1 - P($*6*$) = 31/36$. (b) First find the complement, which
    requires much less effort: $P($*2* or *3*$)=1/36+2/36=1/12$. Then
    calculate $P(B) = 1-P(B^c) = 1-1/12 = 11/12$. (c) As before, finding
    the complement is the clever way to determine $P(D)$. First find
    $P(D^c) = P($*11* or *12*$)=2/36 + 1/36=1/12$. Then calculate
    $P(D) = 1 - P(D^c) = 11/12$.

[^19]: (a) The probability the first person is left-handed is $0.09$,
    which is the same for the second person. We apply the Multiplication
    Rule for independent processes to determine the probability that
    both will be left-handed: $0.09\times 0.09 = 0.0081$.

    (b) It is reasonable to assume the proportion of people who are
    ambidextrous (both right and left handed) is nearly 0, which results
    in $P($right-handed$)=1-0.09=0.91$. Using the same reasoning as in
    part (a), the probability that both will be right-handed is
    $0.91\times 0.91 = 0.8281$.

[^20]: (a) The abbreviations *RH* and *LH* are used for right-handed and
    left-handed, respectively. Since each are independent, we apply the
    Multiplication Rule for independent processes: $$\begin{aligned}
    P(\text{all five are RH})
    &= P(\text{first = RH, second = RH, ..., fifth = RH}) \\
    &= P(\text{first = RH})\times P(\text{second = RH})\times  \dots \times P(\text{fifth = RH}) \\
    &= 0.91\times 0.91\times 0.91\times 0.91\times 0.91 = 0.624\end{aligned}$$

    (b) Using the same reasoning as in (a),
    $0.09\times 0.09\times 0.09\times 0.09\times 0.09 = 0.0000059$

    (c) Use the complement, $P($all five are *RH*$)$, to answer this
    question: $$\begin{aligned}
    P(\text{not all RH})
        = 1 - P(\text{all RH})
        = 1 - 0.624 = 0.376\end{aligned}$$

[^21]: The actual proportion of the U.S. population that is *female* is
    about 50%, and so we use 0.5 for the probability of sampling a
    woman. However, this probability does differ in other countries.

[^22]: Brief answers are provided. (a) This can be written in
    probability notation as $P($a randomly selected person is male and
    right-handed$)=0.455$. (b) 0.207. (c) 0.045. (d) 0.0093.

[^23]: Ellis GJ and Stone LH. 1979. Marijuana Use in College: An
    Evaluation of a Modeling Explanation. Youth and Society 10:323-334.

[^24]: Each of the four outcome combination are disjoint, all
    probabilities are indeed non-negative, and the sum of the
    probabilities is $0.28 + 0.19 + 0.21 + 0.32 = 1.00$.

[^25]: This is an observational study and no causal conclusions may be
    reached.

[^26]: (a)
    $P(\text{parent = not} | \text{student = not})$.
    (b) Equation ({reference-type="ref"
    reference="condProbEq"}) for conditional probability indicates we
    should first find
    $P(\text{parents = not and student = not})=0.32$
    and $P(\text{student = not})=0.51$. Then the ratio
    represents the conditional probability: $0.32/0.51 = 0.63$.

[^27]: (a) This probability is
    $\frac{P(\text{parents = used and student = not})}{P(\text{student = not})} = \frac{0.19}{0.51} = 0.37$.
    (b) The total equals 1. (c) Under the condition the student does not
    use drugs, the parents must either use drugs or not. The complement
    still appears to work *when conditioning on the same information*.

[^28]: No. This was an observational study. Two potential confounding
    variables include and . Can you think of others
 


[^29]: Fenner F. 1988. *Smallpox and Its Eradication (History of
    International Public Health, No. 6)*. Geneva: World Health
    Organization. ISBN 92-4-156110-6.

[^30]: $P($ = *died* $|$ =
    *no*$) = \frac{P(\text{result = died and inoculated = no})}{P(\text{inoculated = no})} = \frac{0.1356}{0.9608} = 0.1411$.

[^31]: $P($ = *died* $|$ =
    *yes*$) = \frac{P(\text{result = died and inoculated = yes})}{P(\text{inoculated = yes})} = \frac{0.0010}{0.0392} = 0.0255$.
    The death rate for individuals who were inoculated is only about
    1 in 40 while the death rate is about 1 in 7 for those who were not
    inoculated.

[^32]: Brief answers: (a) Observational. (b) No, we cannot infer
    causation from this observational study. (c) Accessibility to the
    latest and best medical care. There are other valid answers for
    part (c).

[^33]: The answer is 0.0382.

[^34]: There were only two possible outcomes: *lived* or *died*. This
    means that 100% - 97.45% = 2.55% of the people who were inoculated
    died.

[^35]: The samples are large relative to the difference in death rates
    for the "inoculated" and "not inoculated" groups, so it seems there
    is an association between and . However, as noted in the solution to
    Guided
    Practice, this is an
    observational study and we cannot be sure if there is a causal
    connection. (Further research has shown that inoculation is
    effective at reducing death rates.)

[^36]: Brief solutions: (a) $1/6$. (b) $1/36$.
    (c) $\frac{P(Y = \text{ 1 and }X=\text{ 1})}{P(X=\text{ 1})} = \frac{1/36}{1/6} = 1/6$.
    (d) The probability is the same as in part (c): $P(Y=1)=1/6$. The
    probability that $Y=1$ was unchanged by knowledge about $X$, which
    makes sense as $X$ and $Y$ are independent.

[^37]: He has forgotten that the next roulette spin is independent of
    the previous spins. Casinos do employ this practice; they post the
    last several outcomes of many betting games to trick unsuspecting
    gamblers into believing the odds are in their favor. This is called
    the .

[^38]: (a) The tree diagram is shown to the right. (b) Identify which
    two joint probabilities represent students who passed, and add them:
    $P($passed$) = 0.7566+0.1254= 0.8820$. (c) $P($construct tree
    diagram $|$ passed$) = \frac{0.7566}{0.8820} = 0.8578$.\
     

    ![image](images/treeDiagramAndPass.png){width="\\textwidth"}

[^39]: If they sell a little more or a little less, this should not be a
    surprise. For example, if we would flip
    a coin 100 times, it will not usually come up heads exactly half the
    time, but it will probably be close.

[^40]: $\mu = \int xf(x)dx$ where $f(x)$ represents a function for the
    density curve.

[^41]: (a) 100% - 25% - 60% = 15% of students do not buy any books for
    the class. Part (b) is represented by the first two lines in the
    table below. The expectation for part (c) is given as the total on
    the line $y_i\times P(Y=y_i)$. The result of part (d) is the
    square-root of the variance listed on in the total on the last line:
    $\sigma = \sqrt{Var(Y)} = \$69.28$.

                   $i$ (scenario)   1 (*noBook*)   2 (*textbook*)   3 (*both*)                   Total
      --------------------------- -------------- ---------------- ------------ -----------------------
                            $y_i$           0.00           159.00       200.00 
                       $P(Y=y_i)$           0.15             0.25         0.60 
             $y_i\times P(Y=y_i)$           0.00            39.75       120.00         $E(Y) = 159.75$
                       $y_i-E(Y)$        -159.75            -0.75        40.25 
                   $(y_i-E(Y))^2$       25520.06             0.56      1620.06 
        $(y_i-E(Y))^2\times P(Y)$         3828.0              0.1        972.0   $Var(Y) \approx 4800$

[^42]: She will make $X$ dollars on the TV but spend $Y$ dollars on the
    toaster oven: $X-Y$.

[^43]: $E(X-Y) = E(X) - E(Y) = 175 - 23 = \$152$. She should expect to
    make about \$152.

[^44]: No, since there is probably some variability. For example, the
    traffic will vary from one day to next, and auction prices will vary
    depending on the quality of the merchandise and the interest of the
    attendees.

[^45]: If $X$ and $Y$ are random variables, consider the following
    combinations: $X^{1+Y}$, $X\times Y$, $X/Y$. In such cases, plugging
    in the average value for each random variable and computing the
    result will not generally lead to an accurate average value for the
    end result.

[^46]: $E(\$6000\times X + \$2000\times Y) = \$6000\times 0.021 + \$2000\times 0.004 = \$134$.

[^47]: No. While stocks tend to rise over time, they are often volatile
    in the short term.

[^48]: One concern is whether traffic patterns tend to have a weekly
    cycle (e.g. Fridays may be worse than other days). If that is the
    case, and John drives, then the assumption is probably not
    reasonable. However, if John walks to work, then his commute is
    probably not affected by any weekly traffic cycle.

[^49]: The equation for Elena can be written as $$\begin{aligned}
    (1)\times X + (-1)\times Y\end{aligned}$$ The variances of $X$ and
    $Y$ are 625 and 64. We square the coefficients and plug in the
    variances: $$\begin{aligned}
    (1)^2\times Var(X) + (-1)^2\times Var(Y) = 1\times 625 + 1\times 64 = 689\end{aligned}$$
    The variance of the linear combination is 689, and the standard
    deviation is the square root of 689: about \$26.25.
