<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 5 Probability | Gov 50: Data" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="davidkane9/PPBDS" />



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Chapter 5 Probability | Gov 50: Data">

<title>Chapter 5 Probability | Gov 50: Data</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.0/str_view.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Gov 50: Data<p><p class="author"></p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="index.html"></a>
<a href="preamble.html">Preamble</a>
<a href="shopping-week.html">Shopping Week</a>
<a href="visualization.html"><span class="toc-section-number">1</span> Visualization</a>
<a href="wrangling.html"><span class="toc-section-number">2</span> Wrangling</a>
<a href="rubin-causal-model.html"><span class="toc-section-number">3</span> Rubin Causal Model</a>
<a href="functions.html"><span class="toc-section-number">4</span> Functions</a>
<a id="active-page" href="probability.html"><span class="toc-section-number">5</span> Probability</a><ul class="toc-sections">
<li class="toc"><a href="#probability-distributions"> Probability distributions</a></li>
<li class="toc"><a href="#tree-diagrams"> Tree diagrams</a></li>
<li class="toc"><a href="#two-models"> Two models</a></li>
<li class="toc"><a href="#three-models"> Three models</a></li>
<li class="toc"><a href="#n-models"> N models</a></li>
<li class="toc"><a href="#posterior-distribution"> Posterior distribution</a></li>
<li class="toc"><a href="#predictions"> Predictions</a></li>
<li class="toc"><a href="#prudence"> Prudence</a></li>
<li class="toc"><a href="#temperance"> Temperance</a></li>
<li class="toc"><a href="#fortitude"> Fortitude</a></li>
<li class="toc"><a href="#justice"> Justice</a></li>
</ul>
<a href="one-parameter.html"><span class="toc-section-number">6</span> One Parameter</a>
<a href="two-parameters.html"><span class="toc-section-number">7</span> Two Parameters</a>
<a href="three-parameters.html"><span class="toc-section-number">8</span> Three Parameters</a>
<a href="n-parameters.html"><span class="toc-section-number">9</span> N Parameters</a>
<a href="pitfalls.html"><span class="toc-section-number">10</span> Pitfalls</a>
<a href="continuous-response.html"><span class="toc-section-number">11</span> Continuous Response</a>
<a href="discrete-response.html"><span class="toc-section-number">12</span> Discrete Response</a>
<a href="appendices.html">Appendices</a>
<a href="tools.html">Tools</a>
<a href="shiny.html">Shiny</a>
<a href="maps.html">Maps</a>
<a href="animation.html">Animation</a>
<a href="references.html">References</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="probability" class="section level1">
<h1>
<span class="header-section-number">Chapter 5</span> Probability</h1>
<!-- 1) Make rayshader.R. Creates all images and animations, places them in either images or animations folder. Lots of info and advice for whomever needs to work with this later. ->


<!-- Add Four Cardinal Virtues section at end, with a subsection about each virtue, with the image, just like Cass.  -->
<!-- Parameter means no parathesis. Anytime you talk about a specific p, you must add a subscript, otherwise how do you know what you are talking about. But, at the same time, it is annoying to write long subscripts, like $p_{Bidengets370electorvotes}$, so it is better to just come up with a short subscript, like $p_370$, where the context makes clear what this refers to. -->
<!-- probability distribution means you must have parentheses.  -->
<!-- When discussing a parameter $p$ and a probability distribution p() in the absence of a specific context, then those simple terms are OK. But, whenever you are talking about specific parameters or specific probability distributions, you should have either subscripts or items in the paratheses, respectively.  -->
<!-- $p_h$ is the probability of heads. -->
<!-- p(coin) is the probability distribution of all the outcomes associated with coin.  -->
<!-- p($p_h$) is the probability distribution (because of p()) of the probability of a head.  -->
<!-- p(models I am considering, results of experiment which I might get) -->
<!-- p($p_h$ | heads = 8) -->
<!-- 6) More animations.  -->
<!-- Other Stuff -->
<!-- DK: We need a single example of a continuous distribution after Electoral Votes. It will also have math. And empirical. And posterior. -->
<!-- Zoom with Tahmid and make sure that he understands the posterior distribution and that you agree with how he describes the posterior distribution in chapter 7. Will students understand his description, even though the last time they thought about this was two weeks earlier in your chapter. -->
<!-- Key references. Make sure to cite all three as separate side notes. But, at the same time, don't feel compelled to do things the way that they did them. -->
<!-- 2) Teaching Bayes' Rule: A Data-Oriented Approach by Jim Albert. The key concept is Bayes Scatterplots. That is the central graphic of this chapter. We will show such a scatterplot four or five times, each time more complex, each time showing marginal distributions in both directions. -->
<!-- 3) Rethinking Chapter 2. Garden of forking data is just excellent stuff.  -->
<!-- Open Questions: -->
<!-- Use some STAT 110 midterm questions as example problems which simulation makes easy to solve. Maybe? At least in the first section? https://projects.iq.harvard.edu/files/stat110/files/midterm_exam.pdf -->
<!-- Class Exercises -->
<!-- a) Workshop Statistics has nice dice and coin examples. Perhaps use those in lecture? -->
<!-- b) Two buckets, each with different pair of die in them: one normal, one weird. You pick a bucket, then roll the die. Q: What are the odds of bucket 1 versus bucket 2? Start with dice function. Then build tibble as in the cookie problem. That takes a day, especially if we build the result by-hand, meaning pivot_wider and summing columns, as we should. Then, day 2, place a prior on the two buckets. Then, what if we through the dice more than once? This will be a list column. Scary! But all the other arguments go through. (I think!) Then, discuss continuous example of a coin, setting the stage for problem set question. -->
<!-- c) Do a dice example where students each have their own priors and then we update after rolling dice, some fake or real. Do it with counts, not proportions.  -->
<!-- d) Might a Bayesian power discussion, as in Kruscke article, be a useful problem set? Ties into the usage of fake data. Good way to introduce/teach type M and S errors? -->
<p>The central tension, and opportunity, in data science is the interplay between the <em>data</em> and the <em>science</em>, between our empirical observations and the models which we use to understand them. Probability is the language we use to explore that interplay; it connects models to data, and data to models.</p>
<div id="probability-distributions" class="section level2">
<h2>
<span class="header-section-number">5.1</span> Probability distributions</h2>
<!-- Read Topic 14 in Bayesian Workshop. Lots of interesting ideas and examples there for this first section of the chapter. Any coding examples should be simple, with  no list-columns and map_* functions. Basic tool we are introducing is doing simulation within a tibble. Consider doing some of the sample problems from STAT 110, many of which are hard to do analytically but easy to do with simulation. -->
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-480"></span>
<img src="05-probability/images/probability_dice.jpeg" alt="Dice and Probability." width="286"><!--
<p class="caption marginnote">-->FIGURE 5.1: Dice and Probability.<!--</p>-->
<!--</div>--></span>
</p>
<p>What does it mean that Trump has a <em>30% chance</em> of winning re-election this fall? That there is a <em>90% probability</em> of rain today? That the die at the casino is <em>unfair</em>? If I roll that die 10 times and five of those times I get a three, how likely is it that the die is <em>unfair</em>?</p>
<p>Probability is about quantifying uncertainty. We can think of probability as a proportion. The probability of an event occurring is a number from 0 to 1, where 1 means that the event is 100% certain.</p>
<p>Let’s begin with the simplest events: coin flips and dice rolls. If the die and
the coins are fair, we can operate under the assumption that all outcomes are
equally likely.</p>
<p>This allows us to make the following statements:</p>
<!-- What kind of notation should I use for these bullet points? -->
<ul>
<li>The probability of rolling a 1 or 2 is 2/6, or 1/3.</li>
<li>The probability of rolling a 1, 2, 3, 4, 5, or 6 is 1.<br>
</li>
<li>The probability of flipping a coin and getting tails is 1/2.</li>
</ul>
<p>For the purposes of this course, a <em>probability distribution</em> is a mathematical object that covers a set of outcomes, where each distinct outcome has a chance of occurring between 0 and 1 inclusive. The set of possible outcomes — heads or tails for the coin, 1 through 6 for the die — can be either discrete or continuous. This set of outcomes is the <em>domain</em> of the probability distribution. There are three types of probability distributions: mathematical, empirical, and posterior. Let’s walk through some examples to better understand each type of probability distribution.</p>
<p>Before we continue, we should be familiar with the notation used in this chapter. Whenever we are talking about a specific probability (represented by a single value), we will use <span class="math inline">\(p\)</span> with a <em>subscript</em>. For instance, <span class="math inline">\(p_h\)</span> = 0.5 denotes the probability of getting heads on a coin toss when the coin is fair. <span class="math inline">\(p_t\)</span> denotes the probability of getting tails on the coin toss. However, when we are referring to the entire probability distribution over a set of outcomes, we will use <span class="math inline">\(p\)</span> with <em>parentheses</em>. For example, the probability distribution of a coin toss is <span class="math inline">\(p(coin)\)</span>. That said, <span class="math inline">\(p(coin)\)</span> is composed of all the two specific probabilities mapped from the domain.</p>
<div id="flipping-a-coin" class="section level3">
<h3>
<span class="header-section-number">5.1.1</span> Flipping a coin</h3>
<p>A <em>mathematical distribution</em> is based on mathematical formulas. Assuming that the dice is perfectly fair, we should get heads as many times as we get tails.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-481-1.png" width="672"></p>
<p>An <em>empirical distribution</em> is based on data. You can think of this as the probability distribution created by running a simulation. In theory, if we increase the number of coins we flip in our simulation, the empirical distribution will look more and more similar to the mathematical distribution. The probability distribution is the Platonic form. The empirical distribution will often look like the mathematical probability distribution, but it will rarely be exactly the same.</p>
<p>In this simulation, there are 49 heads and 51 tails. The outcome will vary every time we run the simulation, but the proportion of heads to tails should not be too different if this coin is fair.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-482-1.png" width="672"></p>
<p>An <em>posterior distribution</em> is based on beliefs and expectations. It displays your belief about things you can’t see right now. You may have posterior distributions for events in the past, present, or future.</p>
<p>In the case of the coin toss, the posterior distribution changes depending on your beliefs. For instance, let’s say your friend brought a coin to school and asked to bet you. If the result is heads, you have to pay them $5.</p>
<p>This makes you suspicious; your posterior distribution would reflect this. You might believe that <span class="math inline">\(p_h\)</span> is 0.95 while <span class="math inline">\(p_t\)</span> is 0.05.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-483-1.png" width="672"></p>
</div>
<div id="rolling-two-die" class="section level3">
<h3>
<span class="header-section-number">5.1.2</span> Rolling two die</h3>
<p>Our <em>mathematical distribution</em> tells us that, with a fair dice, the probability of getting 1, 2, 3, 4, 5, and 6 are equal: there is a 1/6 chance of each. When we roll two die at the same time and sum the values, the numbers closes to the middle (ex. 6, 7, 8) are more common sums than numbers at the very edge (ex. 2, 12) because there are more combinations of numbers that add up to the middle values.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-484-1.png" width="672"></p>
<p>We get an <em>empirical distribution</em> by running a simulation and rolling two die a hundred times. The result is not identical to the mathematical distribution because of the inherent randomness of the real world. We can observe that the <span class="math inline">\(p_2\)</span> and <span class="math inline">\(p_12\)</span>, which are displayed on the left and right most ends of the distribution, are far lower than the <span class="math inline">\(p_6\)</span>, for example.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-485-1.png" width="672"></p>
<p>The <em>posterior distribution</em> for rolling one dice a hundred depends on your expectations. If you take the dice from your Monopoly set, you have reason to believe that the assumptions underlying the mathematical distribution are true. However, if you walk into a crooked casino and a host asks you to play craps, you might be suspicious. In craps, a come-out roll of 7 and 11 is a “natural” and the you win. You might expect those numbers to occur less often than they would with fair dice. Meanwhile, a come-out roll of 2, 3 is bad for someone betting what’s known as the “Pass line.” You might also expect values like 2 and 3 to occur more frequently. Your posterior distribution might look like this:</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-486-1.png" width="672"></p>
<p>Someone less suspcious of the casina would have a posterior distribution which looks more like the mathematical distribution.</p>
</div>
<div id="presidential-elections" class="section level3">
<h3>
<span class="header-section-number">5.1.3</span> Presidential elections</h3>
<p>Now we let’s say we are building probability distributions for political events, like a presidential election. We want to know the probability that Democratic candidate wins x electoral votes, where x represents the range of possible outcomes from 0 to 538.</p>
<p>It would be incredibly naive to create the following <em>mathematical distribution</em>. We create a distribution by running a simulation 10,000 times, where the chances of the Democratic candidate winning any given state is 0.5.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-487-1.png" width="672"></p>
<p>We know that campaign platforms, donations, charisma, and many other factors will contribute to a candidate’s likeability. Elections are more complicated than coin tosses.</p>
<p>The <em>empirical distribution</em> in this case could involve looking into past elections in the United States and counting the number of electoral votes that the Democrats won in each. For the empirical distribution, we create a tibble with electoral vote results from past elections. Looking at elections since 1964, we can observe that the number of electoral votes that the Democrats received in each one is different. Given that we only have 14 entries, it is difficult to draw conclusions or make predictions based off of this empirical distribution.</p>
<p>However, this model is enough to suggest that the assumptions of the mathematical probability distribution above do not work for electoral votes. The model assumes that the Democrats have a 50% chance of receiving each of the 538 votes. Just looking at the mathematical probability distribution, we can observe that receiving 13 or 17 or 486 votes out of 538 would be extreme and almost impossible under this mathematical model. However, our empirical distribution tells us that those were real election results.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-488-1.png" width="672"></p>
<p>The <em>posterior distribution</em> in the election case is something data scientists devote a lot of time to. The analysts develop algorithms that consider their expectations for each outcome. Consider this generated using data from <em>FiveThirtyEight</em>.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-489-1.png" width="672"></p>
<p>Here is a posterior from the FiveThirtyEight website from August 13, 2020. This was created using the same data as the above distribution, but simply displayed differently. For each electoral result, the height of the bar represents the probability that a given event will occur. However, there is no numbered y-axis telling us what the specific probability of each outcome is.</p>
<p><img src="05-probability/images/fivethirtyeight.png" width="682"></p>
<p>Here is the posterior from <em>The Economist</em>, also from August 13, 2020. This looks confusing at first because the data analysts have chosen to merge the axes for Republican and Democratic electoral votes. We can tell that the Economist is more optimistic about Biden’s odds in the election compared to Trump’s, relative to <em>FiveThirtyEight</em>.</p>
<div class="figure fullwidth">
<img src="05-probability/images/economist_aug13.png" alt=" " width="1161"><p class="caption marginnote shownote">
</p>
</div>
<p>There are many political science questions you could explore with posterior distributions and they can relate to the past, present, and future.</p>
<ul>
<li>Past: How many electoral votes would Hilary Clinton have won if she picked a different VP?</li>
<li>Present: What is the median height of Harvard students?</li>
<li>Future: How many electoral votes will a presidential candidate win?</li>
</ul>
</div>
<div id="unnormalized-distributions" class="section level3">
<h3>
<span class="header-section-number">5.1.4</span> Unnormalized distributions</h3>
<p>Remember that probability distributions are mathematical objects that cover a set of outcomes, where each outcome in the domain is mapped to a probability value between 0 and 1 inclusive and the sum of all mappings is 1. Sometimes, you may see distributions similar to probability distributions, only the y-axis displays raw counts instead of proportions. Unnormalized distributions are not probability distributions, but it is easy to convert between the two. You simply divide all the outcome counts on the y-axis by the sum of all outcome counts to “normalize” and unnormalized distribution. Unnormalized distributions are often an intermediary step; it is often handy to work with counts until the very end.</p>
<p>For instance, we can generate the following unnormalized distribution for the sum of rolling two die (empirical distribution from running this simulation 100 times). You may notice that the shape of the distribution is the same as the empirical probability distribution we generated earlier, only the y-axis is labeled differently.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-492-1.png" width="672"></p>
<!-- DK: Add normalized density plot. Comment that they look identical, just scaled. -->
<!-- after_stat("density") -->
</div>
<div id="joint-distributions" class="section level3">
<h3>
<span class="header-section-number">5.1.5</span> Joint distributions</h3>
<!-- DK: Should be p(A). Discuss p(A, B) -->
<p>Now we understand that <span class="math inline">\(p_A\)</span> can represent the probability distribution of outcomes for event A. Let’s talk about joint distributions, which can be represented by <span class="math inline">\(p_{A, B}\)</span>. Joint distributions are also mathematical objects that cover a set of outcomes, where each distinct outcome has a chance of occurring between 0 and 1 and the sum of all chances equals to 1. The key to a joint distribution is it measures the chance that both events A and B will occur simultaneously.</p>
<p>Let’s say that you are rolling two six-sided die simultaneously. One is weighted so that there is a 50% chance of rolling a 6 and a 10% chance of each of the other values. The other is weighted so there is a 50% chance of rolling a 5 and a 10% chance of rolling each of the other values. Let’s roll both die 1000 times. In previous examples involving two die, we cared about the sum of results and not the outcomes of the first versus the second rolls of each simulation. With a joint distributions, the order matters so instead of 11 possible outcomes on the x-axis of our distribution graph (ranging from 2 to 12), we have 36. Furthermore, a 2D probability distribution is not sufficient to represent all of the variables involved, so the joint distribution for this example is displayed using a 3D plot.</p>
<p><img src="05-probability/images/joint.png" width="754"></p>
</div>
</div>
<div id="tree-diagrams" class="section level2">
<h2>
<span class="header-section-number">5.2</span> Tree diagrams</h2>
<div id="independence" class="section level3">
<h3>
<span class="header-section-number">5.2.1</span> Independence</h3>
<p>So far, you have learned how to calculate <span class="math inline">\(p_A\)</span>, which is the fancy, statistical way of saying the probability of an event known as A. When flipping a coin, the probability of getting heads was 1/2. You have also learned how to compute the <span class="math inline">\(p_{A or B}\)</span>. This means the probability of either A or B happening. When rolling a dice, <span class="math inline">\(p_{1 or 2}\)</span>–the probability of getting a 1 or a 2–was 1/3.</p>
<p>What if you flipped 2 coins? You know that the probability of getting heads once is 1/2, but what are the odds of getting heads 2 times in a row? Let’s take a look at this tree diagram. We read this diagram from left to right. On the left, the probability of getting heads is 0.5. Now the tree branches out.</p>
<ul>
<li>
<em>If</em> we got heads the first time, then we go up the top branch. The probability of getting heads again is 0.5.</li>
<li>
<em>If</em> we got tails the first time, then we go down the bottom branch. The probability of getting heads is 0.5.</li>
</ul>
<p>Notice how regardless of what we get the first time we flip the coin, the probability of getting heads is 0.5 throughout. This suggests that the coin flips are <strong>independent</strong>. The result of one coin flip does not impact the likelihood of getting the same result next time. Take a look at the tree diagram. <span class="math inline">\(p_{H given H}\)</span> represents the probability of getting heads <em>given</em> that we got heads the first time. <span class="math inline">\(p_{H given T}\)</span> represents the probability of getting heads <em>given</em> that we got tails the first time. <span class="math inline">\(p_{H given H}\)</span> = <span class="math inline">\(p_{H given T}\)</span>.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-494-1.png" width="672"></p>
</div>
<div id="conditional-probability" class="section level3">
<h3>
<span class="header-section-number">5.2.2</span> Conditional probability</h3>
<p>Now imagine that 60% of people in a community have a disease. A doctor develops a test to determine if a random person has the disease. However, this test isn’t 100% accurate. This test is 80% sure of correctly returning positive <strong>if the person has the disease</strong> and 90% sure of correctly returning negative <strong>if the person does not have the disease</strong>.</p>
<p>This tree diagram illustrates exactly this. Starting from the left, we see that the probability of a random person having the disease is 0.6. Since they either have the disease or don’t (those are the only two possibilities), the probability that they don’t have the disease is 1 - 0.4.</p>
<p>Now the tree branches out.</p>
<ul>
<li>
<em>If</em> the random person has the disease, then we go down the top branch. The probability of the person testing positive is 0.8 because the test is 80% sure of correctly returning positive when the person has the disease.</li>
<li>By the same logic, <em>if</em> the random person does not have the disease, we go down the bottom branch. The probability of the person incorrectly testing positive is 0.1.</li>
</ul>
<p>We decide to go down the top branch <em>if</em> our random person has the disease. We go down the bottom branch <em>if</em> they do not. This is called <strong>conditional probability</strong>. The probability of testing positive is <strong>dependent</strong> on whether the person has the disease.</p>
<p>How would you express this in statistical notation? <span class="math inline">\(p(A|B)\)</span> is the same thing as the probability of A <em>given</em> B. <span class="math inline">\(p(A|B)\)</span> essentially means the probability of A <em>if</em> we know for sure the value of B. You should also remember that <span class="math inline">\(p(A|B)\)</span> is not the same thing as <span class="math inline">\(p(B|A)\)</span>.</p>
<p><label for="tufte-mn-57" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-57" class="margin-toggle"><span class="marginnote"><span style="display: block;"><strong>Positive:</strong> The test results suggest that the patient has the disease.</span>
<span style="display: block;"><strong>False Positive:</strong> The patient does not have the disease but the test results incorrectly suggest that they do.</span>
<span style="display: block;"><strong>Negative:</strong> The test results suggest that the patient does not have the disease.</span>
<span style="display: block;"><strong>False Negative:</strong> The patient has the disease but the test results incorrectly suggest that they do not.</span></span></p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-496-1.png" width="672"></p>
<p>This concept of conditional probability is relevant in our everyday lives. For example, the probability of Trump’s re-election might be different than the probability of Trump’s re-election <em>given</em> that we are in a recession. The probability of you reading a textbook might vary, <em>depending</em> on the likelihood of your instructor cold-calling you in class. Whenever you encounter a question involving conditional probability, drawing a tree diagram is a very useful approach to visualization.</p>
</div>
<div id="two-diagrams-for-one-set-of-coin-flips" class="section level3">
<h3>
<span class="header-section-number">5.2.3</span> Two diagrams for one set of coin flips</h3>
<p>In our histogram probability distribution, we didn’t care what combinations of numbers made each sum. We only cared about the outcome. There are two ways of thinking about a coin toss as well. Your tree diagram should look different depending on whether the order of the results matters.</p>
<p>To understand tree diagrams a little better, imagine you’re flipping 2 coins. Your tree diagram may look different depending what you’re interested in measuring.</p>
<p><label for="tufte-mn-58" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-58" class="margin-toggle"><span class="marginnote"><span style="display: block;">In this figure, the order of your coin toss results does not matter. We can imagine that you are rolling two coins together, or that you only care about the sum of the two die values.</span></span></p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-498-1.png" width="672"></p>
<p><label for="tufte-mn-59" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-59" class="margin-toggle"><span class="marginnote"><span style="display: block;">In this figure, the order of your coin toss results does matter. Depending on your first result, you go down a different branch.</span></span></p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-500-1.png" width="672"></p>
<!-- 2 b) Another coding session, but this time with list-columns and map_functions. These do not have to be long. We just want to re-iterate the points we made in words. Maybe we don't need list-columns. Maybe just show map functions here. Again, the point of this section is ONLY to understand the key probabity concepts: joint, total, conditional and marginal. -->
</div>
</div>
<div id="two-models" class="section level2">
<h2>
<span class="header-section-number">5.3</span> Two models</h2>
<!-- Then, with those ideas fixed, we make a Bayes Scatterplot with just two rows on the y-axis: have the disease or don't have the disease. (Or maybe we use another exmaple each time.) Since these two models have no fixed numeric meaning, we can just place them at 0 and 1 on the y-axis, which sort of corresponds to FALSE and TRUE. Then, we can x-axis we have the actual data. Which, in this case, is also a TRUE/FAlSE value: Either you tested positive or you tested negative, so also 0 and 1. Then, we can simulate. Put a 100,000 people through, fill out the values. There are only 4 possibilities, so we will need to jittter. (See below for an example of how to do this. And then explore the marginal distributions. Show how this gives you the same answer, roughly, as the math we did before.) -->
<!-- 3 b) Code up a full featured simulation exercise, like the cookie problem but with more complexity. See the old 1005 problem set. Connect this to how 538 does things. 99.99% of real world problems are solved with simulation, not analytically. -->
<p>You are in a city of 100,000 people. We know for a fact that exactly 1% of the population has a disease. Everyone received a test for the disease, which returned accurate results exactly 99% of the time. In terms of a count, that means 1,000 people have this disease of the 100,000 in the population. The correctly identified these individuals 99% of the time, meaning that around 990 correctly tested positive and 10 incorrectly tested negative. This city also has 99,000 people who do not have the disease, 990 of which incorrectly tested positive and 98010 of which correctly tested negative. That means that the number of people who would test positive for the disease is 1980 but <em>only 990 of them have the disease</em>. So, in simple terms, the probability of you having the disease given a positive test is <span class="math inline">\(990\div1980\)</span>!</p>
<p>Here is the joint empirical distribution of the test result and disease status. Note that this is an unnormalized distribution because each dot represents a person in this city.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-501-1.png" width="672"></p>
<p>Here is a joint distribution displayed in 3D. Instead of using the “jitter” feature in R to unstack the dots, we are using a 3D Rayshader plot to visualize the number of dots in each box. The number of people who correctly test negative in this city is 98010, far outweighing any of the other categories. There are 990 false positives, 990 true positives, and only 10 false negatives. This is why we can barely see the 3D bar coming from those sections.</p>
<p><img src="05-probability/images/rayshader_disease.png" width="773"></p>
<p>What is the difference between these distributions? How can they be useful in data analysis?</p>
<p>We want to analyze these plots by looking at different slices. For instance, let’s say that you have tested positive for the disease. Since the test is not always accurate, you cannot be 100% certain that you have it. We would isolate the slice where the test result equals 1 (meaning positive). If we zoom in on the plot, 990 people who tested positive have the disease and 990 who tested positive do not have the disease. In this case, we are focusing on one slice of the probability distribution where the test result was positive. There are two disease outcomes: positive or negative. By isolating a section, we are looking at a conditional distribution. Conditional on a positive test, you can visualize the likelihood of actually having the disease versus not.</p>
<p>This is what looks like when we take the slice where the test result is positive and zoom in.</p>
<p><img src="05-probability/images/rayshader_disease_zoom.png" width="761"></p>
<p>This Stat 110 Animations video does a really good job of explaining a similar concept.</p>
<iframe src="https://www.youtube.com/embed/by3_weGwnMg?showcase=0" width="672" height="400px">
</iframe>
</div>
<div id="three-models" class="section level2">
<h2>
<span class="header-section-number">5.4</span> Three models</h2>
<p><label for="tufte-mn-60" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-60" class="margin-toggle"><span class="marginnote"><span style="display: block;">This example is slightly more complex than the previous one with two models; it is the bridge between the two models example and the n models example we are about to explore.</span></span></p>
<p>Now, imagine that your friend gives you a bag with two marbles. There could either be two white marbles, two black marbles, or one of each color. Thus, the bag could contain 0% white marbles, 50% white marbles, or 100% white marbles. <span class="math inline">\(p\)</span> of white marbles could be 0, 0.5, or 1.</p>
<p>Let’s say you take a marble out of the bag, record whether it’s black or white, then return it to the bag. You repeat this three times, observing the number of white marbles you see out of three trials. You could get three whites, two whites, one white, or zero whites as a result of this trial. Let’s make what we call a Bayes scatterplot out of this. We have three models (three different proportions of white marbles in the bag) and four possible experimental results.</p>
<p>Here is the scatterplot visualization of the scenario:</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-506-1.png" width="672"></p>
<p>Here is the 3D Rayshader visualization:</p>
<p><img src="05-probability/images/three_models.png" width="752"></p>
<!-- # Section 5: 11 and the 1001 models. Same as coin example with unknown p as used in Albert example. First, p is 0, 0.1, 0.2, ... 0.9, 1.0. Make Bayes Scatterplot. Show marginals. Then, extend it so p takes on 1,001 values. This is how we go from discrete to continuous. All the same tricks apply. -->
</div>
<div id="n-models" class="section level2">
<h2>
<span class="header-section-number">5.5</span> N models</h2>
<!-- 5 a) Now go on to Rethinking approach. I think that chapter 2 is just genius. Bayesian is really just counting. Maybe we do a very similar example to what he does? Maybe different? I am still pondering this myself. I think that there is a deep relationship here. In the simple Bayes rule decision trees, we know all the probabilities. But what if we don't? Instead, we get to observe lots of data (which are counts!) and then, from that data, figure out the probabilities. (Note that Rethinking does not talk like this --- after all, we know all the probabilities since each marble has a 20% chance of being drawn --- but I think it is implicit in his approach.) Key issue: Can we connect this in a sensible way to Bayesian scatterplot. There is always the data and the model and the relationship between the two. (And "the model" means, mainly, the parameter estimates thereof.) Tell me the data, and I will tell you the model. Tell me the model, and I will tell you the model. -->
<!-- Note the connection between the marbles from Rethinking and the Bayesian scatterplot. In figure 2.2 in Rethinking represents the model where p = 0.25, where p is the proportion of blue marbles in the total collection. The y-axis models would be labeled with p = 0, 0.25, 0.5, 0.75, and 1. With the tree marble diagram in figure 2.2, we would be taking random samples with 3 marbles. The number of blue marbles we get each time would be plotted along p = 0.25. This is another example of model on the y-axis and data on the x-axis. -->
<!-- DK: Should we cut out p = 0 and p = 1 as too annoying to deal with? -->
<p><label for="tufte-mn-61" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-61" class="margin-toggle"><span class="marginnote"><span style="display: block;">Is it not annoying that we use the same letter, “p”, to mean two totally different things? At the start of the chapter, “p” is the symbol used for a probability distribution. Here, we are also using it to mean the probability of a coin coming up heads. Sadly, there are only so many letters we can use, so you need to be mentally flexible enough to keep track of both meanings. When “p” is used for an unknown parameter, it will written in italics as <span class="math inline"><span class="math inline">\(p\)</span></span>, which is always the case for parameters. The “p” which is the symbol for a probability distribution is in regular text: p. Putting these together, p(<span class="math inline"><span class="math inline">\(p\)</span></span>) is the probability distribution for the probability of a flipped-coin coming up heads.</span></span></p>
<p>Assume that there is a coin with probability <span class="math inline">\(p\)</span> of coming up heads. I guarantee that there are only 11 possible values of <span class="math inline">\(p\)</span>: <span class="math inline">\(0, 0.1, 0.2, ..., 0.9, 1\)</span>. In other words, there are 11 possible models, 11 things which might be true about the world. This is just like situations we have previously discussed, except that there are more models to consider.</p>
<p>We are going to run an experiment in which you flip the coin 20 times and record the number of heads. What does this result tell you about the value of <span class="math inline">\(p\)</span>? Ultimately, we will want to calculate a posterior distribution of <span class="math inline">\(p\)</span>, which is written as p(<span class="math inline">\(p\)</span>).</p>
<p>To start, it is useful to consider all the things which might happen if, for example, <span class="math inline">\(p = 0.4\)</span>. Fortunately, the R functions for simulating random variables makes this easy</p>
<div class="sourceCode" id="cb745"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb745-1"><a href="probability.html#cb745-1"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb745-2"><a href="probability.html#cb745-2"></a></span>
<span id="cb745-3"><a href="probability.html#cb745-3"></a>x &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">heads =</span> <span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">1000</span>, <span class="dt">size =</span> <span class="dv">20</span>, <span class="dt">p =</span> <span class="fl">0.4</span>))</span>
<span id="cb745-4"><a href="probability.html#cb745-4"></a></span>
<span id="cb745-5"><a href="probability.html#cb745-5"></a>x <span class="op">%&gt;%</span></span>
<span id="cb745-6"><a href="probability.html#cb745-6"></a><span class="st">  </span><span class="kw">group_by</span>(heads) <span class="op">%&gt;%</span></span>
<span id="cb745-7"><a href="probability.html#cb745-7"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">total =</span> <span class="kw">n</span>(), <span class="dt">.groups =</span> <span class="st">"drop"</span>) <span class="op">%&gt;%</span></span>
<span id="cb745-8"><a href="probability.html#cb745-8"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">prob =</span> total<span class="op">/</span><span class="kw">sum</span>(total)) <span class="op">%&gt;%</span></span>
<span id="cb745-9"><a href="probability.html#cb745-9"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(heads, prob)) <span class="op">+</span></span>
<span id="cb745-10"><a href="probability.html#cb745-10"></a><span class="st">    </span><span class="kw">geom_col</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb745-11"><a href="probability.html#cb745-11"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"Empirical Distribution of Number of Heads"</span>,</span>
<span id="cb745-12"><a href="probability.html#cb745-12"></a>         <span class="dt">subtitle =</span> <span class="st">"Based on 1,000 simulations with p = 0.4"</span>,</span>
<span id="cb745-13"><a href="probability.html#cb745-13"></a>         <span class="dt">x =</span> <span class="st">"Number of Heads out of 20 Tosses"</span>,</span>
<span id="cb745-14"><a href="probability.html#cb745-14"></a>         <span class="dt">y =</span> <span class="st">"Probability"</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-509-1.png" width="672"></p>
<p>First, notice that many different things can happen! Even if we <em>know</em>, for certain, that <span class="math inline">\(p = 0.4\)</span>, many outcomes are possible. Life is remarkably random. Second, the most likely result of the experiment is 8 heads, as we would expect. Third, we have transformed the raw counts of how many times each total appeared into a probability distribution. Sometimes, however, it is convenient to just keep track of the raw counts. The shape of the figure is the same in both cases.</p>
<div class="sourceCode" id="cb746"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb746-1"><a href="probability.html#cb746-1"></a>x <span class="op">%&gt;%</span></span>
<span id="cb746-2"><a href="probability.html#cb746-2"></a><span class="st">  </span><span class="kw">group_by</span>(heads) <span class="op">%&gt;%</span></span>
<span id="cb746-3"><a href="probability.html#cb746-3"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">total =</span> <span class="kw">n</span>(), <span class="dt">.groups =</span> <span class="st">"drop"</span>) <span class="op">%&gt;%</span></span>
<span id="cb746-4"><a href="probability.html#cb746-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(heads, total)) <span class="op">+</span></span>
<span id="cb746-5"><a href="probability.html#cb746-5"></a><span class="st">    </span><span class="kw">geom_col</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb746-6"><a href="probability.html#cb746-6"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"Total Count of the Number of Heads Out of 20 Tosses"</span>,</span>
<span id="cb746-7"><a href="probability.html#cb746-7"></a>         <span class="dt">subtitle =</span> <span class="st">"Based on 1,000 simulations with p = 0.4"</span>,</span>
<span id="cb746-8"><a href="probability.html#cb746-8"></a>         <span class="dt">x =</span> <span class="st">"Number of Heads out of 20 Tosses"</span>,</span>
<span id="cb746-9"><a href="probability.html#cb746-9"></a>         <span class="dt">y =</span> <span class="st">"Count"</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-510-1.png" width="672"></p>
<p>Either way, the figures show <em>what would have happened if that model — that <span class="math inline">\(p = 0.4\)</span> — were true.</em></p>
<p>We can do the same thing for all 11 possible models, calculating what would happen if each of them were true. This is somewhat counterfactual since only one of them can be true. Yet this assumption does allow us to create the <em>joint distribution</em> of <em>models which might be true</em> and of <em>data which our experiment might generate</em>. Let’s simplify this is p(models, data), although you should keep the precise meaning in mind.</p>
<div class="sourceCode" id="cb747"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb747-1"><a href="probability.html#cb747-1"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb747-2"><a href="probability.html#cb747-2"></a></span>
<span id="cb747-3"><a href="probability.html#cb747-3"></a>x &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">p =</span> <span class="kw">rep</span>(<span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.1</span>), <span class="dv">1000</span>)) <span class="op">%&gt;%</span></span>
<span id="cb747-4"><a href="probability.html#cb747-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">heads =</span> <span class="kw">map_int</span>(p, <span class="op">~</span><span class="st"> </span><span class="kw">rbinom</span>(<span class="dt">n =</span> <span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">20</span>, <span class="dt">p =</span> .)))</span>
<span id="cb747-5"><a href="probability.html#cb747-5"></a></span>
<span id="cb747-6"><a href="probability.html#cb747-6"></a>x <span class="op">%&gt;%</span></span>
<span id="cb747-7"><a href="probability.html#cb747-7"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y =</span> p, <span class="dt">x =</span> heads)) <span class="op">+</span></span>
<span id="cb747-8"><a href="probability.html#cb747-8"></a><span class="st">    </span><span class="kw">geom_jitter</span>(<span class="dt">alpha =</span> <span class="fl">0.1</span>) <span class="op">+</span></span>
<span id="cb747-9"><a href="probability.html#cb747-9"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"Number of Heads and Probability of Heads"</span>,</span>
<span id="cb747-10"><a href="probability.html#cb747-10"></a>         <span class="dt">x =</span> <span class="st">"Number of Heads out of 20 Tosses"</span>,</span>
<span id="cb747-11"><a href="probability.html#cb747-11"></a>         <span class="dt">y =</span> <span class="st">"Value of *p*"</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-511-1.png" width="672"></p>
<p>Here is the 3D version of the same plot.</p>
<p><img src="05-probability/images/n_models.png" width="734"></p>
<!-- DK: Bunch of things to see in this diagram. -->
<!-- DK: Then, finally, we do the experiment. We get 8 heads. What does that mean?  -->
</div>
<div id="posterior-distribution" class="section level2">
<h2>
<span class="header-section-number">5.6</span> Posterior distribution</h2>
<p>We don’t really care about the p(<span class="math inline">\(models\)</span>, <span class="math inline">\(data\)</span>), the joint distribution of the models-which-might-be-true and the data-which-our-experiment-might-generate. Instead, we want to estimate <span class="math inline">\(p\)</span>, the unknown parameter which determines the probability that this coin will come up heads when tossed. The joint distribution alone can’t tell us that. We <em>created</em> the joint distribution before we had even conducted the experiment. It is our creation, a tool which we use to make inferences. Instead, we want the conditional distribution, p(<span class="math inline">\(models\)</span> | <span class="math inline">\(data = 8\)</span>). We have the results of the experiment. What do those results tell us about the probability distribution of <span class="math inline">\(p\)</span>?</p>
<p>To answer this question, we simply take a vertical <em>slice</em> from the joint distribution at the point of the x-axis corresponding to the results of the experiment.</p>
<p><label for="tufte-mn-62" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-62" class="margin-toggle"><span class="marginnote"><span style="display: block;">This animation shows what we want to do with joint distributions. We take a slice (the red one), isolate it, rotate it to look at the conditional distribution, normalize it (change the values along the current z-axis from counts to probabilities), then observe the resulting posterior.</span></span></p>
<p><img src="05-probability/animations/color_red_combo.gif"></p>
<p>This is the only part of the joint distribution that we care about. We aren’t interested in what the object looks like where, for example, the number of heads is 11. That portion is irrelevant because we observed 8 heads, not 11. There are a total of 465 times in our simulation in which 8 heads were observed.</p>
<div class="sourceCode" id="cb748"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb748-1"><a href="probability.html#cb748-1"></a>x_with_heads_equal_<span class="dv">8</span> &lt;-<span class="st"> </span>x <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb748-2"><a href="probability.html#cb748-2"></a><span class="st">  </span><span class="kw">filter</span>(heads <span class="op">==</span><span class="st"> </span><span class="dv">8</span>)</span></code></pre></div>
<p>As we would expect, most of the time when 8 coin tosses came up heads, the value of <span class="math inline">\(p\)</span> was 0.4. But, on numerous occasions, it was not. It is quite common for a value of <span class="math inline">\(p\)</span> like 0.3 or 0.5 to generate 8 heads. Consider:</p>
<div class="sourceCode" id="cb749"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb749-1"><a href="probability.html#cb749-1"></a>x <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb749-2"><a href="probability.html#cb749-2"></a><span class="st">  </span><span class="kw">filter</span>(heads <span class="op">==</span><span class="st"> </span><span class="dv">8</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb749-3"><a href="probability.html#cb749-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(p)) <span class="op">+</span></span>
<span id="cb749-4"><a href="probability.html#cb749-4"></a><span class="st">    </span><span class="kw">geom_bar</span>() <span class="op">+</span></span>
<span id="cb749-5"><a href="probability.html#cb749-5"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"Values of p Associated with 8 Heads"</span>,</span>
<span id="cb749-6"><a href="probability.html#cb749-6"></a>         <span class="dt">x =</span> <span class="st">"Assumed value of p in simulation"</span>,</span>
<span id="cb749-7"><a href="probability.html#cb749-7"></a>         <span class="dt">y =</span> <span class="st">"Count"</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-515-1.png" width="672"></p>
<p>Yet this is a distribution of raw counts. It is an unnormalized density. To turn it into a proper probability density — i.e., one in which the sum of the probabilities across possible outcomes sums to one — we just divide everything by the total number of observations.</p>
<div class="sourceCode" id="cb750"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb750-1"><a href="probability.html#cb750-1"></a>p_posterior &lt;-<span class="st"> </span>x <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb750-2"><a href="probability.html#cb750-2"></a><span class="st">  </span><span class="kw">filter</span>(heads <span class="op">==</span><span class="st"> </span><span class="dv">8</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb750-3"><a href="probability.html#cb750-3"></a><span class="st">  </span><span class="kw">group_by</span>(p) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb750-4"><a href="probability.html#cb750-4"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">total =</span> <span class="kw">n</span>(), <span class="dt">.groups =</span> <span class="st">"drop"</span>) <span class="op">%&gt;%</span></span>
<span id="cb750-5"><a href="probability.html#cb750-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">probs =</span> total<span class="op">/</span><span class="kw">sum</span>(total))</span>
<span id="cb750-6"><a href="probability.html#cb750-6"></a></span>
<span id="cb750-7"><a href="probability.html#cb750-7"></a>p_posterior <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb750-8"><a href="probability.html#cb750-8"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> p, <span class="dt">y =</span> probs)) <span class="op">+</span></span>
<span id="cb750-9"><a href="probability.html#cb750-9"></a><span class="st">    </span><span class="kw">geom_col</span>() <span class="op">+</span></span>
<span id="cb750-10"><a href="probability.html#cb750-10"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"Posterior Probability Distribution of p"</span>,</span>
<span id="cb750-11"><a href="probability.html#cb750-11"></a>         <span class="dt">x =</span> <span class="st">"Possible Values of p"</span>,</span>
<span id="cb750-12"><a href="probability.html#cb750-12"></a>         <span class="dt">y =</span> <span class="st">"Probability"</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-516-1.png" width="672"></p>
<p>The most likely value of <span class="math inline">\(p\)</span> is still 0.4, as before. But, it is much more likely that <span class="math inline">\(p\)</span> is either 0.3 or 0.5. And there is about an 8% chance that <span class="math inline">\(p \ge 0.6\)</span>.</p>
</div>
<div id="predictions" class="section level2">
<h2>
<span class="header-section-number">5.7</span> Predictions</h2>
<p>Models are useless unless we use them for something. Let’s make some predictions. What are the chances that, if we toss this coin 10 times, we will get 7 or more heads? Because our posterior distribution is centered around <span class="math inline">\(p = 0.4\)</span>, we don’t expect to see 7 heads, but it is certainly not impossible.</p>
<!-- DK: 

1> First wrong way to do this is with assuming that p is certain, based on seeing 8 heads. Ignore the uncertainty on your estimate of p.

sims <- 100000

tibble(sim_ID = 1:sims) %>%
  mutate(heads = map_int(sim_ID, ~ rbinom(n = 1, size = 10, p = .4))) %>% 
  mutate(result = ifelse(heads >= 7, TRUE, FALSE)) %>% 
  summarize(success = sum(result)/sims)
  
About 5%. So, I might offer you 19:1 odds on a bet. But this is wrong!

Second way, it to just sample from the whole distribution posterior distribution vector that you created.

p_draws <- x %>% 
  filter(heads == 8)
  
tibble(p = sample(p_draws$p, size = sims, replace = TRUE)) %>%
  mutate(heads = map_int(p, ~ rbinom(n = 1, size = 10, p = .))) %>% 
  mutate(result = ifelse(heads >= 7, TRUE, FALSE)) %>% 
  summarize(success = sum(result)/sims)

Third way is to sample from the actual distribution, which is a small dataset with just a few rows, but it includes both p and the probability of each p.

tibble(p = sample(p_posterior$p, 
                  size = sims, prob = p_posterior$probs, replace = TRUE)) %>%
  mutate(heads = map_int(p, ~ rbinom(n = 1, size = 10, p = .))) %>% 
  mutate(result = ifelse(heads >= 7, TRUE, FALSE)) %>% 
  summarize(success = sum(result)/sims)


-->
<!-- ## Testing is evil -->
<!-- Introduce concepts like the null model, testing, and p-values. Connect to permutation tests from chapter 3.  Side note quotation: "Amatuers test. Professionals summarize." Maybe we should pick an example in which the number of heads is low enough to provide some reasonable evidence against p = 0.5. -->
<!-- In some fields, it is common to want to test a specific hypothesis. Consider the hypothesis that the coin is fair, i.e., that $p = 0.5$. Does the data we have support or reject that hypothesis? (Be wary that $p$ is both used for the probability of a head and the $p$-value of a hypothesis test.) -->
<!-- Not really interested in that exact test except in toy scenarios. -->
<!-- Difference between 0.04 and 0.06 is rarely significant. And is hardly ever a good reason to decide X over Y. -->
<p>The PPBDS contains several important themes that are relevant in all chapters. As you move through the textbook, you will be building on and refining these concepts. In this chapter, you will learn about model structure, predictive uncertainty, parameter uncertainty, unmodeled variation, and unknown unknowns. These are organized according to the four cardinal virtues that reoccur throughout the book: Prudence, Temperance, Fortitude, and Justice.</p>
</div>
<div id="prudence" class="section level2">
<h2>
<span class="header-section-number">5.8</span> Prudence</h2>
<div id="parameter-uncertainty" class="section level3">
<h3>
<span class="header-section-number">5.8.1</span> Parameter uncertainty</h3>
<p>Suppose your friend sets up a pseudo-casino in the playground of the neighborhood school. He’s offering everyone the opportunity to play probability games and bet money. The first game is simple: coin tosses. If the coin lands on heads, you get five dollars. If it lands on tails, you pay three dollars.</p>
<p>You have a sneaking suspicion that the coin isn’t fair and you ask your friend to flip it 10 times to test your theory. However, you must not be overconfident. 10 observations might be too few to judge the fairness of the coin. Perhaps your friend secretly switches coins when it comes time for the actual betting and your sample in the initial simulation is not representative. You might be nervous about losing your money and even miscount the number of heads and tails. These are all examples of <em>parameter uncertainty</em>. Sometimes, a model has the correct form, but it’s not practical to run the simulation millions of times to be certain of the outcome. It’s not possible to be absolutely certain that your friend isn’t switching coins. A perfect world does not exist, so we must have reservations when drawing likely conclusions.</p>
</div>
<div id="unknown-unknowns" class="section level3">
<h3>
<span class="header-section-number">5.8.2</span> Unknown unknowns</h3>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-517"></span>
<img src="05-probability/images/donald_rumsfeld.jpg" alt="Donald Rumsfeld." width="600"><!--
<p class="caption marginnote">-->FIGURE 5.2: Donald Rumsfeld.<!--</p>-->
<!--</div>--></span>
</p>
<p>Donald Rumsfeld, the former US Secretary of Defense, once said the following tongue-twisting quote:</p>
<p>“There are known knowns. There are things we know we know. We also know there are known unknowns. That is to say, we know there are some things we do not know. But there are also unknown unknowns, the ones we do not know we do not know.”</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-518"></span>
<img src="05-probability/images/Three_Card_Monte.jpg" alt="Three Card Monte." width="512"><!--
<p class="caption marginnote">-->FIGURE 5.3: Three Card Monte.<!--</p>-->
<!--</div>--></span>
</p>
<p>What does this mean? Well imagine a crowd playing Three Card Monte in the streets of New York. The guy running the game runs a demo and shows you all the cards to make you confident. They earn money by making you overconfident and persuading you to bet. Your odds may seem good during the demo round, but that doesn’t actually say anything about what will likely happen when the real, high stakes game begins. The person running the game does many simulations, making the “victim” forget that they cannot actually make any conclusions about the odds of winning. There are some variables that we simply do not know even if we put a lot of effort into making posterior probability distributions. People can be using slight of hand, for instance.</p>
</div>
</div>
<div id="temperance" class="section level2">
<h2>
<span class="header-section-number">5.9</span> Temperance</h2>
</div>
<div id="fortitude" class="section level2">
<h2>
<span class="header-section-number">5.10</span> Fortitude</h2>
</div>
<div id="justice" class="section level2">
<h2>
<span class="header-section-number">5.11</span> Justice</h2>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-519"></span>
<img src="05-probability/images/coin_flip.jpg" alt="Probability Themes." width="300"><!--
<p class="caption marginnote">-->FIGURE 5.4: Probability Themes.<!--</p>-->
<!--</div>--></span>
</p>
<div id="model-structure" class="section level3">
<h3>
<span class="header-section-number">5.11.1</span> Model structure</h3>
<p>Is <span class="math inline">\(P_h\)</span> constant?</p>
</div>
<div id="predictive-uncertainty" class="section level3">
<h3>
<span class="header-section-number">5.11.2</span> Predictive uncertainty</h3>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-520"></span>
<img src="05-probability/images/probability_dice.jpeg" alt="PROBABILITY DOES NOT EXIST." width="286"><!--
<p class="caption marginnote">-->FIGURE 5.5: PROBABILITY DOES NOT EXIST.<!--</p>-->
<!--</div>--></span>
</p>
<p>A wise, Italian statistician named Bruno de Finetti once famously said “PROBABILITY DOES NOT EXIST.” Some call him a “radical probabilist” but he was right to point out that probability is something humans constructed to understand the world; it is not possible to forecast the literal future. The two primary sources of predictive uncertainty are parameter uncertainty and unmodeled variation.</p>
<!-- Still conditional on model structure. p(result from experiment to come) -->
</div>
<div id="unmodeled-variation" class="section level3">
<h3>
<span class="header-section-number">5.11.3</span> Unmodeled variation</h3>
<p>(This may be difficult to talk about since we don’t (?) write down formulas with error terms.) But each chapter should discuss the concept of a residual. Even if we have perfect parameter estimates for a model structure which matches the unknown data generating mechanism, we still won’t make perfect predictions. Some randomness is intrinsic. Example: prediction for an individual.</p>
<p>result = model + other stuff, where other stuff is variation which is not part of the model, i.e., it is</p>
<p>45 = 40 + 5</p>
<p>unmodeled variation. <em>residual</em>; <em>fitted value</em> <em>expected value</em></p>
<p>result = fitted (expected) value + residual</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-521"></span>
<img src="05-probability/images/de_finetti.jpg" alt="De Finetti." width="100"><!--
<p class="caption marginnote">-->FIGURE 5.6: De Finetti.<!--</p>-->
<!--</div>--></span>
</p>
<p><label for="tufte-mn-63" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-63" class="margin-toggle"><span class="marginnote"><span style="display: block;">Bruno de Finetti was an Italian statistician who wrote a famous treatise on the theory of probability that began with the statement “PROBABILITY DOES NOT EXIST.” This is because probability only exists subjectively in our minds. It is a tool people made up and use for broad-stroke estimates.</span></span></p>
<p>Throughout this chapter, we spent time going through examples of conditional distributions. However, it’s worth noting that all probability distributions are conditional on something. Even in the most simple examples, when we were flipping a coin multiple times, we were assuming that the probability of getting heads versus tails did not change between tosses.</p>
<p>We also discussed the difference between empirical, mathematical, and posterior probability distributions. Even though we developed these heuristics to better understand distributions, every time we make a claim about the world, it is based on our beliefs - what we think about the world. We could be wrong. Our beliefs can differ. Two reasonable people can have conflicting beliefs about the fairness of a die.</p>
<p>It is useful to understand the three types of distributions and the concept of conditional distributions, but almost every probability distribution is conditional and posterior. We can leave out both words in future discussions, as we generally will in this book. They are implicit.</p>

</div>
</div>
</div></body></html>

<p style="text-align: center;">
<a href="functions.html"><button class="btn btn-default">Previous</button></a>
<a href="one-parameter.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-08-21
</p>
</div>
</div>



</body>
</html>
