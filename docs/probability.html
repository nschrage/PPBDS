<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 5 Probability | Preceptor’s Primer for Bayesian Data Science" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="davidkane9/PPBDS" />

<meta name="author" content="David Kane" />

<meta name="date" content="2020-07-08" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Chapter 5 Probability | Preceptor’s Primer for Bayesian Data Science">

<title>Chapter 5 Probability | Preceptor’s Primer for Bayesian Data Science</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Preceptor's Primer for Bayesian Data Science<p><p class="author">David Kane</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="index.html">Cover</a>
<a href="preamble.html">Preamble</a>
<a href="visualization.html"><span class="toc-section-number">1</span> Visualization</a>
<a href="wrangling.html"><span class="toc-section-number">2</span> Tidyverse</a>
<a href="rubin-causal-model.html"><span class="toc-section-number">3</span> Rubin Causal Model</a>
<a href="functions.html"><span class="toc-section-number">4</span> Functions</a>
<a id="active-page" href="probability.html"><span class="toc-section-number">5</span> Probability</a><ul class="toc-sections">
<li class="toc"><a href="#the-language-of-inference"> The Language of Inference</a></li>
<li class="toc"><a href="#unknown-unknowns"> Unknown Unknowns</a></li>
<li class="toc"><a href="#probability-and-simulations"> Probability and Simulations</a></li>
<li class="toc"><a href="#tree-diagrams"> Tree Diagrams</a></li>
<li class="toc"><a href="#comparing-two-models"> Comparing Two Models</a></li>
<li class="toc"><a href="#comparing-three-models"> Comparing Three Models</a></li>
<li class="toc"><a href="#comparing-n-models"> Comparing N Models</a></li>
<li class="toc"><a href="#testing-is-evil"> Testing is Evil</a></li>
<li class="toc"><a href="#posterior-predictions-advanced"> Posterior Predictions (Advanced)</a></li>
<li class="toc"><a href="#key-themes"> Key Themes</a></li>
</ul>
<a href="sampling.html"><span class="toc-section-number">6</span> Sampling</a>
<a href="one-parameter.html"><span class="toc-section-number">7</span> One Parameter</a>
<a href="two-parameters.html"><span class="toc-section-number">8</span> Two Parameters</a>
<a href="n-parameters.html"><span class="toc-section-number">9</span> N Parameters</a>
<a href="regression.html"><span class="toc-section-number">10</span> Continuous Response I</a>
<a href="multiple-regression.html"><span class="toc-section-number">11</span> Continuous Response II</a>
<a href="classification.html"><span class="toc-section-number">12</span> Discrete Response</a>
<a href="appendices.html">Appendices</a>
<a href="productivity.html">Productivity</a>
<a href="shiny.html">Shiny</a>
<a href="maps.html">Maps</a>
<a href="animation.html">Animation</a>
<a href="rubin-causal-model.html">References</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="probability" class="section level1">
<h1>
<span class="header-section-number">Chapter 5</span> Probability</h1>
<!-- 1) Add screen shot from https://projects.economist.com/us-2020-forecast/president of electoral vote forecast. This is p(electoral votes) or, shorter p(ev). It is just like all our other p()'s. It is a distribution because all values are between 0 and 1 and the sum is one. But it does not come from either math or from (direct) experience. Instead it is the distribution --- coloquially, the posterior distribution --- which comes from our modeling process. But this p() is, conceptually, the same as all our other p()'s. 

There are *probability* distributions (which are mathematical formulas, using fair dice). There are *frequency* distributions (which are data). Both have good Wikipedia entries. Maybe link to them? Compare math of two dice and frequency of rolling the pair 20 times. The probability distribution is the Platonic form. The frequency distribution will often look like the probability distribution, but it will rarely be exactly the same. The third type of distribution is a posterior distribution, which is a measures of your belief about things you can't see right now. You can have posterior distributions about things in the pas --- How many electoral votes would Hilary Clinton have won if she picked a differnt VP? About things in the present --- What is the median height of Harvard students? And about things in the future --- How many electoral votes will Joe Biden win? 

-->
<!-- 2) Move 05-questions.Rmd over to GOV-50/part_2. Need to set-up, just like you did with PPBDS. (Move the file over "by hand", then commit as usual and do a pr_push().) Then, you can delete it here. Write two questions. (We need to give Tyler something to mess with.) -->
<!-- 3) Think about ways we can ensure that students have done the reading. Previous chapters use tutorial questions. What sort of questions could we use? Set up Zoom with Evelyn and have her guide you through writing a couple of questions.-->
<!-- 4) Code snippets are cut off. How to fix? Make those sections wider? Make code smaller? Set up Zoom to discuss with Yao. -->
<!-- TODOS

1) Revise PDF section. The tension between writing the exact truth and making sure students get the intuition, which is thinking in terms of p().  pdf, pmf, pd, p where "f" means function; d means continuous and m means discrete.  pd is just a probability distribution, which comes from counts.  

Use p(A). 

mean income  p(MI), P(MI), pd(MI) or pdf(MI).   Start with p(models, data you might see) before you see the data, but after you know the experiment you are planning to do. Then, you see the data. Cool! p(models | data = what you saw) == p(models | data)

Make sense to use p for three totally different things in chapters 3 and 5?

2) Right before comparing two models, add a section showing that a tree diagram may look different depending on whether order matters. Are we looking for sum or do we care about the order of rolling H vs T as well? Flip 2 coins. Only 4 branches from one dot if we care about sum. But if order matters, we need a more extensive diagram with 6 branches.

4) 
- Workshop statistics quote + generally populate sidebar
- Add Rossman quote to side.
- More quotes and fun stuff.

5) PROBABILITY DOES NOT EXIST. de finetti (photo! Italian?)

8) Add section on unknown unknowns

9) Go into terms like parameter uncertainty, validity, unmodeled variation (either give them their own section headings or make them italicized terms.)

10) Integrate Maria's animations

11) gradethis and learnr

12) add section at the bottom noting the key themes from DK

-->
<!-- DK: Things to discuss 


2) Don't use grid.arrange. Use the functions in cowplot. Or is there a better package?

DK: If we want to do rethinking: https://bookdown.org/content/3890/small-worlds-and-large-worlds.html#the-garden-of-forking-data

-->
<!-- Central idea: No formulas. No likelihoods. No specific probability distributions. The most technical we get is explaining: p(A), p(B), p(A, B), p(A|B) and p(B|A). Teach probability using branching trees, which eventually lead to outcomes from your sample set. Conditional and marginal probability from those trees. Then go to Bayes Scatterplots. Data on the x-axis. Model on the y-axis. Everything flows from those scatterplots. First, with 0/1 models. The equivalent of a Bayesian box, but with the rows on the y-axis. Then a Bayesian Scatterplot with three models. Then, modeling p with 11 values. Then with 1,001. Then we wave our hands and report that the continuous case is just the extension of that idea, from a few discrete models to a continuum of millions of them. Simulations grow in complexity. The first one would be simple. No map functions or list columns. Later ones get more serious. Introducing testing and why it is evil. Finish with Bayesian posterior predictions. -->
<!-- Key references. Make sure to cite all three as separate side notes. But, at the same time, don't feel compelled to do things the way that they did them. -->
<!-- 2) Teaching Bayes' Rule: A Data-Oriented Approach by Jim Albert. The key concept is Bayes Scatterplots. That is the central graphic of this chapter. We will show such a scatterplot four or five times, each time more complex, each time showing marginal distributions in both directions. -->
<!-- 3) Rethinking Chapter 2. Garden of forking data is just excellent stuff.  -->
<!-- Open Questions: -->
<!-- Should we connect to the Rubin Causal Model? Leafs on the tree are the potential outcomes. Never seen this done before. Because you followed the tree diagram in one direction, you can't go down two branches simultaneously. Is there a connection to game theory tree diagrams in microeconomics? Not sure how exactly to apply this . . . -->
<!-- Review problem set #5 from last year for ideas about simulations to use as examples. -->
<!-- Use some STAT 110 midterm questions as example problems which simulation makes easy to solve. Maybe? At least in the first section? https://projects.iq.harvard.edu/files/stat110/files/midterm_exam.pdf -->
<!-- Would it be helpful to introduce the rsample::bootstraps() function? Or wait till next chapter? Or maybe do a bootstraps the hard way here and then introduce the easy way later? -->
<!-- Should we discuss, or show an example, of multiple dimensions? We have two coins, each with their own p. Build the joint distribution for them, with one on the x-axis and one on the y-axis. You need a near graphic for each value of the H number of heads total that you get from flipping them each N times. Then, you run the experiment, and you select the correct graphic. That shows you the best guess joint distribution. This is confusing! Too hard for the chapter, but maybe not for a problem set. Or maybe we revisit exactly this example in the two parameter chapter? -->
<!-- Class Exercises -->
<!-- a) Workshop Statistics has nice dice and coin examples. Perhaps use those in lecture? -->
<!-- b) Two buckets, each with different pair of die in them: one normal, one weird. You pick a bucket, then roll the die. Q: What are the odds of bucket 1 versus bucket 2? Start with dice function. Then build tibble as in the cookie problem. That takes a day, especially if we build the result by-hand, meaning pivot_wider and summing columns, as we should. Then, day 2, place a prior on the two buckets. Then, what if we through the dice more than once? This will be a list column. Scary! But all the other arguments go through. (I think!) Then, discuss continuous example of a coin, setting the stage for problem set question. -->
<!-- c) Do a dice example where students each have their own priors and then we update after rolling dice, some fake or real. Do it with counts, not proportions.  -->
<!-- d) Might a Bayesian power discussion, as in Kruscke article, be a useful problem set? Ties into the usage of fake data. Good way to introduce/teach type M and S errors? -->
<div id="the-language-of-inference" class="section level2">
<h2>
<span class="header-section-number">5.1</span> The Language of Inference</h2>
<!-- Read Topic 14 in Bayesian Workshop. Lots of interesting ideas and examples there for this first section of the chapter. Any coding examples should be simple, with  no list-columns and map_* functions. Basic tool we are introducing is doing simulation within a tibble. Consider doing some of the sample problems from STAT 110, many of which are hard to do analytically but easy to do with simulation. Mention what a PDF is, but no math. Show histogram of results from one die and two die. Explain how those histograms are, more or less, PDFs. Explain what p(A), p(B) and p(A, B) using dice/coin examples. PDF. Trump's electoral votes as a PDF. -->
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-317"></span>
<img src="05-probability/images/probability_dice.jpeg" alt="Dice and Probability."><!--
<p class="caption marginnote">-->FIGURE 5.1: Dice and Probability.<!--</p>-->
<!--</div>--></span>
</p>
<p><label for="tufte-mn-35" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-35" class="margin-toggle"><span class="marginnote"><span style="display: block;">The opening paragraph of <em>Workshop Statistics: Discovery with Data, A Bayesian Approach by James H. Albert and Allan J. Rossman</em> does a wonderful job of explaining the concept of probability.</span>
<span style="display: block;">“In the activities to follow, we don’t know if we have a particular disease, if a die being used in the casino is fair, the exact number of fish in our backyard pond, or the number of defectives in a shipment of electronic components. A model is a possible description of this unknown phenomena. In each application, there will be a number of possible models. We assign prior probabilities to these models — these probabilities reflect our opinions about which models are more or less likely to be true. To learn about the correct model, data will be observed. In the activities, the data will consist of the results of a blood test, the results of a roll of the die, the results of a capture-recapture experiment, and the number of defectives observed in a sample. This data will change our opinions about the likelihoods of the different models. Bayes’ rule is the formula which tells us how to compute the new model probabilities.”</span></span></p>
<p>The central tension, and opportunity, in data science is the interplay between the <em>data</em> and the <em>science</em>, between our empirical observations and the models which we use to understand them. Probability is the language we use to explore that interplay; it connects models to data, and data to models.</p>
<p>What does it mean that Trump has a <em>30% chance</em> of winning re-election this fall? That there is a <em>90% probability</em> of rain today? That the die at the casino is <em>unfair</em>? If I roll that die 10 times and five of those times I get a three, how likely is it that the die is <em>unfair</em>?</p>
<p>Probability is about quantifying uncertainty. We can think of probability as a proportion. The probability of an event occurring is a number from 0 to 1, where 1 means that the event is 100% certain.</p>
<p>Let’s begin with the simplest events: coin flips and dice rolls. If the die and
the coins are fair, we can operate under the assumption that all outcomes are
equally likely.</p>
<p>This allows us to make the following statements:</p>
<ul>
<li>The probability of rolling either a 1 or 2 is 2/6, or 1/3.<br>
</li>
<li>The probability of rolling either 1, 2, 3, 4, 5, or 6 is 1.<br>
</li>
<li>The probability of flipping a coin and getting a tail is 1/2.</li>
</ul>
<p>We can also use subtraction to make opposite statements:</p>
<ul>
<li>The probability of <strong>not</strong> getting a 1 or 2 is 2/3.<br>
</li>
<li>The probability of <strong>not</strong> rolling 1, 2, 3, 4, 5, or 6 is 0.<br>
</li>
<li>The probability of <strong>not</strong> flipping a coin and not getting a tail is 1/2.</li>
</ul>
</div>
<div id="unknown-unknowns" class="section level2">
<h2>
<span class="header-section-number">5.2</span> Unknown Unknowns</h2>
<p>Donald Rumsfeld, the former US Secretary of Defense, once said the following tongue-twisting quote:</p>
<p>“There are known knowns. There are things we know we know. We also know there are known unknowns. That is to say, we know there are some things we do not know. But there are also unknown unknowns, the ones we do not know we do not know.”</p>
<p>What does this mean? Well imagine there are people playing games on the street corners of New York. The guy leading the game flips a coin 50 times and shows that there is approximately equal probability of landing heads or tails. Even if the guy can prove the odds of each result through simulations, that doesn’t say anything about what will likely happen when someone in the crowd decides to bet on a certain result.</p>
</div>
<div id="probability-and-simulations" class="section level2">
<h2>
<span class="header-section-number">5.3</span> Probability and Simulations</h2>
<p>Now, let’s take our understanding of probability and apply it to a data science context.</p>
<p>Flipping 1 coin 1 time gives us a flat histogram:</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-319-1.png" width="672"></p>
<p>Flipping a single dice 1000 times gives us a histogram with probability of around 0.5 for each of heads and tails. Notice that the sum of the probabilities is 1.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-320-1.png" width="672"></p>
<p>Here is the result of rolling a dice 1000 times:</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-321-1.png" width="672"></p>
<p>This is the result of rolling the same 2 die 1000 times:</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-322-1.png" width="672"></p>
<p>Do you notice a common characteristic among all the histograms we’ve seen so far? If we add up the area under the “curve,” we get a sum of 1. Let’s think about this intuitively. Each single dice roll is guaranteed to yield a result of 1, 2, 3, 4, 5, or 6. Thus, the sum of the probabilities of each result gives us 100%.</p>
<p>Another way to denote a histogram showing many coin tosses is P(coin), since the histogram is really a representation of all the possible results of the toss. Similarly, the histogram for rolling a single dice many times is P(dice).</p>
<p>A histogram is functionally a <strong>probability distribution function</strong> or <strong>PDF</strong>. A PDF in the field of statistics is a graph showing how likely a random observation would give a specific value on the x axis. With the first histogram where we flip 1 coin 1 time, for instance, the likelihood of getting the result we did is 1.</p>
<p>There is a caveat, though. The term PDF technically only applies to samples where the results on the x axis are continuous and not discrete values. The results of coin flips and die rolls seem to be discrete. However, let’s look back at the histograms. The height of the histogram, which represents probability, is not discrete; the height is continuous even though the results are discrete. Taking this observation one step further, we realize the following:</p>
<p>You technically can’t measure continuous anything. Even if you could, you wouldn’t be able to put it on a computer! Thus, we can functionally think of the histograms we’ve generated as PDFs.</p>
<p>Using our knowledge of PDFs, histograms, and simulations, we can solve a problem.</p>
<p>What are the odds of that the sum of two die will be seven? We could figure this out analytically, but a simulation in R is a easy way to predict and confirm our expected probability.</p>
<p>We create a dice and set the number of simulations. Next, we build a tibble and filter for observations where the sum of the die equals 7.</p>
<p><label for="tufte-mn-36" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-36" class="margin-toggle"><span class="marginnote"><span style="display: block;">Note that we could have hard-coded the <code>sims</code> value into the tibble call in step 3 by setting size = 10000. However, it is good practice to create a separate variable. This way, if we want to change the number of simulations, we do not need to manually change all of our code.</span></span></p>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb540-1"><a href="probability.html#cb540-1"></a>dice &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>)</span>
<span id="cb540-2"><a href="probability.html#cb540-2"></a></span>
<span id="cb540-3"><a href="probability.html#cb540-3"></a>sims &lt;-<span class="st"> </span><span class="dv">10000</span></span>
<span id="cb540-4"><a href="probability.html#cb540-4"></a></span>
<span id="cb540-5"><a href="probability.html#cb540-5"></a>mydata &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">dice_1 =</span> <span class="kw">sample</span>(dice, <span class="dt">size =</span> sims, <span class="dt">replace =</span> <span class="ot">TRUE</span>),</span>
<span id="cb540-6"><a href="probability.html#cb540-6"></a>                 <span class="dt">dice_2 =</span> <span class="kw">sample</span>(dice, <span class="dt">size =</span> sims, <span class="dt">replace =</span> <span class="ot">TRUE</span>))</span>
<span id="cb540-7"><a href="probability.html#cb540-7"></a></span>
<span id="cb540-8"><a href="probability.html#cb540-8"></a>count &lt;-<span class="st"> </span>mydata <span class="op">%&gt;%</span></span>
<span id="cb540-9"><a href="probability.html#cb540-9"></a><span class="st">  </span><span class="kw">filter</span>((dice_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>dice_<span class="dv">2</span>) <span class="op">%in%</span><span class="st"> </span><span class="dv">7</span>) <span class="op">%&gt;%</span></span>
<span id="cb540-10"><a href="probability.html#cb540-10"></a><span class="st">  </span><span class="kw">count</span>() <span class="op">%&gt;%</span></span>
<span id="cb540-11"><a href="probability.html#cb540-11"></a><span class="st">  </span><span class="kw">pull</span>(n)</span>
<span id="cb540-12"><a href="probability.html#cb540-12"></a></span>
<span id="cb540-13"><a href="probability.html#cb540-13"></a>probability &lt;-<span class="st"> </span>count<span class="op">/</span>sims</span></code></pre></div>
<p>In this simulation, we calculated a final probability of 0.1627.</p>
<p>To visualize the probability of different outcomes, we can build a histogram using the tibble we just created.</p>
<p>First, we create a column in our tibble containing the sum of the two die that we rolled.</p>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb541-1"><a href="probability.html#cb541-1"></a>mydata &lt;-<span class="st"> </span>mydata <span class="op">%&gt;%</span></span>
<span id="cb541-2"><a href="probability.html#cb541-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">sum =</span> (dice_<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>dice_<span class="dv">2</span>))</span>
<span id="cb541-3"><a href="probability.html#cb541-3"></a></span>
<span id="cb541-4"><a href="probability.html#cb541-4"></a><span class="kw">ggplot</span>(mydata, <span class="kw">aes</span>(<span class="dt">x =</span> sum)) <span class="op">+</span></span>
<span id="cb541-5"><a href="probability.html#cb541-5"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y=</span>..count..<span class="op">/</span><span class="kw">sum</span>(..count..)), <span class="dt">binwidth =</span> <span class="dv">1</span>, </span>
<span id="cb541-6"><a href="probability.html#cb541-6"></a>                 <span class="dt">fill =</span> <span class="st">"dark green"</span>, <span class="dt">color =</span> <span class="st">"white"</span>) <span class="op">+</span></span>
<span id="cb541-7"><a href="probability.html#cb541-7"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"Histogram Probability Distribution of Sum for Rolling 2 Die 10000 Times"</span>,</span>
<span id="cb541-8"><a href="probability.html#cb541-8"></a>       <span class="dt">x =</span> <span class="st">"Value of dice roll"</span>,</span>
<span id="cb541-9"><a href="probability.html#cb541-9"></a>       <span class="dt">y =</span> <span class="st">"Probability"</span>) <span class="op">+</span></span>
<span id="cb541-10"><a href="probability.html#cb541-10"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">12</span>,<span class="dv">1</span>), <span class="dt">labels =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">12</span>) <span class="op">+</span></span>
<span id="cb541-11"><a href="probability.html#cb541-11"></a><span class="st">  </span><span class="kw">theme_classic</span>()</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-325-1.png" width="672"></p>
<p>Similarly, we could create a more complicated simulation of the fall election
and count the number of observations involving Trump’s re-election. We could
simulate different weather patterns and count the number of observations involving
rain today.</p>
<p>Takeaway: we want to simulate a scenario as many times as possible, then count the number of observations with the desired outcome.</p>
</div>
<div id="tree-diagrams" class="section level2">
<h2>
<span class="header-section-number">5.4</span> Tree Diagrams</h2>
<div id="independence" class="section level3">
<h3>
<span class="header-section-number">5.4.1</span> Independence</h3>
<p>So far, you have learned how to calculate P(A), which is the fancy, statistical way of saying the probability of an event. When flipping a coin, the probability of getting heads was 1/2. You have also learned how to compute the P(A or B). This means the probability of either A or B happening. When rolling a dice, P(1 or 2)–the probability of getting a 1 or a 2–was 1/3.</p>
<p>What if you flipped 2 coins? You know that the probability of getting heads once is 1/2, but what are the odds of getting heads 2 times in a row? Let’s take a look at this tree diagram. We read this diagram from left to right. On the left, the probability of getting heads is 0.5. Now the tree branches out.</p>
<ul>
<li>
<em>If</em> we got heads the first time, then we go up the top branch. The probability of getting heads again is 0.5.</li>
<li>
<em>If</em> we got tails the first time, then we go down the bottom branch. The probability of getting heads is 0.5.</li>
</ul>
<p>Notice how regardless of what we get the first time we flip the coin, the probability of getting heads is 0.5 throughout. This suggests that the coin flips are <strong>independent</strong>. The result of one coin flip does not impact the likelihood of getting the same result next time. Take a look at the tree diagram. P(H given H) represents the probability of getting heads <em>given</em> that we got heads the first time. P(H given T) represents the probability of getting heads <em>given</em> that we got tails the first time. P(H given H) = P(H given T).</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-326-1.png" width="672"></p>
</div>
<div id="conditional-probability" class="section level3">
<h3>
<span class="header-section-number">5.4.2</span> Conditional probability</h3>
<p>Now imagine that 60% of people in a community have a disease. A doctor develops a test to determine if a random person has the disease. However, this test isn’t 100% accurate. This test is 80% sure of correctly returning positive <strong>if the person has the disease</strong> and 90% sure of correctly returning negative <strong>if the person does not have the disease</strong>.</p>
<p>This tree diagram illustrates exactly this. Starting from the left, we see that the probability of a random person having the disease is 0.6. Since they either have the disease or don’t (those are the only two possibilities), the probability that they don’t have the disease is 1 - 0.4.</p>
<p>Now the tree branches out.</p>
<ul>
<li>
<em>If</em> the random person has the disease, then we go down the top branch. The probability of the person testing positive is 0.8 because the test is 80% sure of correctly returning positive when the person has the disease.</li>
<li>By the same logic, <em>if</em> the random person does not have the disease, we go down the bottom branch. The probability of the person incorrectly testing positive is 0.1.</li>
</ul>
<p>We decide to go down the top branch <em>if</em> our random person has the disease. We go down the bottom branch <em>if</em> they do not. This is called <strong>conditional probability</strong>. The probability of testing positive is <strong>dependent</strong> on whether the person has the disease.</p>
<p>How would you express this in statistical notation? P(A|B) is the same thing as the probability of A <em>given</em> B. P(A|B) essentially means the probability of A <em>if</em> we know for sure that B is true.</p>
<p><label for="tufte-mn-37" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-37" class="margin-toggle"><span class="marginnote"><span style="display: block;"><strong>Positive:</strong> The test results suggest that the patient has the disease.</span>
<span style="display: block;"><strong>False Positive:</strong> The patient does not have the disease but the test results incorrectly suggest that they do.</span>
<span style="display: block;"><strong>Negative:</strong> The test results suggest that the patient does not have the disease.</span>
<span style="display: block;"><strong>False Negative:</strong> The patient has the disease but the test results incorrectly suggest that they do not.</span></span></p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-328-1.png" width="672"></p>
<p>This concept of conditional probability is relevant in our everyday lives. For example, the probability of Trump’s re-election might be different than the probability of Trump’s re-election <em>given</em> that we are in a recession. The probability of you reading a textbook might vary, <em>depending</em> on the likelihood of your instructor cold-calling you in class. Whenever you encounter a question involving conditional probability, drawing a tree diagram is a very useful approach to visualization.</p>
<!-- EC: This could be a good section to include a disclaimer about not mixing up P(B|A) and P(A|B). Alternatively, could add more examples to the section below that mentions they are different, since it is mentioned in passing -->
</div>
<div id="two-diagrams-for-one-set-of-coin-flips" class="section level3">
<h3>
<span class="header-section-number">5.4.3</span> Two Diagrams for One Set of Coin Flips</h3>
<p>In our histogram probability distribution, we didn’t care what combinations of numbers made each sum. We only cared about the outcome. There are two ways of thinking about a coin toss as well. Your tree diagram should look different depending on whether the order of the results matters.</p>
<p>To understand tree diagrams a little better, imagine you’re flipping 2 coins. Your tree diagram may look different depending what you’re interested in measuring.</p>
<p><label for="tufte-mn-38" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-38" class="margin-toggle"><span class="marginnote"><span style="display: block;">In this figure, the order of your coin toss results does not matter. We can imagine that you are rolling two coins together, or that you only care about the sum of the two die values.</span></span></p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-330-1.png" width="672"></p>
<p><label for="tufte-mn-39" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-39" class="margin-toggle"><span class="marginnote"><span style="display: block;">In this figure, the order of your coin toss results does matter. Depending on your first result, you go down a different branch.</span></span></p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-332-1.png" width="672"></p>
<!-- # Section 2: Trees as a formal structure for probability -->
<!-- 2 a) Describe trees. Show some diagrams. (Maybe save making these for later? Are their R packages for this?) This is the basic structure which we will use for everything in the chapter. We can make trees for the examples above. We can discuss important statistical concepts: like conditional probability, marginal probability in the context of a tree. We can highlight subtle cases: Like throw two dice together versus throw one dice and then a second dice. These make for different tree structures, but the same set of leaves. Show an unbalanced tree, in which one branch is a different length, like a craps game or maybe blackjack. Again, no mathematical formalism. Also, no Bayesian stuff. We are just taking the same examples from above and making them a little more structured.  -->
<!--https://github.com/YuLab-SMU/treedata-book is useful for tree diagrams-->
<!-- Discuss conditional probability and marginal probability using a simple tree with 0.6/0.4 first branch, and then next branches slightly different: 0.8/0.2 and 0.1/0.9. -->
<!-- We a tree, we can explain total probability, conditional probability and marginal probabity. Explain the meaning of p(A, B), p(A), p(B) and p(B|A). But that is it. Nothing more mathematical than that. Focus on words, directly connected to the tree images. -->
<!-- 2 b) Another coding session, but this time with list-columns and map_functions. These do not have to be long. We just want to re-iterate the points we made in words. Maybe we don't need list-columns. Maybe just show map functions here. Again, the point of this section is ONLY to understand the key probabity concepts: joint, total, conditional and marginal. -->
</div>
</div>
<div id="comparing-two-models" class="section level2">
<h2>
<span class="header-section-number">5.5</span> Comparing Two Models</h2>
<!-- # Section 3: Two Models, Scatterplots and Bayes Theorem -->
<!-- 3 a) Key point of this section is how we deal with the simplest possible situation. There are only two possibilities. Either you have the disease, or you don't. Walk through this problem with counts first. There are 100,000 people in the country. (Top of tree.) 0.1% have the disease, which is 100 people. 999,900 do not. (These are the two branches from the top.) We give the test to all 100,000 people. And so on. We have the four leaves, and then we just add the two branches which positive test results together, and then divide that into the total with the disease who tested positive. Presto! Your true odds.

See page 330 of the Bayesian Workshop for the use of the frequency format. Don't think in terms of percentages. Think in terms of counts. Would this be useful to show students?

       1000
      10   990
     8  2  95 895
     8/(8 + 95)

Should we start with counts and then go to probabilities, or just start with probabilities? Flip a coin 100 times, and get 53 heads and 47 tails. Or maybe explain with counts each time we learn a new thing, and then do with percentages. Note how all this ties into the below discussion. When we are playing with models, we just "know" what the percentages are. We use this knowledge to determine what a single data point means. But we also do the opposite! (Call this the inverse?) We collect a lot of data (counts?) and then use that data to estimate the probabilities in the tree. Hmmm. 

Then do another example, but point out we don't need the counts. Numbers are abritrary because we divide at the end. Show that.

Now that we understand trees, we can do some Bayes' Theorem examples by hand. We don't even show the formula! Just walk through the four leaves, and how we add two and then divide into one of them. -->
<!-- Then, with those ideas fixed, we make a Bayes Scatterplot with just two rows on the y-axis: have the disease or don't have the disease. (Or maybe we use another exmaple each time.) Since these two models have no fixed numeric meaning, we can just place them at 0 and 1 on the y-axis, which sort of corresponds to FALSE and TRUE. Then, we can x-axis we have the actual data. Which, in this case, is also a TRUE/FAlSE value: Either you tested positive or you tested negative, so also 0 and 1. Then, we can simulate. Put a 100,000 people through, fill out the values. There are only 4 possibilities, so we will need to jittter. (See below for an example of how to do this. And then explore the marginal distributions. Show how this gives you the same answer, roughly, as the math we did before.) -->
<!-- 3 b) Code up a full featured simulation exercise, like the cookie problem but with more complexity. See the old 1005 problem set. Connect this to how 538 does things. 99.99% of real world problems are solved with simulation, not analytically. -->
<!-- This prediction by 538 is really interesting: (https://projects.fivethirtyeight.com/2020-march-madness-predictions/), especially
pre-game. Is this what you mean by how 538 does things? Potentially link something
like this into the textbook to illustrate how simulations are used?  webshot() -->
<!-- Do we like all the words below? I am not sure. -->
<!-- adding my own version of this - looking for feedback IB -->
<p>Imagine you wake up one morning and feel a little bit under the weather. Not sick, just not 100%.
So, you go to your doctor and your doctor is confused. So, she runs a slew of tests and in a couple of days, one of them comes back positive. You’ve tested positive for a rare disease, called <span class="math inline">\(X\)</span>. Only <em>.1%</em> of the population has this disease. And the test correctly identifies you as positive <em>99%</em> of the time!</p>
<p>So, understandably worried, you ask yourself: what is the probability I have this disease?</p>
<p>The immediate, but <em>wrong</em>, answer would be 99%. Why is this wrong? Isn’t 99% the accuracy of the test? To understand, we’re going to abandon probability as a <em>proportion</em> (ie 99%) and think of it in <em>counts</em>.</p>
<p>Imagine you’re part of a population of 1000 people. Now, the frequency of the disease is .1%. In terms of a count, that means 1 person has this disease of the 1000 in the population. The test would probably correctly identify this individual. However, a test with an accuracy of 99% would also identify 10 other perfectly healthy people out of 1000 people as sick! That means that the number of people who would test positive for the disease is 11 but <em>only one of them has the disease</em>. So, in simple terms, the probability of you having the disease given a positive test is <span class="math inline">\(1\div11\)</span>!</p>
<p>It becomes easier to understand when you increase this population size 10,000 and model this!</p>
<p><img src="book_temp_files/figure-html/disease-1.png" width="672" style="display: block; margin: auto;"></p>
<p>Remember, we’re currently conceptualizing probability in counts. Therefore, a .1% chance of having the disease means 10 people have it and a 99% chance of testing correctly (a 1% chance of testing incorrectly) means 100 people were incorrectly identified as positive (in addition to the 10 people who tested positive correctly). So, to recap:</p>
<ul>
<li><p>10 people have the disease</p></li>
<li><p>They all tested positive</p></li>
<li><p>9990 people don’t have the disease</p></li>
<li><p>100 of them still tested positive</p></li>
</ul>
<p>There’s a population of 110 people who tested positive and only 10 of them have the disease. So, if you test positive, your chances of having the disease are <span class="math inline">\(10\div110\)</span>, which is equal to 9%!</p>
<p>Now, let’s switch back to proportion-based probabilities and think about it. Just because the probability of having the disease is .1% and the test is 99% accurate, it doesn’t mean that these are the exact numbers that always work out in the real world. That is, for a <em>sample</em> of 10,000, a disease frequency of .1% doesn’t necessarily mean that 10 people have the disease. It could be 11. Or 9. Or 20! Given that uncertainty, we do what we did above. We model. We built and understanding of the world and expressed it in counts. We then used that to understand what the implications of an event (testing positive) are on our belief that we have the disease. In the next section, we’ll follow the same principle but make this a little more complicated.</p>
</div>
<div id="comparing-three-models" class="section level2">
<h2>
<span class="header-section-number">5.6</span> Comparing Three Models</h2>
<!-- # Section 4: Three Models (use the the Two Marble Example) and Scatterplots -->
<!-- 4 a)  Bayes Scatterplots show how both the data and the model can be viewed as probability distributions. If I tell the the model, the you look down one axis to see what the pdf of the data is. If I show you the data, then you look down the other axis to see the posterior pdf of the model. -->
<!-- Having shown an example with two rows above, we now need an example with three. I like the two marble problem. (Cite Rethinking when you use it.) Bag of marbles contains either two white, two black or one of each. This can be formalized with a number p, which is the proportion of white marbles, which can only be 0, 0.5 or 1. Create a Bayes scatterplot for this case. Follow the coding style below. Show the marginal distributions after we observe some data. Big a useful number, like we did with 8 heads out of 20 above.-->
<!-- 4 b) Show the code for doing this, both the simulation itself and how to make the graphic. Key is that we do no math anywhere. -->
<!-- # Section 5: 11 and the 1001 models. Same as coin example with unknown p as used in Albert example. First, p is 0, 0.1, 0.2, ... 0.9, 1.0. Make Bayes Scatterplot. Show marginals. Then, extend it so p takes on 1,001 values. This is how we go from discrete to continuous. All the same tricks apply. -->
</div>
<div id="comparing-n-models" class="section level2">
<h2>
<span class="header-section-number">5.7</span> Comparing N Models</h2>
<!-- 5 a) Now go on to Rethinking approach. I think that chapter 2 is just genius. Bayesian is really just counting. Maybe we do a very similar example to what he does? Maybe different? I am still pondering this myself. I think that there is a deep relationship here. In the simple Bayes rule decision trees, we know all the probabilities. But what if we don't? Instead, we get to observe lots of data (which are counts!) and then, from that data, figure out the probabilities. (Note that Rethinking does not talk like this --- after all, we know all the probabilities since each marble has a 20% chance of being drawn --- but I think it is implicit in his approach.) Key issue: Can we connect this in a sensible way to Bayesian scatterplot. There is always the data and the model and the relationship between the two. (And "the model" means, mainly, the parameter estimates thereof.) Tell me the data, and I will tell you the model. Tell me the model, and I will tell you the model. -->
<!-- Note the connection between the marbles from Rethinking and the Bayesian scatterplot. In figure 2.2 in Rethinking represents the model where p = 0.25, where p is the proportion of blue marbles in the total collection. The y-axis models would be labeled with p = 0, 0.25, 0.5, 0.75, and 1. With the tree marble diagram in figure 2.2, we would be taking random samples with 3 marbles. The number of blue marbles we get each time would be plotted along p = 0.25. This is another example of model on the y-axis and data on the x-axis. -->
<p>Imagine there are 10 high schools in your district. Each high school has 1000 students. You are the statistics teacher at high school <span class="math inline">\(A\)</span> and the rest of the
high schools are <span class="math inline">\(B\)</span> through <span class="math inline">\(J\)</span>. You’re really into statistics and you have a
deep burning desire to know:</p>
<ul>
<li>What portion of high school students at my lovely school of <span class="math inline">\(A\)</span> love statistics?</li>
</ul>
<p>The easy way to answer this question would be to ask all 1000 of the students at <span class="math inline">\(A\)</span> whether they love statistics. You count up the “Yes” answers and divide by 1000 and boom! There’s your answer. However, the statistics department at <span class="math inline">\(A\)</span> is extremely underfunded and you only have the power to ask 20 random students this question. So, you ask 20 random students and you get 8 “Yes” answers. Is the proportion of students that love statistics at high school <span class="math inline">\(A\)</span> equal to <span class="math inline">\(8\div20 = .4\)</span>?</p>
<p>The correct answer is … you don’t know. Rather, this is information that may help you better understand the true (unknown) answer. So, where do you go from here?</p>
<p>The next question you ask is “well … how likely is it to get a sample of 20 with a sample proportion of .4 for various population proportions?” That is, if the population proportion is <span class="math inline">\(500\div1000 = .5\)</span>, how likely is it I get a sample of 20 with 8 “Yes” answers.</p>
<p>Or, if the population proportion is .3, how likely is it I get a sample of 20 with 8 “Yes” answers?</p>
<p>You contact all your other statistics teacher friends at high schools <span class="math inline">\(B\)</span> through <span class="math inline">\(J\)</span>. Those statistics teacher are much more fortunate than you and have plenty of resources! They tell you that they were able to ask each one of the students the question and get a precise answer for the proportion of their students who love statistics! Great for them, but how does this help you.</p>
<p>Well, incidentally, each of the other high schools has a distinct and exact proportion of students. At <span class="math inline">\(B\)</span>, the teacher discovered that <span class="math inline">\(100\div1000 = .1\)</span> students love statistics. At <span class="math inline">\(C\)</span>, the teacher discovered that <span class="math inline">\(200\div1000 = .2\)</span> students love statistics. This goes on and it turns out high school <span class="math inline">\(J\)</span> has <span class="math inline">\(900\div1000 = .9\)</span> students that love statistics.</p>
<p>Well, each of these schools can serve as a <em>model</em> for sampling from a population with a given proportion.</p>
<p>You’re pretty smart and so you ask each of your friends to repeatedly choose 20 random students at their schools and ask them if they love statistics. Your helpful teacher friends record the answers.</p>
<ul>
<li>To clarify, the teacher at <span class="math inline">\(B\)</span> is asking random samples of 20 students whether they love statistics from a population in which 10% of the students love statistics.</li>
</ul>
<p>So, at high school <span class="math inline">\(B\)</span>, if the teacher asked 1000 groups of 20 random students, the distribution of the proportions of each group the teacher asked look like this:</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-333-1.png" width="672"></p>
<p>This means that with a population proportion of .1, the teacher is likely to get answers that range from [.05, .5]. You, at your high school, with a sample proportion of .4, could easily fall into this. It could be the case that your population proportion is actually .1.</p>
<p>Suppose the teacher at high school <span class="math inline">\(J\)</span> did this? Remember, <span class="math inline">\(J\)</span> has a 90% proportion of yes answers.</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-334-1.png" width="672"></p>
<p>Then, your answers range from [.65, 1]!</p>
<p>So at your high school (where you got a sample proportion of .4), you can probabaly conclude your population percentage is not .9. That is, it’s very unlikely 900 out of 1000 students at your high school <span class="math inline">\(A\)</span> love statistics. Why? Because your sample from <span class="math inline">\(A\)</span> gave you a proportion of .4 and when we sampled from high school <span class="math inline">\(J\)</span> (where we’re sure the actual population proportion is .9), we got zero samples that had a proportion of .4.</p>
<p>This is how each of these other high schools is a model you can use to update your understanding of where your high school is. That’s because you can use them to determine what samples look like if the population you are sampling from had various proportions.</p>
<p>What if we did this for every high school <span class="math inline">\(B\)</span> through <span class="math inline">\(J\)</span>?</p>
<p><img src="book_temp_files/figure-html/unnamed-chunk-335-1.png" width="672"></p>
<p>Clarifying notes:</p>
<ul>
<li>Each row is a population (or “high school”) and at each high school, we’ve surveyed 1000 random groups of 20 and recorded the proportions. The darkness of each cluster represents how many individual samples are in that area. The clusters with few, lighter points are less likely to occur in the sampling distribution. So, for example, if I wanted to know the sampling distribution of one particular high school, I’d look at that row. The animation below illustrates this concept:</li>
</ul>
<p><img src="05-probability/animations/color_red_combo.gif"></p>
<ul>
<li>Read the graph vertically (find a point along the x-axis and look up) if you’re trying to figure out in which population proportion(s) your sample statistic appears.</li>
</ul>
<p><label for="tufte-mn-40" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-40" class="margin-toggle"><span class="marginnote"><span style="display: block;">Jim Albert goes through a very similar example and as he points out: “The histogram of the simulated values of the proportion p reflects the prior distribution that we placed on this parameter. The histogram of the simulated values of the data y is also meaningful. This is the distribution of data that is plausible assuming our prior on p and the binomial sampling model.”</span>
<span style="display: block;"><em>Read more: Jim Albert (1997) Teaching Bayes Rule: A Data-Oriented Approach, The American Statistician, 51:3, 247-253</em></span></span></p>
<ul>
<li>Read the graph horizontally (find a point on the y-axis and look to the side) if you’re trying to figure out the distribution of sample statistics given a population proportion.</li>
</ul>
<p>So, from this scatterplot you can observe some interesting things about your own initial sample of 20 at high school <span class="math inline">\(A\)</span>.</p>
<ul>
<li><p>You got a sample proportion of .2. If you find that place on the x-axis, you can see all of the population proportions for which that sample proportion occurs. That would be from .1 to .5! You’re pretty confident your high school has a proportion somewhere in there!</p></li>
<li><p>In fact, you even know the how likely a sample proportion tends to appear in a population proportion. While a .6 proportion population sometimes gives a sample with a proportion of .2, it doesn’t do so as often as a population with the proportion of .2. If you took 10 more samples of 20 at your high school and got values close to .2, you’re increasing your confidence the population of your high school is closer to .2</p></li>
<li><p>The above means you can use this scatterplot to estimate a confidence interval for your sample of 20. If you want a 90% confidence interval, find population proportions which have a sampling distribution in which this sample result is in the middle 90% of the data!</p></li>
</ul>
<p>There are a few key takeaways we want to note in this situation.</p>
<p>First, we are uncertain about the actual proportion of the population that loves statistics. This is likely to always be the case - that we are uncertain about the parameter. We won’t really know what the true probability is. We can however, become better informed about what it could be. For that, we use models. That is the principle expressed in this in this example. We created a bunch of models for each potential probability and used the results of those models to understand which model is more or less likely to explain our specific results.</p>
<p>Second,</p>
</div>
<div id="testing-is-evil" class="section level2">
<h2>
<span class="header-section-number">5.8</span> Testing is Evil</h2>
<!-- Introduce concepts like the null model, testing, and p-values. Connect to permutation tests from chapter 3.  Side note quotation: "Amatuers test. Professionals summarize." Maybe we should pick an example in which the number of heads is low enough to provide some reasonable evidence against p = 0.5. -->
<p>In some fields, it is common to want to test a specific hypothesis. Consider the hypothesis that the coin is fair, i.e., that <span class="math inline">\(p = 0.5\)</span>. Does the data we have support or reject that hypothesis? (Be wary that <span class="math inline">\(p\)</span> is both used for the probability of a head and the <span class="math inline">\(p\)</span>-value of a hypothesis test.)</p>
<p>Not really interested in that exact test except in toy scenarios.</p>
<p>Difference between 0.04 and 0.06 is rarely significant. And is hardly ever a good reason to decide X over Y.</p>
</div>
<div id="posterior-predictions-advanced" class="section level2">
<h2>
<span class="header-section-number">5.9</span> Posterior Predictions (Advanced)</h2>
<p>Looking at the marginal distributions from the Bayes scatterplots shows us the posterior distribution of the data, conditioning on the model, and of the model, conditioning on the data. In other words, if the model us true, this is what we believe about the distribution of the data, both the data that we have already seen and about the data we will see in the future, assuming that that the model is true.</p>
<p>But such a forecast is, in the real world, not the best forecast possible because it is assuming that the model is 100% true — in this case, that <span class="math inline">\(p = 0.4\)</span> — even though we don’t know, for certain, that the model is true. Indeed, the whole point of the Bayesian scatter plot is to show that, if we see 8 heads in 20 tosses, that, although <span class="math inline">\(p = 0.4\)</span> is the most likely model, it could be that <span class="math inline">\(p = 0.3\)</span> or <span class="math inline">\(p = 0.5\)</span>. <em>We are uncertain about what <span class="math inline">\(p\)</span> is.</em> The best possible forecast will incorporate that uncertainty, will not pretend that we know, for certain, that <span class="math inline">\(p = 0.4\)</span>. Forecasts which incorporate our uncertainty about parameter values are called “posterior predictions.”</p>
<p>To construct posterior predictions, we do the same sampling proceedure as with the Bayes scatterplots, while averaging over the rest of possible values for <span class="math inline">\(p\)</span>, weighted by their relative likelihood. Recall the analysis above:</p>
<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb542-1"><a href="probability.html#cb542-1"></a><span class="co"># Same code to get set up as before. But 10,000 this time for more stability,</span></span>
<span id="cb542-2"><a href="probability.html#cb542-2"></a><span class="co"># and to really see some extreme values for p. Don't need to show this code</span></span>
<span id="cb542-3"><a href="probability.html#cb542-3"></a><span class="co"># again. Maybe just show the plot.</span></span>
<span id="cb542-4"><a href="probability.html#cb542-4"></a></span>
<span id="cb542-5"><a href="probability.html#cb542-5"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb542-6"><a href="probability.html#cb542-6"></a></span>
<span id="cb542-7"><a href="probability.html#cb542-7"></a>mod &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="fl">0.1</span>)</span>
<span id="cb542-8"><a href="probability.html#cb542-8"></a>rep &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">10000</span></span>
<span id="cb542-9"><a href="probability.html#cb542-9"></a>toss &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">20</span></span>
<span id="cb542-10"><a href="probability.html#cb542-10"></a></span>
<span id="cb542-11"><a href="probability.html#cb542-11"></a>x &lt;-<span class="st"> </span><span class="kw">crossing</span>(mod, rep, toss) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb542-12"><a href="probability.html#cb542-12"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">result =</span> <span class="kw">ifelse</span>(<span class="kw">runif</span>(<span class="dt">n =</span> <span class="kw">nrow</span>(.)) <span class="op">&lt;</span><span class="st"> </span>mod, <span class="dv">1</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb542-13"><a href="probability.html#cb542-13"></a><span class="st">  </span><span class="kw">group_by</span>(mod, rep)  <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb542-14"><a href="probability.html#cb542-14"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">total =</span> <span class="kw">sum</span>(result)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb542-15"><a href="probability.html#cb542-15"></a><span class="st">  </span><span class="kw">filter</span>(total <span class="op">==</span><span class="st"> </span><span class="dv">8</span>)</span></code></pre></div>
<pre><code>## `summarise()` regrouping output by 'mod' (override with `.groups` argument)</code></pre>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb544-1"><a href="probability.html#cb544-1"></a><span class="co"># Show that the plot is the same, but highlight that there is a chance, however</span></span>
<span id="cb544-2"><a href="probability.html#cb544-2"></a><span class="co"># miniscule, that p is 0.8 or 0.1. </span></span>
<span id="cb544-3"><a href="probability.html#cb544-3"></a></span>
<span id="cb544-4"><a href="probability.html#cb544-4"></a>x <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb544-5"><a href="probability.html#cb544-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> mod)) <span class="op">+</span></span>
<span id="cb544-6"><a href="probability.html#cb544-6"></a><span class="st">    </span><span class="kw">geom_bar</span>(<span class="kw">aes</span>(<span class="dt">y =</span> (..count..)<span class="op">/</span><span class="kw">sum</span>(..count..))) <span class="op">+</span><span class="st"> </span></span>
<span id="cb544-7"><a href="probability.html#cb544-7"></a><span class="st">    </span><span class="kw">scale_y_continuous</span>(<span class="dt">labels=</span>percent) <span class="op">+</span></span>
<span id="cb544-8"><a href="probability.html#cb544-8"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">"Posterior Estimate of p Given 8 Heads in 20 Flips"</span>,</span>
<span id="cb544-9"><a href="probability.html#cb544-9"></a>         <span class="dt">subtitle =</span> <span class="st">"p is more likely to be something other than 0.4"</span>,</span>
<span id="cb544-10"><a href="probability.html#cb544-10"></a>         <span class="dt">x =</span> <span class="st">"Probability of Heads"</span>,</span>
<span id="cb544-11"><a href="probability.html#cb544-11"></a>         <span class="dt">y =</span> <span class="st">"Posterior"</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-337-1.png" width="672"></p>
<p>Although the most likely value for <span class="math inline">\(p\)</span> is 0.4, it is actually more likely that <span class="math inline">\(p\)</span> is a different value than 0.4, either lower or higher and, potentially, much lower or higher. To get the correct uncertainty in our forecasts for the number of heads in the next 20 tosses, we need to incorporate that uncertainty directly.</p>
<div class="sourceCode" id="cb545"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb545-1"><a href="probability.html#cb545-1"></a><span class="co"># Did not get around to finishing this.</span></span>
<span id="cb545-2"><a href="probability.html#cb545-2"></a></span>
<span id="cb545-3"><a href="probability.html#cb545-3"></a>x <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb545-4"><a href="probability.html#cb545-4"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>rep, <span class="op">-</span>total) </span></code></pre></div>
<pre><code>## # A tibble: 4,827 x 1
## # Groups:   mod [8]
##      mod
##    &lt;dbl&gt;
##  1   0.1
##  2   0.1
##  3   0.1
##  4   0.1
##  5   0.1
##  6   0.2
##  7   0.2
##  8   0.2
##  9   0.2
## 10   0.2
## # … with 4,817 more rows</code></pre>
</div>
<div id="key-themes" class="section level2">
<h2>
<span class="header-section-number">5.10</span> Key Themes</h2>
<!-- Mention recurring theme.
-->
<p>Casino talk.</p>
<div id="model-structure" class="section level3">
<h3>
<span class="header-section-number">5.10.1</span> Model Structure</h3>
<p>Is <span class="math inline">\(P_h\)</span> constant?</p>
</div>
<div id="parameter-uncertainty" class="section level3">
<h3>
<span class="header-section-number">5.10.2</span> Parameter Uncertainty</h3>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-339"></span>
<img src="05-probability/images/coin_flip.jpg" alt="Coin Flip Uncertainty."><!--
<p class="caption marginnote">-->FIGURE 5.2: Coin Flip Uncertainty.<!--</p>-->
<!--</div>--></span>
</p>
<p><span class="math inline">\(p(MI)\)</span></p>
<p><span class="math inline">\(p(P_h)\)</span> Only people who hate students do that sort of stuff.</p>
<p><span class="math inline">\(p(H=10)\)</span></p>
<p>Suppose your friend sets up a pseudo-casino in the playground of the neighborhood school. He’s offering everyone the opportunity to play probability games and bet money. The first game is simple: coin tosses. If the coin lands on heads, you get five dollars. If it lands on tails, you pay three dollars.</p>
<p>You have a sneaking suspicion that the coin isn’t fair and you ask your friend to flip it 10 times to test your theory. However, you must not be overconfident. 10 observations might be too few to judge the fairness of the coin. Perhaps your friend secretly switches coins when it comes time for the actual betting and your sample in the initial simulation is nonrepresentative. You might be nervous about losing your money and even miscount the number of heads and tails. These are all examples of <strong>parameter uncertainty</strong>. Sometimes, a model has the correct form. But it’s not practical to run the simulation millions of times to be certain of the outcome. It’s not possible to be absolutely certain that your friend isn’t switching coins. A perfect world does not exist, so we must have reservations when drawing likely conclusions.</p>
</div>
<div id="unmodeled-variation" class="section level3">
<h3>
<span class="header-section-number">5.10.3</span> Unmodeled Variation</h3>
<p>(This may be difficult to talk about since we don’t (?) write down formulas with error terms.) But each chapter should discuss the concept of a residual. Even if we have perfect parameter estimates for a model structure which matches the unknown data generating mechanism, we still won’t make perfect predictions. Some randomness is intrinsic. Example: prediction for an individual.</p>
<p>result = model + other stuff, where other stuff is variation which is not part of the model, i.e., it is</p>
<p>45 = 40 + 5</p>
<p>unmodeled variation. <em>residual</em>; <em>fitted value</em> <em>expected value</em></p>
<p>result = fitted (expected) value + residual</p>
</div>
<div id="predictive-uncertainty" class="section level3">
<h3>
<span class="header-section-number">5.10.4</span> Predictive Uncertainty</h3>
<p>Still conditional on model structure. p(result from experiment to come)</p>
</div>
<div id="unknown-unknowns-1" class="section level3">
<h3>
<span class="header-section-number">5.10.5</span> Unknown Unknowns</h3>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-340"></span>
<img src="05-probability/images/donald_rumsfeld.jpg" alt="Donald Rumsfeld."><!--
<p class="caption marginnote">-->FIGURE 5.3: Donald Rumsfeld.<!--</p>-->
<!--</div>--></span>
</p>
<p>Donald Rumsfeld, the former US Secretary of Defense, once said the following tongue-twisting quote:</p>
<p>“There are known knowns. There are things we know we know. We also know there are known unknowns. That is to say, we know there are some things we do not know. But there are also unknown unknowns, the ones we do not know we do not know.”</p>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">--><span id="fig:unnamed-chunk-341"></span>
<img src="05-probability/images/Three_Card_Monte.jpg" alt="Three Card Monte."><!--
<p class="caption marginnote">-->FIGURE 5.4: Three Card Monte.<!--</p>-->
<!--</div>--></span>
</p>
<p>What does this mean? Well imagine a crowd playing Three Card Monte in the streets of New York. The guy running the game runs a demo and shows you all the cards to make you confident. They earn money by making you overconfident and persuading you to bet. Your odds may seem good during the demo round, but that doesn’t actually say anything about what will likely happen when the real, high stakes game begins. The person running the game does many simulations, making the “victim” forget that they cannot actually make any conclusions about the odds of winning. There are some variables that we simply do not know. People can be using slight of hand, for instance.</p>

</div>
</div>
</div></body></html>

<p style="text-align: center;">
<a href="functions.html"><button class="btn btn-default">Previous</button></a>
<a href="sampling.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-07-08
</p>
</div>
</div>



</body>
</html>
