<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Chapter 7 Two Parameters | Gov 50: Data" />
<meta property="og:type" content="book" />



<meta name="github-repo" content="davidkane9/PPBDS" />



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Chapter 7 Two Parameters | Gov 50: Data">

<title>Chapter 7 Two Parameters | Gov 50: Data</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.0/str_view.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Gov 50: Data<p><p class="author"></p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="index.html"></a>
<a href="preamble.html">Preamble</a>
<a href="shopping-week.html">Shopping Week</a>
<a href="visualization.html"><span class="toc-section-number">1</span> Visualization</a>
<a href="wrangling.html"><span class="toc-section-number">2</span> Wrangling</a>
<a href="rubin-causal-model.html"><span class="toc-section-number">3</span> Rubin Causal Model</a>
<a href="functions.html"><span class="toc-section-number">4</span> Functions</a>
<a href="probability.html"><span class="toc-section-number">5</span> Probability</a>
<a href="one-parameter.html"><span class="toc-section-number">6</span> One Parameter</a>
<a id="active-page" href="two-parameters.html"><span class="toc-section-number">7</span> Two Parameters</a><ul class="toc-sections">
<li class="toc"><a href="#resampling-tactile"> Pennies example</a></li>
<li class="toc"><a href="#eda-for-nhanes"> EDA for <code>nhanes</code></a></li>
<li class="toc"><a href="#using-bootstraps-with-nhanes"> Using Bootstraps with <code>nhanes</code></a></li>
<li class="toc"><a href="#show-that-bootstrap-works"> Show that Bootstrap Works</a></li>
<li class="toc"><a href="#watch-me-wave-my-hands"> Watch me wave my hands</a></li>
<li class="toc"><a href="#NA"> <code>stan_glm()</code></a></li>
<li class="toc"><a href="#NA"> Diving into MAD_SD</a></li>
<li class="toc"><a href="#unpacking-the-first-parameter-the-intercept"> Unpacking the first parameter: the intercept</a></li>
<li class="toc"><a href="#unpacking-the-second-parameter-sigma"> Unpacking the second parameter: sigma</a></li>
<li class="toc"><a href="#NA"> Comparing lm and stan_glm</a></li>
<li class="toc"><a href="#visualizing-the-results-of-the-linear-model"> Visualizing the results of the linear model</a></li>
<li class="toc"><a href="#wisdom"> Wisdom</a></li>
<li class="toc"><a href="#justice"> Justice</a></li>
<li class="toc"><a href="#courage"> Courage</a></li>
<li class="toc"><a href="#temperance"> Temperance</a></li>
</ul>
<a href="three-parameters.html"><span class="toc-section-number">8</span> Three Parameters</a>
<a href="n-parameters.html"><span class="toc-section-number">9</span> N Parameters</a>
<a href="model-choice.html"><span class="toc-section-number">10</span> Model Choice</a>
<a href="continuous-response.html"><span class="toc-section-number">11</span> Continuous Response</a>
<a href="discrete-response.html"><span class="toc-section-number">12</span> Discrete Response</a>
<a href="appendices.html">Appendices</a>
<a href="tools.html">Tools</a>
<a href="shiny.html">Shiny</a>
<a href="maps.html">Maps</a>
<a href="animation.html">Animation</a>
<a href="references.html">References</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="two-parameters" class="section level1">
<h1>
<span class="header-section-number">Chapter 7</span> Two Parameters</h1>
<p>What is the average height of an American male? What is the 90th percentile of the distribution of height for American men? How certain are you are your estimates? If we past 5 men walking down the street, what are the odds that the tallest will be at least 5 centimeters taller than the shortest?</p>
<div id="resampling-tactile" class="section level2">
<h2>
<span class="header-section-number">7.1</span> Pennies example</h2>
<p>In Chapter <a href="one-parameter.html#one-parameter">6</a>, we studied sampling. We started with a “tactile” exercise where we wanted to know the proportion of balls in the urn that are red. While we could have performed an exhaustive count, this would have been a tedious process. So instead, we used a shovel to extract a sample of 50 balls and used the resulting proportion that were red as an <em>estimate</em>. Furthermore, we made sure to mix the urn’s contents before every use of the shovel. Because of the randomness created by the mixing, different uses of the shovel yielded different proportions red and hence different estimates of the proportion of the urn’s balls that are red.</p>
<p>Remember: There is a <em>truth</em> here. There is an urn. It has red and white balls in it. An exact, but unknown, number of the balls are red. An exact, but unknown, number of the balls are white. An exact, but unknown, percentage of the balls are red – defined as the number red divided by the sum of the number red and the number white. Our goal was to estimate that unknown percentage. We wanted to make statements about the world, even if we can never be certain that those statements are <em>true</em>. We will never have the time or inclination to actually count all the balls. We use the term <em>parameter</em> for things that exist but which are unknown. We use statistics to estimate the true values of parameters.</p>
<p>We then mimicked this <em>physical</em> sampling exercise with an equivalent <em>virtual</em> sampling exercise using the computer. In Subsection <a href="one-parameter.html#different-shovels">6.2.4</a>, we repeated this sampling procedure 1,000 times, using three different virtual shovels with 25, 50, and 100 slots. We visualized these three sets of 1,000 estimates in Chapter 6 and saw that as the sample size increased, the variation in the estimates decreased. We then expanded this for all sample sizes from 1 to 100.</p>
<p>In doing so, we constructed <em>sampling distributions</em>. The motivation for taking a 1,000 repeated samples and visualizing the resulting estimates was to study how these estimates varied from one sample to another; in other words, we wanted to study the effect of <em>sampling variation</em>. We quantified the variation of these estimates using their standard deviation, which has a special name: the <em>standard error</em>. In particular, we saw that as the sample size increased from 1 to 100, the standard error decreased and thus the sampling distributions narrowed. Larger sample sizes led to more <em>precise</em> estimates that varied less around the center.</p>
<!-- Distinguish further the difference between standard deviation and standard error in the above paragraph. Readers can confuse the two. -->
<p>We then tied these sampling exercises to terminology and mathematical notation related to sampling in Subsection <a href="one-parameter.html#terminology-and-notation">6.3.1</a>. Our <em>study population</em> was the large urn with <span class="math inline">\(N\)</span> = 2,400 balls, while the <em>population parameter</em>, the unknown quantity of interest, was the population proportion <span class="math inline">\(p\)</span> of the urn’s balls that were red. Since performing a <em>census</em> would be expensive in terms of time and energy, we instead extracted a <em>sample</em> of size <span class="math inline">\(n\)</span> = 50. The <em>point estimate</em>, also known as a <em>sample statistic</em>, used to estimate <span class="math inline">\(p\)</span> was the sample proportion <span class="math inline">\(\hat{p}\)</span> of these 50 sampled balls that were red. Furthermore, since the sample was obtained at <em>random</em>, it can be considered as <em>unbiased</em> and as <em>representative</em> of the population. Thus any results based on the sample could be <em>generalized</em> to the population. Therefore, the proportion of the shovel’s balls that were red was a “good guess” of the proportion of the urn’s balls that are red. In other words, we used the sample to draw <em>inferences</em> about the population.</p>
<p>However, as described in Section <a href="one-parameter.html#sampling-simulation">6.2</a>, both the physical and virtual sampling exercises are not what one would do in real life. This was merely an activity used to study the effects of sampling variation. In a real life situation, we would not take 1,000 samples of size <span class="math inline">\(n\)</span>, but rather take a <em>single</em> representative sample that’s as large as possible. Additionally, we knew that the true proportion of the urn’s balls that were red was 37.5%. In a real-life situation, we will not know what this value is. Because if we did, then why would we take a sample to estimate it?</p>
<p>An example of a realistic sampling situation would be a poll, like the <a href="https://www.npr.org/sections/itsallpolitics/2013/12/04/248793753/poll-support-for-obama-among-young-americans-eroding">Obama poll</a> you saw in Section <a href="one-parameter.html#sampling-case-study">6.4</a>. Pollsters did not know the true proportion of <em>all</em> young Americans who supported President Obama in 2013, and thus they took a single sample of size <span class="math inline">\(n\)</span> = 2,089 young Americans to estimate this value.</p>
<p>So how does one quantify the effects of sampling variation when you only have a <em>single sample</em> to work with? You cannot directly study the effects of sampling variation when you only have one sample. One common method to study this is <em>bootstrapping resampling</em>.</p>
<p>What if we would like, not only a single estimate of the unknown population parameter, but also a <em>range of highly plausible</em> values? Going back to the Obama poll article, it stated that the pollsters’ estimate of the proportion of all young Americans who supported President Obama was 41%. But in addition it stated that the poll’s “margin of error was plus or minus 2.1 percentage points.” This “plausible range” was [41% - 2.1%, 41% + 2.1%] = [38.9%, 43.1%]. This range of plausible values is what’s known as a <em>confidence interval</em>, which will be the focus of the later sections of this chapter.</p>
<div id="to-the-bank" class="section level3">
<h3>
<span class="header-section-number">7.1.1</span> To the Bank</h3>
<p>As we did in Chapter <a href="one-parameter.html#one-parameter">6</a>, we’ll begin with a hands-on tactile activity. We almost always need the <strong>tidyverse</strong> package.</p>
<div class="sourceCode" id="cb843"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb843-1"><a href="two-parameters.html#cb843-1"></a><span class="kw">library</span>(PPBDS.data)</span>
<span id="cb843-2"><a href="two-parameters.html#cb843-2"></a><span class="kw">library</span>(rsample)</span>
<span id="cb843-3"><a href="two-parameters.html#cb843-3"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb843-4"><a href="two-parameters.html#cb843-4"></a><span class="kw">library</span>(skimr)</span>
<span id="cb843-5"><a href="two-parameters.html#cb843-5"></a><span class="kw">library</span>(gtsummary)</span>
<span id="cb843-6"><a href="two-parameters.html#cb843-6"></a><span class="kw">library</span>(rstanarm)</span></code></pre></div>
<p><strong>PPBDS.data</strong> includes the data sets for this book. <strong>rsample</strong> includes functions for bootstrapping, the main statistical tool which will we use in this chapter.</p>
</div>
<div id="what-is-the-average-year-on-us-pennies-in-2019" class="section level3">
<h3>
<span class="header-section-number">7.1.2</span> What is the average year on US pennies in 2019?</h3>
<p>Try to imagine all the pennies being used in the United States in 2019. That’s a lot of pennies! Now say we’re interested in the average year of minting of <em>all</em> these pennies. One way to compute this value would be to gather up all pennies being used in the US, record the year, and compute the average. However, this would be near impossible! So instead, let’s collect a <em>sample</em> of 50 pennies from a local bank in downtown Northampton, Massachusetts, USA as seen in the photo below</p>
<div class="figure">
<span id="fig:unnamed-chunk-652-1"></span>
<p class="caption marginnote shownote">
FIGURE 7.1: Collecting a sample of 50 US pennies from a local bank.
</p>
<img src="07-two-parameters/images/bank.jpg" alt="Collecting a sample of 50 US pennies from a local bank." width="2016">
</div>
<div class="figure">
<span id="fig:unnamed-chunk-652-2"></span>
<p class="caption marginnote shownote">
FIGURE 7.2: Collecting a sample of 50 US pennies from a local bank.
</p>
<img src="07-two-parameters/images/roll.jpg" alt="Collecting a sample of 50 US pennies from a local bank." width="2016">
</div>
<p>An image of these 50 pennies can be seen in below. For each of the 50 pennies starting in the top left, progressing row-by-row, and ending in the bottom right, note there is an “ID” identification variable printed in black and the year of minting printed in white.</p>
<div class="figure">
<span id="fig:unnamed-chunk-653"></span>
<p class="caption marginnote shownote">
FIGURE 7.3: 50 US pennies labelled.
</p>
<img src="07-two-parameters/images/3.jpg" alt="50 US pennies labelled." width="804">
</div>
<p>Run the <code>pennies_sample</code> code below to extract our 50 sampled pennies.</p>
<div class="sourceCode" id="cb844"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb844-1"><a href="two-parameters.html#cb844-1"></a>pennies_sample &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">ID =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">50</span>), </span>
<span id="cb844-2"><a href="two-parameters.html#cb844-2"></a>                         <span class="dt">year =</span> <span class="kw">c</span>(<span class="dv">2002</span>, <span class="dv">1986</span>, <span class="dv">2017</span>, <span class="dv">1988</span>, <span class="dv">2008</span>, <span class="dv">1983</span>, <span class="dv">2008</span>, </span>
<span id="cb844-3"><a href="two-parameters.html#cb844-3"></a>                                  <span class="dv">1996</span>, <span class="dv">2004</span>, <span class="dv">2000</span>, <span class="dv">1994</span>, <span class="dv">1995</span>, <span class="dv">2015</span>, <span class="dv">1978</span>, </span>
<span id="cb844-4"><a href="two-parameters.html#cb844-4"></a>                                  <span class="dv">1974</span>, <span class="dv">2015</span>, <span class="dv">2016</span>, <span class="dv">1996</span>, <span class="dv">1983</span>, <span class="dv">1971</span>, <span class="dv">1981</span>, </span>
<span id="cb844-5"><a href="two-parameters.html#cb844-5"></a>                                  <span class="dv">1976</span>, <span class="dv">1998</span>, <span class="dv">2017</span>, <span class="dv">1979</span>, <span class="dv">1979</span>, <span class="dv">1993</span>, <span class="dv">2006</span>, </span>
<span id="cb844-6"><a href="two-parameters.html#cb844-6"></a>                                  <span class="dv">1988</span>, <span class="dv">1978</span>, <span class="dv">2013</span>, <span class="dv">1976</span>, <span class="dv">1979</span>, <span class="dv">1985</span>, <span class="dv">1985</span>, </span>
<span id="cb844-7"><a href="two-parameters.html#cb844-7"></a>                                  <span class="dv">2015</span>, <span class="dv">1962</span>, <span class="dv">1999</span>, <span class="dv">2015</span>, <span class="dv">1990</span>, <span class="dv">1992</span>, <span class="dv">1997</span>, </span>
<span id="cb844-8"><a href="two-parameters.html#cb844-8"></a>                                  <span class="dv">2018</span>, <span class="dv">2015</span>, <span class="dv">1997</span>, <span class="dv">2017</span>, <span class="dv">1982</span>, <span class="dv">1988</span>, <span class="dv">2006</span>, </span>
<span id="cb844-9"><a href="two-parameters.html#cb844-9"></a>                                  <span class="dv">2017</span>))</span>
<span id="cb844-10"><a href="two-parameters.html#cb844-10"></a>pennies_sample</span></code></pre></div>
<pre><code>## # A tibble: 50 x 2
##       ID  year
##    &lt;int&gt; &lt;dbl&gt;
##  1     1  2002
##  2     2  1986
##  3     3  2017
##  4     4  1988
##  5     5  2008
##  6     6  1983
##  7     7  2008
##  8     8  1996
##  9     9  2004
## 10    10  2000
## # … with 40 more rows</code></pre>
<p>The <code>pennies_sample</code> data frame has 50 rows corresponding to each penny with two variables. The first variable <code>ID</code> corresponds to the ID labels in our table above, whereas the second variable <code>year</code> corresponds to the year of minting saved as a numeric variable, also known as a double (<code>dbl</code>).</p>
<p>Additionally, let’s look at what a Preceptor Table would look like in this <code>pennies_sample example</code>. Essentially, what we are seeing is that if you are given a random penny in 2019, we are trying to estimate what they year is for that random penny. The last row is your best guess if that random year is given, because given that we are dealing with one parameter we are only dealing with one row. This would be different with two paramters because then we would have two rows.</p>
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#vngjguzslq .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#vngjguzslq .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vngjguzslq .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#vngjguzslq .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#vngjguzslq .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vngjguzslq .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#vngjguzslq .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#vngjguzslq .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#vngjguzslq .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#vngjguzslq .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#vngjguzslq .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#vngjguzslq .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#vngjguzslq .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#vngjguzslq .gt_from_md > :first-child {
  margin-top: 0;
}

#vngjguzslq .gt_from_md > :last-child {
  margin-bottom: 0;
}

#vngjguzslq .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#vngjguzslq .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#vngjguzslq .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vngjguzslq .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#vngjguzslq .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#vngjguzslq .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#vngjguzslq .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#vngjguzslq .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#vngjguzslq .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vngjguzslq .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#vngjguzslq .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#vngjguzslq .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#vngjguzslq .gt_left {
  text-align: left;
}

#vngjguzslq .gt_center {
  text-align: center;
}

#vngjguzslq .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#vngjguzslq .gt_font_normal {
  font-weight: normal;
}

#vngjguzslq .gt_font_bold {
  font-weight: bold;
}

#vngjguzslq .gt_font_italic {
  font-style: italic;
}

#vngjguzslq .gt_super {
  font-size: 65%;
}

#vngjguzslq .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
</style>
<div id="vngjguzslq" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;"><table class="gt_table">
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"><strong>Penny ID</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">Year</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">1</td>
      <td class="gt_row gt_center">2002</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">2</td>
      <td class="gt_row gt_center">1986</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">3</td>
      <td class="gt_row gt_center">2017</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">4</td>
      <td class="gt_row gt_center">1988</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">5</td>
      <td class="gt_row gt_center">2008</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">6</td>
      <td class="gt_row gt_center">1983</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">7</td>
      <td class="gt_row gt_center">2008</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">...</td>
      <td class="gt_row gt_center">...</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">50</td>
      <td class="gt_row gt_center">2017</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">X</td>
      <td class="gt_row gt_center">?</td>
    </tr>
</tbody>
</table></div>
<p>Based on these 50 sampled pennies, what can we say about <em>all</em> US pennies in 2019? Let’s study some properties of our sample by performing an exploratory data analysis. Let’s first visualize the distribution of the year of these 50 pennies using our data visualization tools from before. Since <code>year</code> is a numerical variable, we use a histogram to visualize its distribution.</p>
<div class="sourceCode" id="cb846"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb846-1"><a href="two-parameters.html#cb846-1"></a>pennies_sample <span class="op">%&gt;%</span></span>
<span id="cb846-2"><a href="two-parameters.html#cb846-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year)) <span class="op">+</span></span>
<span id="cb846-3"><a href="two-parameters.html#cb846-3"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="dv">10</span>, <span class="dt">color =</span> <span class="st">"white"</span>)</span></code></pre></div>
<div class="figure">
<span id="fig:unnamed-chunk-656"></span>
<p class="caption marginnote shownote">
FIGURE 7.4: Distribution of year on 50 US pennies.
</p>
<img src="book_temp_files/figure-html/unnamed-chunk-656-1.png" alt="Distribution of year on 50 US pennies." width="672">
</div>
<p>Observe a slightly left-skewed distribution, since most pennies fall between 1980 and 2010 with only a few pennies older than 1970. What is the average year for the 50 sampled pennies? Eyeballing the histogram it appears to be around 1990. Let’s now compute this value exactly using our data wrangling tools from Chapter <a href="wrangling.html#wrangling">2</a>.</p>
<div class="sourceCode" id="cb847"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb847-1"><a href="two-parameters.html#cb847-1"></a>pennies_sample <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb847-2"><a href="two-parameters.html#cb847-2"></a><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">mean_year =</span> <span class="kw">mean</span>(year))</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   mean_year
##       &lt;dbl&gt;
## 1     1995.</code></pre>
<p>Thus, if we’re willing to assume that <code>pennies_sample</code> is a representative sample from <em>all</em> US pennies, a “good guess” of the average year of minting of all US pennies would be 1995.44. In other words, around 1995. This should all start sounding similar to what we did previously in Chapter <a href="one-parameter.html#one-parameter">6</a>!</p>
<p>After calculating our “good guess”, we can fill in the question mark for our original Preceptor Table. Essentially, any random penny in 2019, the best guess would be 1995.44.</p>
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#nuwhogovgo .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#nuwhogovgo .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#nuwhogovgo .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#nuwhogovgo .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#nuwhogovgo .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#nuwhogovgo .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#nuwhogovgo .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#nuwhogovgo .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#nuwhogovgo .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#nuwhogovgo .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#nuwhogovgo .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#nuwhogovgo .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#nuwhogovgo .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#nuwhogovgo .gt_from_md > :first-child {
  margin-top: 0;
}

#nuwhogovgo .gt_from_md > :last-child {
  margin-bottom: 0;
}

#nuwhogovgo .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#nuwhogovgo .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#nuwhogovgo .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#nuwhogovgo .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#nuwhogovgo .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#nuwhogovgo .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#nuwhogovgo .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#nuwhogovgo .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#nuwhogovgo .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#nuwhogovgo .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#nuwhogovgo .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#nuwhogovgo .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#nuwhogovgo .gt_left {
  text-align: left;
}

#nuwhogovgo .gt_center {
  text-align: center;
}

#nuwhogovgo .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#nuwhogovgo .gt_font_normal {
  font-weight: normal;
}

#nuwhogovgo .gt_font_bold {
  font-weight: bold;
}

#nuwhogovgo .gt_font_italic {
  font-style: italic;
}

#nuwhogovgo .gt_super {
  font-size: 65%;
}

#nuwhogovgo .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
</style>
<div id="nuwhogovgo" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;"><table class="gt_table">
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"><strong>Penny ID</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">Year</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">1</td>
      <td class="gt_row gt_center">2002</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">2</td>
      <td class="gt_row gt_center">1986</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">3</td>
      <td class="gt_row gt_center">2017</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">4</td>
      <td class="gt_row gt_center">1988</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">5</td>
      <td class="gt_row gt_center">2008</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">6</td>
      <td class="gt_row gt_center">1983</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">7</td>
      <td class="gt_row gt_center">2008</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">...</td>
      <td class="gt_row gt_center">...</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">50</td>
      <td class="gt_row gt_center">2017</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">X</td>
      <td class="gt_row gt_center">1995</td>
    </tr>
</tbody>
</table></div>
<p>In Chapter <a href="one-parameter.html#one-parameter">6</a>, our <em>study population</em> was the urn of <span class="math inline">\(N\)</span> = 2400 balls. Our <em>population parameter</em> was the <em>population proportion</em> of these balls that were red, denoted by <span class="math inline">\(p\)</span>. In order to estimate <span class="math inline">\(p\)</span>, we extracted a sample of 50 balls using the shovel. We then computed the relevant <em>point estimate</em>: the <em>sample proportion</em> of these 50 balls that were red, denoted mathematically by <span class="math inline">\(\hat{p}\)</span>.</p>
<p>Here our population is <span class="math inline">\(N\)</span> = whatever the number of pennies are being used in the US, a value which we don’t know and probably never will. The population parameter of interest is now the <em>population mean</em> year of all these pennies, a value denoted mathematically by the Greek letter <span class="math inline">\(\mu\)</span> (pronounced “mu”). In order to estimate <span class="math inline">\(\mu\)</span>, we went to the bank and obtained a sample of 50 pennies and computed the relevant point estimate: the <em>sample mean</em> year of these 50 pennies, denoted mathematically by <span class="math inline">\(\overline{x}\)</span> (pronounced “x-bar”). An alternative and more intuitive notation for the sample mean is <span class="math inline">\(\hat{\mu}\)</span>. However, this is unfortunately not as commonly used, so in this book we’ll stick with convention and always denote the sample mean as <span class="math inline">\(\overline{x}\)</span>.</p>
<p>We summarize the correspondence between the sampling urn exercise in Chapter <a href="one-parameter.html#one-parameter">6</a> and our pennies exercise in Table below.</p>
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#qudpfvlpeq .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#qudpfvlpeq .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qudpfvlpeq .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#qudpfvlpeq .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#qudpfvlpeq .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qudpfvlpeq .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qudpfvlpeq .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#qudpfvlpeq .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#qudpfvlpeq .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#qudpfvlpeq .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#qudpfvlpeq .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#qudpfvlpeq .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#qudpfvlpeq .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#qudpfvlpeq .gt_from_md > :first-child {
  margin-top: 0;
}

#qudpfvlpeq .gt_from_md > :last-child {
  margin-bottom: 0;
}

#qudpfvlpeq .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#qudpfvlpeq .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#qudpfvlpeq .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qudpfvlpeq .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#qudpfvlpeq .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qudpfvlpeq .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#qudpfvlpeq .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#qudpfvlpeq .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qudpfvlpeq .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qudpfvlpeq .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#qudpfvlpeq .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qudpfvlpeq .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#qudpfvlpeq .gt_left {
  text-align: left;
}

#qudpfvlpeq .gt_center {
  text-align: center;
}

#qudpfvlpeq .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#qudpfvlpeq .gt_font_normal {
  font-weight: normal;
}

#qudpfvlpeq .gt_font_bold {
  font-weight: bold;
}

#qudpfvlpeq .gt_font_italic {
  font-style: italic;
}

#qudpfvlpeq .gt_super {
  font-size: 65%;
}

#qudpfvlpeq .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
</style>
<div id="qudpfvlpeq" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;"><table class="gt_table">
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Scenario</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Population_parameter</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Notation</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Point_Estimate</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Symbol</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_left"><div class="gt_from_md">
<p>1</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Population Proportion</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$p$$</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Sample Proportion</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\hat{p}$$</p>
</div></td>
    </tr>
<tr>
<td class="gt_row gt_left"><div class="gt_from_md">
<p>2</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Population mean</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\mu $$</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Sample mean</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\overline{x}$$ or $$\hat{\mu}$$</p>
</div></td>
    </tr>
<tr>
<td class="gt_row gt_left"><div class="gt_from_md">
<p>3</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Difference in population proportions</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$p_1 - p_2$$</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Difference in sample proportions</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\hat{p}_1 - \hat{p}_2$$</p>
</div></td>
    </tr>
<tr>
<td class="gt_row gt_left"><div class="gt_from_md">
<p>4</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Difference in population means</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\mu_1 - \mu_2$$</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>Difference in sample means</p>
</div></td>
      <td class="gt_row gt_left"><div class="gt_from_md">
<p>$$\overline{x}_1 - \overline{x}_2$$</p>
</div></td>
    </tr>
</tbody>
</table></div>
<p>Going back to our 50 sampled pennies, the point estimate of interest is the sample mean <span class="math inline">\(\overline{x}\)</span> of 1995.44. This quantity is an <em>estimate</em> of the population mean year of <em>all</em> US pennies <span class="math inline">\(\mu\)</span>.</p>
<p>Recall that we also saw in Chapter <a href="one-parameter.html#one-parameter">6</a> that such estimates are prone to <em>sampling variation</em>. For example, in this particular sample, we observed three pennies with the year 1999. If we sampled another 50 pennies, would we observe exactly three pennies with the year 1999 again? More than likely not. We might observe none, one, two, or maybe even all 50! The same can be said for the other 26 unique years that are represented in our sample of 50 pennies.</p>
<p>So what do we do about this sampling variation? One solution is that we create bootstrap samples! As you already know that resampling is a significant tool in data science, bootstrapping is one such resampling method that many data scientists use today. Bootstrapping essentially repeatedly draws independent samples from our data set with replacement. By sampling with replacement, the same observation can be sampled multiple times and each bootstrap sample will have the same number of observations as the original data set.</p>
<p><label for="tufte-mn-79" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-79" class="margin-toggle"><span class="marginnote">To conduct bootstraps, make sure your dowload both rsample and tidyverse libraries</span></p>
<p>Before the computer age, scientists would use direct standard error formulas and complex Taylor Series to compute confidence intervals for an estimate. However, the bootstrap was developed as an alternative to compute standard errors and confidence intervals for any statistic in a much faster and easier way.</p>
<p>The intuition with bootstrapping is that we can model an inference about the population from resampling our sample data and then performing an inference about a sample from each resample. It will look something like this: resampled → sample → population.</p>
<p>The first thing we want to do when bootstrapping is creating our bootstrap samples.Since we are concerned with the <code>year</code> of pennies in 2019, let’s select <code>year</code> in our data set before we create our bootstraps. Let’s now perform the virtual analog for 1000 resamples. Using these results, we’ll be able to study the variability in the sample means from 1000 resamples of size 50. Let’s first add a <code>times = 1000</code> argument to <code>bootstraps()</code>  to indicate we would like 1000 replicates. Remember that we must use the <code>rsample</code> library to use bootstraps.</p>
<div class="sourceCode" id="cb849"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb849-1"><a href="two-parameters.html#cb849-1"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb849-2"><a href="two-parameters.html#cb849-2"></a>virtual_resamples &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span></span>
<span id="cb849-3"><a href="two-parameters.html#cb849-3"></a><span class="st">  </span><span class="kw">select</span>(year) <span class="op">%&gt;%</span></span>
<span id="cb849-4"><a href="two-parameters.html#cb849-4"></a><span class="st">  </span><span class="kw">bootstraps</span>(<span class="dt">times =</span> <span class="dv">1000</span>)</span>
<span id="cb849-5"><a href="two-parameters.html#cb849-5"></a>virtual_resamples</span></code></pre></div>
<pre><code>## # Bootstrap sampling 
## # A tibble: 1,000 x 2
##    splits          id           
##    &lt;list&gt;          &lt;chr&gt;        
##  1 &lt;split [50/19]&gt; Bootstrap0001
##  2 &lt;split [50/20]&gt; Bootstrap0002
##  3 &lt;split [50/16]&gt; Bootstrap0003
##  4 &lt;split [50/18]&gt; Bootstrap0004
##  5 &lt;split [50/18]&gt; Bootstrap0005
##  6 &lt;split [50/18]&gt; Bootstrap0006
##  7 &lt;split [50/17]&gt; Bootstrap0007
##  8 &lt;split [50/14]&gt; Bootstrap0008
##  9 &lt;split [50/19]&gt; Bootstrap0009
## 10 &lt;split [50/20]&gt; Bootstrap0010
## # … with 990 more rows</code></pre>
<p>So we have now created our bootstrap samples, which are stored in a tibble-like object, and each bootstrap sample is nested in the splits column. This means that each <code>rsplit</code> row is a different bootstrap sample and the <code>id</code> column is used to identify each bootstrap sample.</p>
<p><label for="tufte-mn-80" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-80" class="margin-toggle"><span class="marginnote">Check out ?analysis in console to get an even more comprehensive review of what analysis() does</span>
Now if you are interested to view a specific bootstrap sample, you can use the <code>analysis()</code> function from the <code>rsample</code> package, which basically allows you to view a specific bootstrap sample as a data frame. To do so, type <code>analysis(virtual_resamples$splits[[n]]) %&gt;% as_tibble()</code> where n represents the nth row bootstrap sample. We will be looking at the first bootstrap sample in this case.</p>
<div class="sourceCode" id="cb851"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb851-1"><a href="two-parameters.html#cb851-1"></a><span class="kw">analysis</span>(virtual_resamples<span class="op">$</span>splits[[<span class="dv">1</span>]]) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as_tibble</span>()</span></code></pre></div>
<pre><code>## # A tibble: 50 x 1
##     year
##    &lt;dbl&gt;
##  1  1983
##  2  2017
##  3  1983
##  4  2017
##  5  1995
##  6  1988
##  7  1978
##  8  2015
##  9  1962
## 10  1996
## # … with 40 more rows</code></pre>
<p>As you can see, we were able to view the data in first bootstrap sample. Noticed how it has 50 rows, which is the same as our <code>pennies_sample</code>. Now that we know how to create bootstrap samples and view them, we can apply more code to our bootstraps to find our desired statistic, which is the average year of pennies in 2019.</p>
<p><label for="tufte-mn-81" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-81" class="margin-toggle"><span class="marginnote">In this chapter, bootstrap samples and resamples mean the same thing</span>
To compute our desired statistics, we now create the column <code>boot</code> by <code>mutate(boot = map(splits, ~ analysis(.)))</code>. What we are doing here is that we are iterating an analysis over each bootstrap sample in a new sample. We want to iterate an analysis over each bootstrap sample, because analysis allows us to extract the mean year for each resample.</p>
<div class="sourceCode" id="cb853"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb853-1"><a href="two-parameters.html#cb853-1"></a>virtual_resamples &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span></span>
<span id="cb853-2"><a href="two-parameters.html#cb853-2"></a><span class="st">  </span><span class="kw">select</span>(year) <span class="op">%&gt;%</span></span>
<span id="cb853-3"><a href="two-parameters.html#cb853-3"></a><span class="st">  </span><span class="kw">bootstraps</span>(<span class="dt">times =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span></span>
<span id="cb853-4"><a href="two-parameters.html#cb853-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">boot =</span> <span class="kw">map</span>(splits, <span class="op">~</span><span class="st"> </span><span class="kw">analysis</span>(.)))</span>
<span id="cb853-5"><a href="two-parameters.html#cb853-5"></a>virtual_resamples</span></code></pre></div>
<pre><code>## # Bootstrap sampling 
## # A tibble: 1,000 x 3
##    splits          id            boot             
##    &lt;list&gt;          &lt;chr&gt;         &lt;list&gt;           
##  1 &lt;split [50/19]&gt; Bootstrap0001 &lt;tibble [50 × 1]&gt;
##  2 &lt;split [50/18]&gt; Bootstrap0002 &lt;tibble [50 × 1]&gt;
##  3 &lt;split [50/20]&gt; Bootstrap0003 &lt;tibble [50 × 1]&gt;
##  4 &lt;split [50/18]&gt; Bootstrap0004 &lt;tibble [50 × 1]&gt;
##  5 &lt;split [50/19]&gt; Bootstrap0005 &lt;tibble [50 × 1]&gt;
##  6 &lt;split [50/15]&gt; Bootstrap0006 &lt;tibble [50 × 1]&gt;
##  7 &lt;split [50/13]&gt; Bootstrap0007 &lt;tibble [50 × 1]&gt;
##  8 &lt;split [50/19]&gt; Bootstrap0008 &lt;tibble [50 × 1]&gt;
##  9 &lt;split [50/20]&gt; Bootstrap0009 &lt;tibble [50 × 1]&gt;
## 10 &lt;split [50/19]&gt; Bootstrap0010 &lt;tibble [50 × 1]&gt;
## # … with 990 more rows</code></pre>
<p><code>boot</code> is now a list-column in the tibble, which we can use if we want to find a specific characteristic of each sample like the average year. Given that <code>boot</code> is a list column and we want to pull out the mean year as we are interested in this, we can create two more columns: <code>years</code> and year_mean<code>, respectively.  To create our</code>years<code>column, we run</code>mutate(years = map(boot, ~ pull(., year)))<code>after creating our</code>boot<code>column. What this does is that we are now pulling the year column of each bootstrap sample, which will evidently be nested in a list. Finally, we can create the column</code>year_mean<code>to extract the mean of each bootstrap sample by now running</code>mutate(year_mean = map_dbl(years, ~ mean(.)))<code>. This command line essentially calculates the mean year from the</code>years` list nested column.</p>
<div class="sourceCode" id="cb855"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb855-1"><a href="two-parameters.html#cb855-1"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb855-2"><a href="two-parameters.html#cb855-2"></a>virtual_resamples &lt;-<span class="st"> </span>pennies_sample <span class="op">%&gt;%</span></span>
<span id="cb855-3"><a href="two-parameters.html#cb855-3"></a><span class="st">  </span><span class="kw">select</span>(year) <span class="op">%&gt;%</span></span>
<span id="cb855-4"><a href="two-parameters.html#cb855-4"></a><span class="st">  </span><span class="kw">bootstraps</span>(<span class="dt">times =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span></span>
<span id="cb855-5"><a href="two-parameters.html#cb855-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">boot =</span> <span class="kw">map</span>(splits, <span class="op">~</span><span class="st"> </span><span class="kw">analysis</span>(.))) <span class="op">%&gt;%</span></span>
<span id="cb855-6"><a href="two-parameters.html#cb855-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">years =</span> <span class="kw">map</span>(boot, <span class="op">~</span><span class="st"> </span><span class="kw">pull</span>(., year))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb855-7"><a href="two-parameters.html#cb855-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">year_mean =</span> <span class="kw">map_dbl</span>(years, <span class="op">~</span><span class="st"> </span><span class="kw">mean</span>(.)))</span>
<span id="cb855-8"><a href="two-parameters.html#cb855-8"></a>virtual_resamples</span></code></pre></div>
<pre><code>## # Bootstrap sampling 
## # A tibble: 1,000 x 5
##    splits          id            boot              years      year_mean
##    &lt;list&gt;          &lt;chr&gt;         &lt;list&gt;            &lt;list&gt;         &lt;dbl&gt;
##  1 &lt;split [50/19]&gt; Bootstrap0001 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1992.
##  2 &lt;split [50/20]&gt; Bootstrap0002 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1999.
##  3 &lt;split [50/16]&gt; Bootstrap0003 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1992.
##  4 &lt;split [50/18]&gt; Bootstrap0004 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1993.
##  5 &lt;split [50/18]&gt; Bootstrap0005 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1995.
##  6 &lt;split [50/18]&gt; Bootstrap0006 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1998.
##  7 &lt;split [50/17]&gt; Bootstrap0007 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1993.
##  8 &lt;split [50/14]&gt; Bootstrap0008 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1995.
##  9 &lt;split [50/19]&gt; Bootstrap0009 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     1993.
## 10 &lt;split [50/20]&gt; Bootstrap0010 &lt;tibble [50 × 1]&gt; &lt;dbl [50]&gt;     2000.
## # … with 990 more rows</code></pre>
<p>Voila! We were able to create a thousand bootstrap samples and calculate the mean year for each resample. Let’s now create a plot to visualizes the posterior distribution for the mean year of American pennies in 2019.</p>
<div class="sourceCode" id="cb857"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb857-1"><a href="two-parameters.html#cb857-1"></a>virtual_resamples <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb857-2"><a href="two-parameters.html#cb857-2"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb857-3"><a href="two-parameters.html#cb857-3"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> year_mean, <span class="dt">y=</span>..count..<span class="op">/</span><span class="kw">sum</span>(..count..)), <span class="dt">binwidth =</span> <span class="fl">.5</span>, <span class="dt">fill =</span> <span class="st">"red"</span>) <span class="op">+</span></span>
<span id="cb857-4"><a href="two-parameters.html#cb857-4"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Estimate in Year"</span>, <span class="dt">y =</span> <span class="st">"Probability"</span>,</span>
<span id="cb857-5"><a href="two-parameters.html#cb857-5"></a>         <span class="dt">title =</span> <span class="st">"Posterior Distribution for the Mean Year of American Pennies in 2019"</span>) </span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-665-1.png" width="672">
Recall from chapter 5 that posterior distribution is based on beliefs and expectations. In the case of the bootstrap samples we made, the posterior distribution represents our knowledge about the mean year of American Pennies in 2019 after taking into account the the data we gathered from our bootstrap sample means. As demonstrated in the plot above, we can see that the mean year of pennies in 2019 is most likely between 1995 and 1998 from our posterior distribution.</p>
<p>Recall that in the “resampling with replacement” scenario we are illustrating here, this histogram has a special name: the <em>bootstrap distribution of the sample mean</em>. Furthermore, recall it is an approximation to the <em>sampling distribution</em> of the sample mean, a concept you saw before. This distribution allows us to study the effect of sampling variation on our estimates of the true population mean, in this case the true mean year for <em>all</em> US pennies. However, unlike in Chapter <a href="one-parameter.html#one-parameter">6</a> where we took multiple samples (something one would never do in practice), bootstrap distributions are constructed by taking multiple resamples from a <em>single</em> sample: in this case, the 50 original pennies from the bank.</p>
<p>Congratulations! You’ve just constructed your first bootstrap distribution! In the next section, you’ll see how to use this bootstrap distribution to construct <em>confidence intervals</em>.</p>
</div>
<div id="ci-build-up" class="section level3">
<h3>
<span class="header-section-number">7.1.3</span> Measuring uncertainty with confidence intervals</h3>
<p>Let’s start this section with an analogy involving fishing. Say you are trying to catch a fish. On the one hand, you could use a spear, while on the other you could use a net. Using the net will probably allow you to catch more fish!</p>
<p>Now think back to our pennies exercise where you are trying to estimate the true population mean year <span class="math inline">\(\mu\)</span> of <em>all</em> US pennies. Think of the value of <span class="math inline">\(\mu\)</span> as a fish.</p>
<p>On the one hand, we could use the appropriate <em>point estimate/sample statistic</em> to estimate <span class="math inline">\(\mu\)</span>, which we saw in the table in the previous section, is the sample mean <span class="math inline">\(\overline{x}\)</span>. Based on our sample of 50 pennies from the bank, the sample mean was 1995.44. Think of using this value as “fishing with a spear.”</p>
<p>What would “fishing with a net” correspond to? Look at the bootstrap distribution we created once more. Between which two years would you say that “most” sample means lie? While this question is somewhat subjective, saying that most sample means lie between 1992 and 2000 would not be unreasonable. Think of this interval as the “net.”</p>
<p>What we’ve just illustrated is the concept of a <em>confidence interval</em>, which we’ll abbreviate with “CI” throughout this book. As opposed to a point estimate/sample statistic that estimates the value of an unknown population parameter with a single value, a <em>confidence interval</em>  gives what can be interpreted as a range of plausible values. Going back to our analogy, point estimates/sample statistics can be thought of as spears, whereas confidence intervals can be thought of as nets.</p>
<div class="figure" style="text-align: center">
<span id="fig:unnamed-chunk-666"></span>
<p class="caption marginnote shownote">
FIGURE 7.5: Analogy of difference between point estimates and confidence intervals.
</p>
<img src="07-two-parameters/images/point_estimate_vs_conf_int.png" alt="Analogy of difference between point estimates and confidence intervals." width="756">
</div>
<p>Our proposed interval of 1992 to 2000 was constructed by eye and was thus somewhat subjective. We now introduce two methods for constructing such intervals in a more exact fashion: the <em>lm method</em> and the <em>quantile method</em>.</p>
<p>Second, they both require you to specify the <em>confidence level</em>. Commonly used confidence levels include 90%, 95%, and 99%. All other things being equal, higher confidence levels correspond to wider confidence intervals, and lower confidence levels correspond to narrower confidence intervals. In this book, we’ll be mostly using 95% and hence constructing “95% confidence intervals for <span class="math inline">\(\mu\)</span>” for our pennies activity.</p>
<p>Using confidence intervals, we can again look back at our Preceptor Tables. We are not entirely sure that 1995.44 is the perfect guess. However, if we use confidence intervals we can be 95% sure that whatever year we get for a penny in 2019 is the truth. Thus, we will see a confidence interval yet to be created for the “Year” of our random penny from 2019.</p>
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#mzknqfrteu .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#mzknqfrteu .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#mzknqfrteu .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#mzknqfrteu .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 4px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#mzknqfrteu .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#mzknqfrteu .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#mzknqfrteu .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#mzknqfrteu .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#mzknqfrteu .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#mzknqfrteu .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#mzknqfrteu .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#mzknqfrteu .gt_group_heading {
  padding: 8px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#mzknqfrteu .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#mzknqfrteu .gt_from_md > :first-child {
  margin-top: 0;
}

#mzknqfrteu .gt_from_md > :last-child {
  margin-bottom: 0;
}

#mzknqfrteu .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#mzknqfrteu .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 12px;
}

#mzknqfrteu .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#mzknqfrteu .gt_first_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
}

#mzknqfrteu .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#mzknqfrteu .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#mzknqfrteu .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#mzknqfrteu .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#mzknqfrteu .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#mzknqfrteu .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding: 4px;
}

#mzknqfrteu .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#mzknqfrteu .gt_sourcenote {
  font-size: 90%;
  padding: 4px;
}

#mzknqfrteu .gt_left {
  text-align: left;
}

#mzknqfrteu .gt_center {
  text-align: center;
}

#mzknqfrteu .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#mzknqfrteu .gt_font_normal {
  font-weight: normal;
}

#mzknqfrteu .gt_font_bold {
  font-weight: bold;
}

#mzknqfrteu .gt_font_italic {
  font-style: italic;
}

#mzknqfrteu .gt_super {
  font-size: 65%;
}

#mzknqfrteu .gt_footnote_marks {
  font-style: italic;
  font-size: 65%;
}
</style>
<div id="mzknqfrteu" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;"><table class="gt_table">
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1"><strong>Penny ID</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">Year</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">1</td>
      <td class="gt_row gt_center">2002</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">2</td>
      <td class="gt_row gt_center">1986</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">3</td>
      <td class="gt_row gt_center">2017</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">4</td>
      <td class="gt_row gt_center">1988</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">5</td>
      <td class="gt_row gt_center">2008</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">6</td>
      <td class="gt_row gt_center">1983</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">7</td>
      <td class="gt_row gt_center">2008</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">...</td>
      <td class="gt_row gt_center">...</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">50</td>
      <td class="gt_row gt_center">2017</td>
    </tr>
<tr>
<td class="gt_row gt_center" style="border-right-width: 1px; border-right-style: solid; border-right-color: #000000; font-weight: bold;">X</td>
      <td class="gt_row gt_center">(?,?)</td>
    </tr>
</tbody>
</table></div>
</div>
<div id="confidence-intervals-using-lm-and-quantile" class="section level3">
<h3>
<span class="header-section-number">7.1.4</span> Confidence Intervals using lm and quantile</h3>
<p>First, let’s type <code>lm(year ~ 1, data = pennies_sample)</code> in our code chunk. This alone will get the mean of our dataset for pennies_sample</p>
<div class="sourceCode" id="cb858"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb858-1"><a href="two-parameters.html#cb858-1"></a>  <span class="kw">lm</span>(year <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> pennies_sample)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = year ~ 1, data = pennies_sample)
## 
## Coefficients:
## (Intercept)  
##        1995</code></pre>
<p>So we see that the mean of pennies_sample is 1995. Now let’s add the line <code>tidy(conf,int = TRUE)</code> to our code. <code>tidy</code> is from the <code>rsample</code> package and this particular function can get the 95% confidence interval for our mean if we set the argument, <code>conf.int = TRUE</code>, in our <code>tidy</code> function.</p>
<div class="sourceCode" id="cb860"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb860-1"><a href="two-parameters.html#cb860-1"></a>  <span class="kw">lm</span>(year <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> pennies_sample) <span class="op">%&gt;%</span></span>
<span id="cb860-2"><a href="two-parameters.html#cb860-2"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 7
##   term        estimate std.error statistic   p.value conf.low conf.high
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)    1995.      2.15      930. 1.03e-105    1991.     2000.</code></pre>
<p>Great! After running the code, we can clearly see the mean of the of <code>pennies_sample</code> as well as other characteristics like the upper and lower levels of our confidence interval. Since we are focused on the confidence interval only, let’s just <code>select(conf.low, estimate, conf.high)</code>.</p>
<div class="sourceCode" id="cb862"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb862-1"><a href="two-parameters.html#cb862-1"></a>  <span class="kw">lm</span>(year <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> pennies_sample) <span class="op">%&gt;%</span></span>
<span id="cb862-2"><a href="two-parameters.html#cb862-2"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb862-3"><a href="two-parameters.html#cb862-3"></a><span class="st">  </span><span class="kw">select</span>(conf.low, estimate, conf.high)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   conf.low estimate conf.high
##      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
## 1    1991.    1995.     2000.</code></pre>
<p>Now we have our confidence interval for the mean year of pennies from 2019, which is (1991.127, 1999.753). But noticed that we used <code>pennies_sample</code> and not <code>virtual_resamples</code> for the <code>lm</code> method to calculate the confidence interval.</p>
<p>Let’s now calculate the confidence interval by hand using our bootstrap samples, <code>virtual_resamples</code>. To do, type the following code below:</p>
<div class="sourceCode" id="cb864"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb864-1"><a href="two-parameters.html#cb864-1"></a><span class="kw">quantile</span>(virtual_resamples<span class="op">$</span>year_mean, <span class="dt">probs =</span> <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>## 2.5%  98% 
## 1991 2000</code></pre>
<p>Whoa! Noticed how we got 1991.28, 1999.92 as our confidence interval, which is the same as the <code>lm</code> method using pennies_sample. What this shows is that we can essentially use two methods to calculate the confidence interval for the mean: the <code>lm</code> method using the original data set and the quantile method using our bootstrap samples! However, if we want to find the confidence interval for any statistic, not including the mean, we have to use the quantile method using our bootstrap samples!</p>
</div>
</div>
<div id="eda-for-nhanes" class="section level2">
<h2>
<span class="header-section-number">7.2</span> EDA for <code>nhanes</code>
</h2>
<p><label for="tufte-mn-82" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-82" class="margin-toggle"><span class="marginnote">Run ?nhanes to get more information about the data from nhanes</span>
Shifting away from dealing with pennies, let’s look at bootstrap modeling witht the nhanes dataset. Let’s perform an exploratory data analysis (EDA) of the nhanes data set from the <strong>PPBDS.data</strong> package. The nhanes data is the data from National Health and Nutrition Examination Survey conduced by the Centers for Disease Control and Prevention and is about children and adults in America.</p>
<p>Load the libraries we will need in this chapter and analyze the nhanes data.</p>
<div class="sourceCode" id="cb866"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb866-1"><a href="two-parameters.html#cb866-1"></a><span class="kw">library</span>(PPBDS.data)</span>
<span id="cb866-2"><a href="two-parameters.html#cb866-2"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb866-3"><a href="two-parameters.html#cb866-3"></a><span class="kw">library</span>(broom)</span>
<span id="cb866-4"><a href="two-parameters.html#cb866-4"></a><span class="kw">library</span>(rsample)</span>
<span id="cb866-5"><a href="two-parameters.html#cb866-5"></a><span class="kw">library</span>(skimr)</span>
<span id="cb866-6"><a href="two-parameters.html#cb866-6"></a><span class="kw">library</span>(tidyverse)</span></code></pre></div>
<div class="sourceCode" id="cb867"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb867-1"><a href="two-parameters.html#cb867-1"></a><span class="kw">glimpse</span>(nhanes)</span></code></pre></div>
<pre><code>## Rows: 10,000
## Columns: 15
## $ survey         &lt;int&gt; 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, …
## $ gender         &lt;chr&gt; "Male", "Male", "Male", "Male", "Female", "Male", "Mal…
## $ age            &lt;int&gt; 34, 34, 34, 4, 49, 9, 8, 45, 45, 45, 66, 58, 54, 10, 5…
## $ race           &lt;chr&gt; "White", "White", "White", "Other", "White", "White", …
## $ education      &lt;ord&gt; High School, High School, High School, NA, Some Colleg…
## $ hh_income      &lt;ord&gt; 25000-34999, 25000-34999, 25000-34999, 20000-24999, 35…
## $ weight         &lt;dbl&gt; 87, 87, 87, 17, 87, 30, 35, 76, 76, 76, 68, 78, 75, 39…
## $ height         &lt;dbl&gt; 165, 165, 165, 105, 168, 133, 131, 167, 167, 167, 170,…
## $ bmi            &lt;dbl&gt; 32, 32, 32, 15, 31, 17, 21, 27, 27, 27, 24, 24, 26, 19…
## $ pulse          &lt;int&gt; 70, 70, 70, NA, 86, 82, 72, 62, 62, 62, 60, 62, 76, 80…
## $ diabetes       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
## $ general_health &lt;int&gt; 3, 3, 3, NA, 3, NA, NA, 4, 4, 4, 4, 4, 2, NA, NA, 3, N…
## $ depressed      &lt;ord&gt; Several, Several, Several, NA, Several, NA, NA, None, …
## $ pregnancies    &lt;int&gt; NA, NA, NA, NA, 2, NA, NA, 1, 1, 1, NA, NA, NA, NA, NA…
## $ sleep          &lt;int&gt; 4, 4, 4, NA, 8, NA, NA, 8, 8, 8, 7, 5, 4, NA, 5, 7, NA…</code></pre>
<p><code>glimpse()</code> is a really cool function to use to get a quick peek at your data. It basically allows your data to be viewed running across rows. <code>glimpse</code> gives you a sense of what your data is supposed to look like. Based on the glimpse of nhanes, we see that nhanes has data on a diverse array of things like physical attributes, education, and sleep.</p>
<p>In our examination of nhanes, however, let’s restrict the nhanes data to a subset, focusing on year, gender, and height.</p>
<div class="sourceCode" id="cb869"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb869-1"><a href="two-parameters.html#cb869-1"></a>ch7 &lt;-<span class="st"> </span>nhanes <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb869-2"><a href="two-parameters.html#cb869-2"></a><span class="st">  </span><span class="kw">select</span>(gender, height, survey)</span></code></pre></div>
<p>Furthermore, it is always smart to look at random samples of our data set.</p>
<div class="sourceCode" id="cb870"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb870-1"><a href="two-parameters.html#cb870-1"></a>ch7 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb870-2"><a href="two-parameters.html#cb870-2"></a><span class="st">  </span><span class="kw">sample_n</span>(<span class="dv">5</span>)</span></code></pre></div>
<pre><code>## # A tibble: 5 x 3
##   gender height survey
##   &lt;chr&gt;   &lt;dbl&gt;  &lt;int&gt;
## 1 Female   167.   2009
## 2 Female   142.   2011
## 3 Male     145    2009
## 4 Male     153.   2011
## 5 Male     171.   2011</code></pre>
<p>Notice how there is a decimal in the height column of ch7 data. This is because <code>height</code> is in <code>&lt;dbl&gt;</code> and not <code>&lt;int&gt;</code>, so <code>height</code> will not be rounded up to the nearest integer.</p>
<p>Let’s also run <code>glimpse</code> to analyze our new data.</p>
<div class="sourceCode" id="cb872"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb872-1"><a href="two-parameters.html#cb872-1"></a>ch7 <span class="op">%&gt;%</span></span>
<span id="cb872-2"><a href="two-parameters.html#cb872-2"></a><span class="st">  </span><span class="kw">glimpse</span>()</span></code></pre></div>
<pre><code>## Rows: 10,000
## Columns: 3
## $ gender &lt;chr&gt; "Male", "Male", "Male", "Male", "Female", "Male", "Male", "Fem…
## $ height &lt;dbl&gt; 165, 165, 165, 105, 168, 133, 131, 167, 167, 167, 170, 182, 16…
## $ survey &lt;int&gt; 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 2009, 20…</code></pre>
<p>Be on the lookout if anything looks suspicious to you. Are there any NA’s in your data set? What types of data are the columns, i.e. why is <code>survey</code> characterized as integer instead of double? Was most of the data collected in 2009? Are there more females than males? There will clearly be more questions to answer, but it is important that you ask these types of questions and notice anything suspicious. A good data scientist will always look thoroughly at the data.</p>
<p>In addition to <code>glimpse</code>, we can run<code>skim</code> on our data to get standard statistics like mean of our data.</p>
<div class="sourceCode" id="cb874"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb874-1"><a href="two-parameters.html#cb874-1"></a>ch7 <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb874-2"><a href="two-parameters.html#cb874-2"></a><span class="st">  </span><span class="kw">skim</span>()</span></code></pre></div>
<p><!--
<caption>--><span class="marginnote shownote"><span id="tab:unnamed-chunk-677">TABLE 7.1: </span>Data summary</span><!--</caption>--></p>
<table><tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">Piped data</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">10000</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">3</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">2</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody></table>
<p><strong>Variable type: character</strong></p>
<table>
<thead><tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr></thead>
<tbody><tr class="odd">
<td align="left">gender</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">6</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">0</td>
</tr></tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead><tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">height</td>
<td align="right">353</td>
<td align="right">0.96</td>
<td align="right">162</td>
<td align="right">20</td>
<td align="right">84</td>
<td align="right">157</td>
<td align="right">166</td>
<td align="right">174</td>
<td align="right">200</td>
<td align="left">▁▁▁▇▂</td>
</tr>
<tr class="even">
<td align="left">survey</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">2010</td>
<td align="right">1</td>
<td align="right">2009</td>
<td align="right">2009</td>
<td align="right">2010</td>
<td align="right">2011</td>
<td align="right">2011</td>
<td align="left">▇▁▁▁▇</td>
</tr>
</tbody>
</table>
<p>Interesting! Noticed how <code>skim</code> told us that are 353 missing values of height in our subset of data even though we could not find that out so easily using glimpse. Thus, it’s always good to use both <code>skim</code> and <code>glimpse</code> to get a gyst of what our data entails.</p>
<p>Since we are dealing with NA’s then, let’s filter out the NA’s using <code>drop_na</code>. This we will remove out the rows that have NA’s in them.</p>
<div class="sourceCode" id="cb875"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb875-1"><a href="two-parameters.html#cb875-1"></a>ch7 &lt;-<span class="st"> </span>nhanes <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb875-2"><a href="two-parameters.html#cb875-2"></a><span class="st">  </span><span class="kw">select</span>(gender, height, survey) <span class="op">%&gt;%</span></span>
<span id="cb875-3"><a href="two-parameters.html#cb875-3"></a><span class="st">  </span><span class="kw">drop_na</span>()</span></code></pre></div>
<p>Plot your data.</p>
<div class="sourceCode" id="cb876"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb876-1"><a href="two-parameters.html#cb876-1"></a>ch7 <span class="op">%&gt;%</span></span>
<span id="cb876-2"><a href="two-parameters.html#cb876-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> height, <span class="dt">color =</span> gender)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb876-3"><a href="two-parameters.html#cb876-3"></a><span class="st">  </span><span class="kw">geom_density</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb876-4"><a href="two-parameters.html#cb876-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Height"</span>,</span>
<span id="cb876-5"><a href="two-parameters.html#cb876-5"></a>       <span class="dt">title =</span> <span class="st">"Height by Gender in Nhanes Dataset"</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-679-1.png" width="672">
The plot shows some interesting stuff. Since the distributions of height for both genders are skewed left, we can infer that this data set included children and thus age played a role in our data. Additionally, we can see the the most probable heights for both genders and that men are generally taller than women.</p>
</div>
<div id="using-bootstraps-with-nhanes" class="section level2">
<h2>
<span class="header-section-number">7.3</span> Using Bootstraps with <code>nhanes</code>
</h2>
<!-- 4. Prove that the bootstrap works, that our 95% confidence intervals provide correct coverage. We make a game and I give you a sample of like 40. Here's the 40, and you give me a 95% CI using the bootstrap tools we learned. Then I give you another 40. And another. If we do this 1,00 times, and we use the same procedure for calculating a confidence interval each time, then 950 should include the truth. That's how we know bootstraps is correct and I could only demonstrate this to you if we know what the truth is.   -->
<!-- Plan: create function called create_ci(), which takes a tibble with a single variable called height and returns the 95% confidence interval --- i.e., a numeric vector of length 2 --- for the 75th percentile.  Note that you get to hard code everything. -->
<!-- Then, create a tibble, first column is ID. Second column is height_sample, which is created by running sample(ch7$height, size = 40, replace = FALSE). Third column is ci, which is result mutate(ci = map(height_sample, ~ create_ci(.)). Fourth column is within_ci, which is TRUE if ci includes the TRUE value and FALSE otherwise. (If you want to have two columns, one for each limit, that is fine.) -->
<p>We have shown you how to use bootstrap sampling to create confidence intervals for an unknown parameter for which you have created. In other words, we use bootstrap sampling to create our posterior distribution for the average year of pennies in the US during 2009. But we have not yet demonstrated that the bootstrap “works,” that our 95% confidence intervals provide correct coverage. The purpose of this section is to provide that demonstration.</p>
<p>In this demonstration, let’s play a game! Let’s first filter our data set to just males and the year 2009. We want to estimate the mean and 75th percentile of male height in the year 2009. Obviously, we already know what these statistics are since we can easily calculate them by hand. However, we want to show that the bootstrap works!</p>
<div class="sourceCode" id="cb877"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb877-1"><a href="two-parameters.html#cb877-1"></a>ch7_male &lt;-<span class="st"> </span>nhanes <span class="op">%&gt;%</span></span>
<span id="cb877-2"><a href="two-parameters.html#cb877-2"></a><span class="st">  </span><span class="kw">filter</span>(survey <span class="op">==</span><span class="st"> </span><span class="dv">2009</span>, gender <span class="op">==</span><span class="st"> "Male"</span>) <span class="op">%&gt;%</span></span>
<span id="cb877-3"><a href="two-parameters.html#cb877-3"></a><span class="st">  </span><span class="kw">select</span>(height) <span class="op">%&gt;%</span></span>
<span id="cb877-4"><a href="two-parameters.html#cb877-4"></a><span class="st">  </span><span class="kw">arrange</span>(height) <span class="op">%&gt;%</span></span>
<span id="cb877-5"><a href="two-parameters.html#cb877-5"></a><span class="st">  </span><span class="kw">na.omit</span>()</span></code></pre></div>
<p>Noticed how we did <code>arrange(height)</code>, because since we know the 90th percentile is the 2,133 tallest male in the data set, it would be good to look at our data in increasing order. Furthermore, remember how nhanes had lots of NA’s. It would be good to get rid of them here. The true mean in this case is ________ and the true 90th percentile is ________.</p>
<p>We are now going to estimate both the true mean and 90th percentile using our bootstrap. Remember how in the <code>pennies_sample</code> example, we first used a sample of 50 pennies to create our bootstrap samples. Let’s do something very similar. In this case, let’s take a sample without replacement of 40 of the 2,370 males in our data and look at their heights in 2009. To do so, we run the following command:</p>
<div class="sourceCode" id="cb878"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb878-1"><a href="two-parameters.html#cb878-1"></a>heights_sample &lt;-<span class="st"> </span><span class="kw">sample_n</span>(ch7_male, <span class="dv">40</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p>Great! So now we have our sample of 40 male heights in 2009. Now you might wonder how this section of this chapter is different from the section with <code>pennies_samples</code>. Well, there are two key differences. First, we know the truth in this case, so we can examine whether or not the bootstrap works. (That is, we pull a sample of 40 and see if the bootstrap confidence interval from that 40 includes the true 90th percentile of the 2,370) Second, note that only the bootstrap will allow us to estimate statistics other than the mean. We can’t use the lm() trick we learned about for pennies as we will find the confidence interval for the 90th percentile, which is a statistic that isn’t the mean.</p>
<div class="sourceCode" id="cb879"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb879-1"><a href="two-parameters.html#cb879-1"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb879-2"><a href="two-parameters.html#cb879-2"></a>virtual_heights &lt;-<span class="st"> </span>heights_sample <span class="op">%&gt;%</span></span>
<span id="cb879-3"><a href="two-parameters.html#cb879-3"></a><span class="st">  </span><span class="kw">select</span>(height) <span class="op">%&gt;%</span></span>
<span id="cb879-4"><a href="two-parameters.html#cb879-4"></a><span class="st">  </span><span class="kw">bootstraps</span>(<span class="dt">times =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span></span>
<span id="cb879-5"><a href="two-parameters.html#cb879-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">boot =</span> <span class="kw">map</span>(splits, <span class="op">~</span><span class="st"> </span><span class="kw">analysis</span>(.))) <span class="op">%&gt;%</span></span>
<span id="cb879-6"><a href="two-parameters.html#cb879-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">heights =</span> <span class="kw">map</span>(boot, <span class="op">~</span><span class="st"> </span><span class="kw">pull</span>(., height))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb879-7"><a href="two-parameters.html#cb879-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">height_90th =</span> <span class="kw">map_dbl</span>(heights, <span class="op">~</span><span class="st"> </span><span class="kw">quantile</span>(., <span class="dt">probs =</span> <span class="fl">.90</span>))) </span>
<span id="cb879-8"><a href="two-parameters.html#cb879-8"></a>virtual_heights</span></code></pre></div>
<pre><code>## # Bootstrap sampling 
## # A tibble: 1,000 x 5
##    splits          id            boot              heights    height_90th
##    &lt;list&gt;          &lt;chr&gt;         &lt;list&gt;            &lt;list&gt;           &lt;dbl&gt;
##  1 &lt;split [40/14]&gt; Bootstrap0001 &lt;tibble [40 × 1]&gt; &lt;dbl [40]&gt;        182.
##  2 &lt;split [40/16]&gt; Bootstrap0002 &lt;tibble [40 × 1]&gt; &lt;dbl [40]&gt;        182.
##  3 &lt;split [40/13]&gt; Bootstrap0003 &lt;tibble [40 × 1]&gt; &lt;dbl [40]&gt;        183.
##  4 &lt;split [40/14]&gt; Bootstrap0004 &lt;tibble [40 × 1]&gt; &lt;dbl [40]&gt;        182.
##  5 &lt;split [40/15]&gt; Bootstrap0005 &lt;tibble [40 × 1]&gt; &lt;dbl [40]&gt;        182.
##  6 &lt;split [40/16]&gt; Bootstrap0006 &lt;tibble [40 × 1]&gt; &lt;dbl [40]&gt;        182.
##  7 &lt;split [40/15]&gt; Bootstrap0007 &lt;tibble [40 × 1]&gt; &lt;dbl [40]&gt;        180.
##  8 &lt;split [40/12]&gt; Bootstrap0008 &lt;tibble [40 × 1]&gt; &lt;dbl [40]&gt;        183.
##  9 &lt;split [40/14]&gt; Bootstrap0009 &lt;tibble [40 × 1]&gt; &lt;dbl [40]&gt;        182.
## 10 &lt;split [40/16]&gt; Bootstrap0010 &lt;tibble [40 × 1]&gt; &lt;dbl [40]&gt;        182.
## # … with 990 more rows</code></pre>
<p>Let’s also see the posterior distribution for the 90th percentile of male heights in 2009 by creating a ggplot.</p>
<div class="sourceCode" id="cb881"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb881-1"><a href="two-parameters.html#cb881-1"></a>virtual_heights <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb881-2"><a href="two-parameters.html#cb881-2"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span></span>
<span id="cb881-3"><a href="two-parameters.html#cb881-3"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> height_90th, <span class="dt">y=</span>..count..<span class="op">/</span><span class="kw">sum</span>(..count..)), <span class="dt">binwidth =</span> <span class="fl">.5</span>, <span class="dt">fill =</span> <span class="st">"red"</span>) <span class="op">+</span></span>
<span id="cb881-4"><a href="two-parameters.html#cb881-4"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">"Estimate in 90th Percentile of Male Height"</span>, <span class="dt">y =</span> <span class="st">"Probability"</span>,</span>
<span id="cb881-5"><a href="two-parameters.html#cb881-5"></a>         <span class="dt">title =</span> <span class="st">"Posterior Distribution for the 90th Percentile of Male Heights in 2009"</span>) </span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-683-1.png" width="672"></p>
<p>We have just created the posterior distribution of the 90th percentile from our bootstraps. The histogram appears to be skewed to the right. Frankly, the posterior distribution looks weird, but that is okay because the posterior distribution includes the truth.</p>
<!-- Bootstrap creates posterior distribution for your estimate of the unknown parametr: the 90th percentile of heights in the 2370 observations from nhanes -->
<p>DK: Discuss our posterior distribution of the 90th percentile. Why it is weird. Does it include the truth in the 95% interval? Yes!</p>
</div>
<div id="show-that-bootstrap-works" class="section level2">
<h2>
<span class="header-section-number">7.4</span> Show that Bootstrap Works</h2>
<p>Suppose we want to set a 95% confidence interval on the 90th percentile, the true parameter
value for the real population. We have taken 1000 bootstrap samples. The bootstrap method suggests that approximately 95% of the time, the true parameter value for 90th percentile falls between the 2.5th percentile of the
bootstrap samples and the 97.5th percentile. In general, a 95% confidence interval indicates that if 1000 bootstrap samples are taken and a 95% confidence interval is calculated for each resample, then approximately 950 of the 1000 confidence intervals will contain the truth. Sometimes, however, we may take just one bootstrap sample and calculate its confidence interval, but this confidence interval may or may not contain the truth. In other words, the confidence interval generated from that bootstrap sample can over- or underestimate the true value. That is why statisticians usually run many samples like a thousand to see if 95% of the confidence intervals generated contain the truth.</p>
<p>In this case, we have created 1000 bootstrap samples, and we want to show that the bootstrap works, we will be creating a confidence interval for the 90th percentile for each bootstrap sample. One way to create a confidence interval for each bootstrap function is through a function. Notice how the function we created is basically the same as the bootstrap code, but we have just added a line to create the confidence interval for each bootstrap sample.</p>
<div class="sourceCode" id="cb882"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb882-1"><a href="two-parameters.html#cb882-1"></a>do_the_bootstrapci &lt;-<span class="st"> </span><span class="cf">function</span>(x){</span>
<span id="cb882-2"><a href="two-parameters.html#cb882-2"></a>x <span class="op">%&gt;%</span><span class="st">   </span></span>
<span id="cb882-3"><a href="two-parameters.html#cb882-3"></a><span class="st">  </span><span class="kw">select</span>(height) <span class="op">%&gt;%</span></span>
<span id="cb882-4"><a href="two-parameters.html#cb882-4"></a><span class="st">  </span><span class="kw">bootstraps</span>(<span class="dt">times =</span> <span class="dv">1000</span>) <span class="op">%&gt;%</span></span>
<span id="cb882-5"><a href="two-parameters.html#cb882-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">boot =</span> <span class="kw">map</span>(splits, <span class="op">~</span><span class="st"> </span><span class="kw">analysis</span>(.))) <span class="op">%&gt;%</span></span>
<span id="cb882-6"><a href="two-parameters.html#cb882-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">heights =</span> <span class="kw">map</span>(boot, <span class="op">~</span><span class="st"> </span><span class="kw">pull</span>(., height))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb882-7"><a href="two-parameters.html#cb882-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">height_90th =</span> <span class="kw">map_dbl</span>(heights, <span class="op">~</span><span class="st"> </span><span class="kw">quantile</span>(., <span class="dt">probs =</span> <span class="fl">0.90</span>))) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb882-8"><a href="two-parameters.html#cb882-8"></a><span class="st">  </span><span class="kw">pull</span>(height_90th)  <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb882-9"><a href="two-parameters.html#cb882-9"></a><span class="st">  </span><span class="kw">quantile</span>(., <span class="kw">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb882-10"><a href="two-parameters.html#cb882-10"></a>}</span></code></pre></div>
<p>Let’s not create a tibble to show whether the true value is within each confidence interval generated.</p>
<div class="sourceCode" id="cb883"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb883-1"><a href="two-parameters.html#cb883-1"></a><span class="kw">set.seed</span>(<span class="dv">9</span>)</span>
<span id="cb883-2"><a href="two-parameters.html#cb883-2"></a>sims &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb883-3"><a href="two-parameters.html#cb883-3"></a></span>
<span id="cb883-4"><a href="two-parameters.html#cb883-4"></a>bootstrapchecks &lt;-<span class="st"> </span><span class="kw">tibble</span>(<span class="dt">ID =</span> <span class="dv">1</span><span class="op">:</span>sims) <span class="op">%&gt;%</span></span>
<span id="cb883-5"><a href="two-parameters.html#cb883-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">heights_samples =</span> <span class="kw">map</span>(ID, <span class="op">~</span><span class="st"> </span><span class="kw">sample_n</span>(ch7_male, <span class="dv">40</span>, <span class="dt">replace =</span> <span class="ot">FALSE</span>))) <span class="op">%&gt;%</span></span>
<span id="cb883-6"><a href="two-parameters.html#cb883-6"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">ci =</span> <span class="kw">map</span>(heights_samples, <span class="op">~</span><span class="st"> </span><span class="kw">do_the_bootstrapci</span>(.))) <span class="op">%&gt;%</span></span>
<span id="cb883-7"><a href="two-parameters.html#cb883-7"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">within_ci =</span> <span class="kw">map_lgl</span>(ci, <span class="op">~</span><span class="st"> </span><span class="kw">ifelse</span>(<span class="kw">between</span>(<span class="fl">184.3</span>, ci[[<span class="dv">1</span>]][<span class="dv">1</span>], ci[[<span class="dv">1</span>]][<span class="dv">2</span>]), <span class="ot">TRUE</span>, <span class="ot">FALSE</span>)))</span>
<span id="cb883-8"><a href="two-parameters.html#cb883-8"></a>bootstrapchecks</span></code></pre></div>
<pre><code>## # A tibble: 100 x 4
##       ID heights_samples   ci        within_ci
##    &lt;int&gt; &lt;list&gt;            &lt;list&gt;    &lt;lgl&gt;    
##  1     1 &lt;tibble [40 × 1]&gt; &lt;dbl [2]&gt; TRUE     
##  2     2 &lt;tibble [40 × 1]&gt; &lt;dbl [2]&gt; TRUE     
##  3     3 &lt;tibble [40 × 1]&gt; &lt;dbl [2]&gt; TRUE     
##  4     4 &lt;tibble [40 × 1]&gt; &lt;dbl [2]&gt; TRUE     
##  5     5 &lt;tibble [40 × 1]&gt; &lt;dbl [2]&gt; TRUE     
##  6     6 &lt;tibble [40 × 1]&gt; &lt;dbl [2]&gt; TRUE     
##  7     7 &lt;tibble [40 × 1]&gt; &lt;dbl [2]&gt; TRUE     
##  8     8 &lt;tibble [40 × 1]&gt; &lt;dbl [2]&gt; TRUE     
##  9     9 &lt;tibble [40 × 1]&gt; &lt;dbl [2]&gt; TRUE     
## 10    10 &lt;tibble [40 × 1]&gt; &lt;dbl [2]&gt; TRUE     
## # … with 90 more rows</code></pre>
<p>We have created a tibble, which indicates whether the truth is within the CI or not. To get an understanding of the coding behind the tibble, we created an <code>ID</code> for each bootstrap sample and coded the creation of bootstrap samples in the next line. We then created the <code>ci</code> of each bootstrap sample, by using function we created. Lastly, we created <code>within_ci</code> by using a standard <code>ifelse</code> statement. The reason why we use <code>map_lgl</code> is that we want to return a logical (or alphabetic) vector.</p>
<p>Of the 100 bootstrap analyses we completed, each starting with a different sample of 40 rows from the <code>nhanes</code> data, 100 calculated a 95% confidence interval included the true 90th percentile of 184.3.</p>
<p>All our confidence intervals contained true 90th percentile, 184.3 cm! We can conclude from our results that the bootstrap does, in fact, work!</p>
</div>
<div id="watch-me-wave-my-hands" class="section level2">
<h2>
<span class="header-section-number">7.5</span> Watch me wave my hands</h2>
<p><label for="tufte-mn-83" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-83" class="margin-toggle"><span class="marginnote"> In this sense, the bootstrap distribution represents an (approximate)
nonparametric, noninformative posterior distribution for our parameter.
But this bootstrap distribution is obtained painlessly — without having to
formally specify a prior and without having to sample from the posterior
distribution. Hence we might think of the bootstrap distribution as a “poor
man’s” Bayes posterior. By perturbing the data, the bootstrap approximates
the Bayesian effect of perturbing the parameters, and is typically
much simpler to carry out. — Elements of Statistical Learning, 2nd edition, by Hastie et al, page 271.</span></p>
<p>Did we mention that this book is still a bit of a mess? Well, it is! And, in the entire book, this section is the messiest mess of them all. Forgive us.</p>
<p>The mess centers on the transition we are now making between the bootstrap and the full scale Bayesian approach. The margin note provides a bit of a justification. For now, that is all we have. So, watch us wave our hands and pretend that we have justified the leap we are about to take.</p>
<p>First, if you understand the concept of a posterior probability distribution as explained in Chapter 5 and, second, if you follow our demonstration that the bootstrap generates posterior distributions, then . . . . hand wave vigorously . . . third, you should be confortable going on to the standard Bayesian modeling approach that we will use for the next few chapters.</p>
</div>
<div id="stan_glm" class="section level2">
<h2>
<span class="header-section-number">7.6</span> <code>stan_glm()</code>
</h2>
<p>Fortunately for us, Bayesian models are not hard to execute in R. Sticking to same the filtered male 2009 data from the bootstrap example, this line of code would be able to perform a bayesian generalized linear model to estimate the mean height. This function comes from the <strong>rstanarm</strong> package, which is very useful for bayesian models.</p>
<div class="sourceCode" id="cb885"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb885-1"><a href="two-parameters.html#cb885-1"></a>ch7_male &lt;-<span class="st"> </span>nhanes <span class="op">%&gt;%</span></span>
<span id="cb885-2"><a href="two-parameters.html#cb885-2"></a><span class="st">  </span><span class="kw">filter</span>(survey <span class="op">==</span><span class="st"> </span><span class="dv">2009</span>, gender <span class="op">==</span><span class="st"> "Male"</span>) <span class="op">%&gt;%</span></span>
<span id="cb885-3"><a href="two-parameters.html#cb885-3"></a><span class="st">  </span><span class="kw">select</span>(height) <span class="op">%&gt;%</span></span>
<span id="cb885-4"><a href="two-parameters.html#cb885-4"></a><span class="st">  </span><span class="kw">arrange</span>(height) <span class="op">%&gt;%</span></span>
<span id="cb885-5"><a href="two-parameters.html#cb885-5"></a><span class="st">  </span><span class="kw">na.omit</span>()</span>
<span id="cb885-6"><a href="two-parameters.html#cb885-6"></a></span>
<span id="cb885-7"><a href="two-parameters.html#cb885-7"></a>mod.obj &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(<span class="dt">data =</span> ch7_male, height <span class="op">~</span><span class="st"> </span><span class="dv">1</span>)</span></code></pre></div>
<pre><code>## 
## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).
## Chain 1: 
## Chain 1: Gradient evaluation took 0.001122 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 11.22 seconds.
## Chain 1: Adjust your expectations accordingly!
## Chain 1: 
## Chain 1: 
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1: 
## Chain 1:  Elapsed Time: 0.026464 seconds (Warm-up)
## Chain 1:                0.190381 seconds (Sampling)
## Chain 1:                0.216845 seconds (Total)
## Chain 1: 
## 
## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).
## Chain 2: 
## Chain 2: Gradient evaluation took 1.8e-05 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.
## Chain 2: Adjust your expectations accordingly!
## Chain 2: 
## Chain 2: 
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2: 
## Chain 2:  Elapsed Time: 0.030203 seconds (Warm-up)
## Chain 2:                0.184224 seconds (Sampling)
## Chain 2:                0.214427 seconds (Total)
## Chain 2: 
## 
## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).
## Chain 3: 
## Chain 3: Gradient evaluation took 1e-05 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.
## Chain 3: Adjust your expectations accordingly!
## Chain 3: 
## Chain 3: 
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3: 
## Chain 3:  Elapsed Time: 0.029287 seconds (Warm-up)
## Chain 3:                0.180986 seconds (Sampling)
## Chain 3:                0.210273 seconds (Total)
## Chain 3: 
## 
## SAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).
## Chain 4: 
## Chain 4: Gradient evaluation took 1.7e-05 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.
## Chain 4: Adjust your expectations accordingly!
## Chain 4: 
## Chain 4: 
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4: 
## Chain 4:  Elapsed Time: 0.025643 seconds (Warm-up)
## Chain 4:                0.194061 seconds (Sampling)
## Chain 4:                0.219704 seconds (Total)
## Chain 4:</code></pre>
<p>Similarly to the bootstrap method we just went over, this model is taking serveral resamples of the data when anayzing the distribution of heights in our data to create a posterior distribution. Each resample or simulation is its own model of two parameters (an intercept and sigma). The best way to see this is to convert the model into a matrix with the <code>as.matrix()</code> function. As you can see below, the outputted matrix shows you the interept and sigma of each simulation</p>
<div class="sourceCode" id="cb887"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb887-1"><a href="two-parameters.html#cb887-1"></a>sims &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(mod.obj)</span></code></pre></div>
<p>If you want to get into the specifics, the function is using sampling via the Markov chain Monte Carlo. While an in depth explanation of this sampling method is beyond the scope of the class, you can read up more on both the function and its algorithm here <a href="https://mc-stan.org/rstanarm/reference/stan_glm.html" class="uri">https://mc-stan.org/rstanarm/reference/stan_glm.html</a> if interested.</p>
<div class="sourceCode" id="cb888"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb888-1"><a href="two-parameters.html#cb888-1"></a>mod.obj</span></code></pre></div>
<pre><code>## stan_glm
##  family:       gaussian [identity]
##  formula:      height ~ 1
##  observations: 2370
##  predictors:   1
## ------
##             Median MAD_SD
## (Intercept) 167.5    0.4 
## 
## Auxiliary parameter(s):
##       Median MAD_SD
## sigma 21.8    0.3  
## 
## ------
## * For help interpreting the printed output see ?print.stanreg
## * For info on the priors used see ?prior_summary.stanreg</code></pre>
<p>When you output the model by itself</p>
<p>In essence, chains 1-4 of the output are sampling in a method similar to the bootstrap that we did to give us the main parameters of the model: the intercept and the sigma. Because all of these cacuation lines are not necessary to understanding our model, you can include refresh=0 in the function and assign it to an object to have a much cleaner output like the one below</p>
<!-- Explain in detail all aspects of the model. -->
<div class="sourceCode" id="cb890"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb890-1"><a href="two-parameters.html#cb890-1"></a>mod.obj &lt;-<span class="st"> </span><span class="kw">stan_glm</span>(<span class="dt">data =</span> ch7_male, height <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">refresh =</span> <span class="dv">0</span>)</span>
<span id="cb890-2"><a href="two-parameters.html#cb890-2"></a>mod.obj</span></code></pre></div>
<pre><code>## stan_glm
##  family:       gaussian [identity]
##  formula:      height ~ 1
##  observations: 2370
##  predictors:   1
## ------
##             Median MAD_SD
## (Intercept) 167.5    0.4 
## 
## Auxiliary parameter(s):
##       Median MAD_SD
## sigma 21.8    0.3  
## 
## ------
## * For help interpreting the printed output see ?print.stanreg
## * For info on the priors used see ?prior_summary.stanreg</code></pre>
<p>Now that have a much cleaner output, we can more easily understand what this model spit out at us. The first few lines remind us that we performed a bayesian generalized linear model of 1 predictor, height, with a gaussian distribution on a dataset of 2370 people. It is useful to know that a Gaussian, or normal, distribution is a probability distribution that is symmetric about the mean, showing that data near the mean are more frequent than data far from it.</p>
<p>Under that, we see the output for the two parameters of the model: intercept and sigma. For each parameter, there is a calculated point estimate (medians computed through the simulation) and uncertainty estimates (standard deviations) of these point estimates. This is the case because we cannot be sure what the actual point estimate of the parameter is, but running many simulations through the model can give us an idea of how certain our calculated point estimate is. For a lot of Bayesian inferencing, our uncertainty estimate for each parameter will be calculated using MAD SD, the median absolute deviation.</p>
</div>
<div id="diving-into-mad_sd" class="section level2">
<h2>
<span class="header-section-number">7.7</span> Diving into MAD_SD</h2>
<p>As previously mentioned, MAD SD is a measure of uncertainty, similar to standard error which has been previously mentioned in the book. In fact MAD SD is a more robust measure than standard error becaue standard error is calculated by squaring ditances from data points to the model, which means outliers will more strongly skew data.</p>
<p>MAD SD is computed by scaling the median absolute deviation from the posterior medians, but what does this even mean? Let’s dive deeper with an example</p>
<p>Here below, we have a vector of 9 numbers, which could represent anything, like the ages of children at a park.</p>
<div class="sourceCode" id="cb892"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb892-1"><a href="two-parameters.html#cb892-1"></a>x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">8</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">1</span>,<span class="dv">5</span>)</span></code></pre></div>
<p>The first step of calculating MAD SD is to calculate MAD, which can be seen with this equation.</p>
<p><span class="math display">\[ MAD = median(|Yi – median(Yi|) \]</span></p>
<p>The first step to doing this is first finding the median of the vector (which in this case is 3) and subtracting it from each value. This gives you a vector where each number is the distance from the original the the median of all the differences. Importantly, all of these distances should be the same sign, since we care about distance more than direction, thus we take the absolute value of them.</p>
<div class="sourceCode" id="cb893"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb893-1"><a href="two-parameters.html#cb893-1"></a>medianx &lt;-<span class="st"> </span><span class="kw">median</span>(x)</span>
<span id="cb893-2"><a href="two-parameters.html#cb893-2"></a>diffx &lt;-<span class="st"> </span><span class="kw">abs</span>(x <span class="op">-</span><span class="st"> </span>medianx)</span></code></pre></div>
<p>At this point, we have a list of numbers which represent that difference between the original numbers and the median</p>
<div class="sourceCode" id="cb894"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb894-1"><a href="two-parameters.html#cb894-1"></a>diffx</span></code></pre></div>
<pre><code>## [1] 0 1 2 5 1 2 1 2 2</code></pre>
<p>The last step in calculating MAD is to take the median of those differenes, which in this case gives us 2</p>
<div class="sourceCode" id="cb896"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb896-1"><a href="two-parameters.html#cb896-1"></a>mediandiffx &lt;-<span class="st"> </span><span class="kw">median</span>(diffx)</span></code></pre></div>
<p>Lastly, because it is very useful in data analysis to be able to compare things to standard deviations, we usually rescale the median absolute deviation by multiplying it by 1.483, which reproduces the standard error if the data is normally distributed and can be calculated with the <code>mad()</code> equation</p>
<div class="sourceCode" id="cb897"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb897-1"><a href="two-parameters.html#cb897-1"></a>mediandiffx <span class="op">*</span><span class="st"> </span><span class="fl">1.483</span></span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb899"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb899-1"><a href="two-parameters.html#cb899-1"></a><span class="kw">mad</span>(x) </span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<p>Thus, the full equation of MAD SD is</p>
<p><span class="math display">\[ MADsd = 1.483 * median(|Yi – median(Yi|) \]</span></p>
<p>Before moving on to the next section of this chapter, take a second to make sure you understand what MAD SD and how it is calculated - it will play a very big role in demonstrating the uncertainty of most of our future parameters in the book</p>
<p>The first step to doing this is first finding the median of the vector (which in this case is 3) and subtracting it from each value. This gives you a vector where each number is the distance from the original the the median of all the differences. Importantly, all of these distances should be the same sign, since we care about distance more than direction, thus we take the absolute value of them.</p>
<div class="sourceCode" id="cb901"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb901-1"><a href="two-parameters.html#cb901-1"></a>medianx &lt;-<span class="st"> </span><span class="kw">median</span>(x)</span>
<span id="cb901-2"><a href="two-parameters.html#cb901-2"></a>diffx &lt;-<span class="st"> </span><span class="kw">abs</span>(x <span class="op">-</span><span class="st"> </span>medianx)</span></code></pre></div>
<p>At this point, we have a list of numbers which represent that difference between the original numbers and the median</p>
<div class="sourceCode" id="cb902"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb902-1"><a href="two-parameters.html#cb902-1"></a>diffx</span></code></pre></div>
<pre><code>## [1] 0 1 2 5 1 2 1 2 2</code></pre>
<p>The last step in calculating MAD is to take the median of those differenes, which in this case gives us 2</p>
<div class="sourceCode" id="cb904"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb904-1"><a href="two-parameters.html#cb904-1"></a>mediandiffx &lt;-<span class="st"> </span><span class="kw">median</span>(diffx)</span></code></pre></div>
<p>Lastly, because it is very useful in data analysis to be able to compare things to standard deviations, we usually rescale the median absolute deviation by multiplying it by 1.483, which reproduces the standard error if the data is normally distributed and can be calculated with the <code>mad()</code> equation</p>
<div class="sourceCode" id="cb905"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb905-1"><a href="two-parameters.html#cb905-1"></a>mediandiffx <span class="op">*</span><span class="st"> </span><span class="fl">1.483</span></span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb907"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb907-1"><a href="two-parameters.html#cb907-1"></a><span class="kw">mad</span>(x) </span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<p>Thus, the full equation of MAD SD is</p>
<p><span class="math display">\[ MADsd = 1.483 * median(|Yi – median(Yi|) \]</span></p>
<p>Before moving on to the next section of this chapter, take a second to make sure you understand what MAD SD and how it is calculated - it will play a very big role in demonstrating the uncertainty of most of our future parameters in the book</p>
</div>
<div id="unpacking-the-first-parameter-the-intercept" class="section level2">
<h2>
<span class="header-section-number">7.8</span> Unpacking the first parameter: the intercept</h2>
<div class="sourceCode" id="cb909"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb909-1"><a href="two-parameters.html#cb909-1"></a>mod.obj</span></code></pre></div>
<pre><code>## stan_glm
##  family:       gaussian [identity]
##  formula:      height ~ 1
##  observations: 2370
##  predictors:   1
## ------
##             Median MAD_SD
## (Intercept) 167.5    0.4 
## 
## Auxiliary parameter(s):
##       Median MAD_SD
## sigma 21.8    0.3  
## 
## ------
## * For help interpreting the printed output see ?print.stanreg
## * For info on the priors used see ?prior_summary.stanreg</code></pre>
<p>Now that we understand MAD SD, we can understand the rest of the output of our mean height model. Since we are trying to find a constant to predict mean height, the intercept of the model can be interpreted as the model’s best estimate of the mean height in the dataset. Recall that the <code>stan_glm()</code> function took many different resamples and found the mean of each one. The most accurate estimate of what the true mean actually is the Baysesian point estimate, the median of these means which in this case happends to be 167.5. In this case, the MAD_SD for the intercept is .4, meaning that the standard deviation of the posterior distribution of mean heights is .4. As a rule of thumb, the smaller the MAD_SD, the less variation there is among mean heights in the samples generated, and thus the more robust our estimate is.</p>
<div class="sourceCode" id="cb911"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb911-1"><a href="two-parameters.html#cb911-1"></a><span class="kw">plot</span>(mod.obj, <span class="st">"hist"</span>, <span class="dt">pars =</span> <span class="st">"(Intercept)"</span>)</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="book_temp_files/figure-html/unnamed-chunk-700-1.png" width="672"></p>
<div class="sourceCode" id="cb913"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb913-1"><a href="two-parameters.html#cb913-1"></a><span class="co">#abline(v = 167.5)</span></span></code></pre></div>
</div>
<div id="unpacking-the-second-parameter-sigma" class="section level2">
<h2>
<span class="header-section-number">7.9</span> Unpacking the second parameter: sigma</h2>
<p>The second parameter, sigma, will be outputted for all bayesian models you compute (no matter how many predictors) and shows us the average error of the model. Another way of conceptualizing this parameter is as the deviation between the predicted value and the observed value. More specifically, sigma, the residual standard error, tells us that the mean height of males will be between plus or minus 21.8 of our prediction 68% of the time and plus or minus two times 21.8 the prediction about 95% of the time. Similar to with the intercept, the MAD_SD of the sigma reflects the standard deviation of the sigma value itself (since so many different samples were taken with each its own sigma)</p>
<div class="sourceCode" id="cb914"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb914-1"><a href="two-parameters.html#cb914-1"></a><span class="kw">plot</span>(mod.obj, <span class="st">"hist"</span>, <span class="dt">pars =</span> <span class="st">"sigma"</span>)</span></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="book_temp_files/figure-html/unnamed-chunk-701-1.png" width="672"></p>
</div>
<div id="comparing-lm-and-stan_glm" class="section level2">
<h2>
<span class="header-section-number">7.10</span> Comparing lm and stan_glm</h2>
<p>Both the <code>lm()</code> and <code>stan_glm()</code> functions can be used to to create linear models. The reason this textbook is focusing on <code>stan_glm()</code> is through running serveral simulations of the model, it can represent uncertainty ina much more accurate way. Additionally, by performing Bayesian inference, this function also leads to more stable estimates and predictions that can be based on priors. A discussion on priors and Bayesian inference in general is beyond the scope of the chapter, but in all essence a prior is some previous information that you bring to the table when creating a sort of model that can influence how you create the model.</p>
</div>
<div id="visualizing-the-results-of-the-linear-model" class="section level2">
<h2>
<span class="header-section-number">7.11</span> Visualizing the results of the linear model</h2>
<p>While the output of the <code>stan_glm()</code> function is helpful, it is many times crucial to visualize our results. One way that we can do this is by taking the output of the model and putting it into a nice table. A great package to specifically visualize these tpye of Bayesian models is the stargazer package, which comes with the <code>stargazer()</code> function seen below</p>
<div class="sourceCode" id="cb916"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb916-1"><a href="two-parameters.html#cb916-1"></a><span class="co">#stargazer(mod.obj)</span></span></code></pre></div>
<p>The results of the bayesian linera model can also be seen with the posterior linpred function, which give a fitted model with a matrix of the estimates probabilites.</p>
<div class="sourceCode" id="cb917"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb917-1"><a href="two-parameters.html#cb917-1"></a>mod.obj_linpred &lt;-<span class="st"> </span><span class="kw">posterior_linpred</span>(mod.obj, <span class="dt">transform =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## Instead of posterior_linpred(..., transform=TRUE) please call posterior_epred(), which provides equivalent functionality.</code></pre>
<p>From this matrix, you can use the ggplot function to create a histogram showing the distribution of mean heights across all of the samples. Looking at the histogram, it seems like the mean point estimate is between 167 and 168, which makes a lot of sense considering our median point estimate is 167.5</p>
<div class="sourceCode" id="cb919"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb919-1"><a href="two-parameters.html#cb919-1"></a>mod.obj_linpred[,<span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb919-2"><a href="two-parameters.html#cb919-2"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb919-3"><a href="two-parameters.html#cb919-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(value)) <span class="op">+</span></span>
<span id="cb919-4"><a href="two-parameters.html#cb919-4"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.002</span>, <span class="dt">color =</span> <span class="st">"blue"</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-705-1.png" width="672"></p>
<div class="sourceCode" id="cb920"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb920-1"><a href="two-parameters.html#cb920-1"></a><span class="co">## add median of model, try to add mad_sd to show the 68&amp; and 95% rules</span></span>
<span id="cb920-2"><a href="two-parameters.html#cb920-2"></a><span class="co">#explain graph</span></span></code></pre></div>
<p>Another useful tool in the rstanarm package is posterior predict, which can make predictions on new data using our model. This becomes even more useful when working with more parameters, as you will see in Chapter 8.</p>
<div class="sourceCode" id="cb921"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb921-1"><a href="two-parameters.html#cb921-1"></a>mod.obj_predict &lt;-<span class="st"> </span><span class="kw">posterior_predict</span>(mod.obj, <span class="dt">transform =</span> <span class="ot">TRUE</span>)</span>
<span id="cb921-2"><a href="two-parameters.html#cb921-2"></a>mod.obj_predict[,<span class="dv">3</span>] <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb921-3"><a href="two-parameters.html#cb921-3"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb921-4"><a href="two-parameters.html#cb921-4"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(value)) <span class="op">+</span></span>
<span id="cb921-5"><a href="two-parameters.html#cb921-5"></a><span class="st">    </span><span class="kw">geom_histogram</span>(<span class="dt">binwidth =</span> <span class="fl">0.002</span>)</span></code></pre></div>
<p><img src="book_temp_files/figure-html/unnamed-chunk-706-1.png" width="672"></p>
</div>
<div id="wisdom" class="section level2">
<h2>
<span class="header-section-number">7.12</span> Wisdom</h2>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/Wisdom.jpg" alt=" " width="1280"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
<p>Let’s look at how our key theme, Wisdom, fits in with two-parameter estimates. Just like in the previous chapter, Wisdom covers the relevance of the estimands and the map from concept to data.</p>
<p>In our NHANES data, we focused on the mean and 90th percentile of male heights. We can easily extract both estimands from our bootstrap samples. However, are these estimands accurately capturing what we care about? Probably, but we are not fully sure. What we want optimally is if we can accurately predict the mean and 90th percentile of male heights in the US. We want a model that should generalize its points of interests and include all predictors. For example, with regard to the outcome variable, a model of heights will not necessarily tell you about patterns of male heights.</p>
<p>Our problem, estimating both mean and 90th percentile of male heights, is by taking care of our confounding variables.</p>
<p>First, there are both genders in the data. We had to adjust for that by filtering to only men. Additionally, males have a certain age range, typically above 18 years old. We also had to account for that. By using bootstraps, we were able to use random samples to thus help get more representative samples.</p>
<p>Second, it’s important to understand that data is always missing. We could easily calculate our estimands through arithmetic means, but because we don’t have perfect data we will have to estimate. In this case, by using bootstrap samples we were able to create confidence intervals to give us some quantitative measure of confidence.</p>
</div>
<div id="justice" class="section level2">
<h2>
<span class="header-section-number">7.13</span> Justice</h2>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/Justice.jpg" alt=" " width="960"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
<p>Let’s try to understand the math behind our height model. For one, height is normally distributed because our data is continuous. Unlike in the previous chapter where data is discrete, we are dealing with continuous data. In addition, we can find the mean height and standard deviation of height, both of which are parameters for the normal distribution. Therefore, we will see the following:</p>
<p><span class="math display">\[ height_i \sim N(\beta, \sigma^2)\]</span>
But what about the standard error in our data. What does its distribution look like? Well the distribution of our standard error is also normally distributed. This is because the errors from our bootstrap samples are random and continuous, which will also follow a normal distribution.</p>
<p><span class="math display">\[ \epsilon_i \sim N(0, \sigma^2)\]</span>
Standard deviation of the bootstrap is the same thing as <span class="math inline">\(\sigma\)</span>.</p>
</div>
<div id="courage" class="section level2">
<h2>
<span class="header-section-number">7.14</span> Courage</h2>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/Courage.jpg" alt=" " width="1024"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
<p>In data science, we deal with words, math, and code. The most important term is code. We need some sort of framework to detail the structure of our model using all three terms. However, Courage is needed to implement the coded model.</p>
<p>The data we have seen is generated by the complex and confusing world. We have to build a model to create some sort of computational mechanism that creates fake data that is consistent with the real, true data in the world. This is our “Data Generating Mechanism,” which provides predictions and uncertainty.</p>
<p>We need a “machine” that generates our predictions, which is the same thing as a machine which fills in all the question marks in the Actual Preceptor Table and provides confidence intervals, which is the same thing as a machine which produces “fake data” which looks a lot like our actual data.</p>
<p>We are ultimately looking at our code and uncertainty under Courage.</p>
</div>
<div id="temperance" class="section level2">
<h2>
<span class="header-section-number">7.15</span> Temperance</h2>
<p>
<span class="marginnote shownote">
<!--
<div class="figure">-->
<img src="other/images/Temperance.jpg" alt=" " width="960"><!--
<p class="caption marginnote">--><!--</p>--><!--</div>--></span>
</p>
<p>Temperance is probably the most important virtue in data science. We won’t have the models that look as good as they appear. We are living in a constantly changing and complex world. There will be unknown unknowns, which factors in the representation of our data, realism in our assumptions, and the call for testing.</p>
<p>In data science, we are focused on that missing data, the data from the future. But the world is always changing, and so it’s hard to capture that missing data. Our predictions are going to have some sort of uncertainty.</p>
<p>In the case of male heights, what would be the average male height if the data was collected a week later? What if there was a pandemic? What if the world lost a great amount of Vitamin D? As you can see, there are events that are considered unknown unknowns. It’s so hard to account for the future, and so our models are likely going to be wrong.</p>
<p>Another reason why we deal with Temperance in data science is that there is realism. Does the structure of our bootstrap match the world? While we hope we won’t be wrong, it never matches frankly and we will see that our conclusions are wrong.</p>
<p>Last but not least, getting the wrong conclusions suck. But at least we are not dealing with null hypotheses. Playing the prediction game could be fun, but if we reject the null hypothesis if p is less than .05, what if we get .06 as our p-value? Will that honestly make a difference? Probably not!</p>
<!-- Follow Gelman. Use some math, from the themes.Rmd file. -->
<div class="sourceCode" id="cb922"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb922-1"><a href="two-parameters.html#cb922-1"></a><span class="co"># mod.obj &lt;- stan_glm(data = ch7_male, height ~ 1, refresh = 0)</span></span>
<span id="cb922-2"><a href="two-parameters.html#cb922-2"></a><span class="co"># </span></span>
<span id="cb922-3"><a href="two-parameters.html#cb922-3"></a><span class="co"># mod.obj</span></span></code></pre></div>
<!-- Explain in detail all aspects of the model. -->
<div class="sourceCode" id="cb923"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb923-1"><a href="two-parameters.html#cb923-1"></a><span class="co"># tbl_regression(mod.obj)</span></span></code></pre></div>

</div>
</div></body></html>

<p style="text-align: center;">
<a href="one-parameter.html"><button class="btn btn-default">Previous</button></a>
<a href="three-parameters.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-09-23
</p>
</div>
</div>



</body>
</html>
